check the codebase. Do a gap analysis with /docs/PLAN. Do a git diff. Check last commit CI status. Be thorough, meticulous, and Thinnk ultra hard before you act.

---

<task-notification>
<task-id>a61aad4</task-id>
<status>completed</status>
<summary>Agent "Explore full codebase structure" completed</summary>
<result>Excellent. Now I have all the information needed to provide a comprehensive report. Let me compile the final detailed exploration:

## Comprehensive Apollo Codebase Exploration

I've completed a thorough exploration of the Apollo codebase. Here's everything you requested:

---

## 1. ALL API ROUTES (47 route.ts files)

**Project Management:**
- `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/route.ts` - GET (list), POST (create)
- `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/route.ts` - GET, PATCH (update), DELETE
- `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/share/route.ts`

**Sections & Phases:**
- `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/sections/route.ts` - GET, POST
- `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/sections/[phase]/route.ts` - GET, PATCH
- `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/sections/[phase]/generate/route.ts` - POST
- `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/sections/[phase]/review/route.ts` - POST
- `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/sections/[phase]/approve/route.ts` - POST
- `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/sections/[phase]/refine/route.ts`

**Compilation & Preview:**
- `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/compile/route.ts` - POST
- `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/compilations/route.ts` - GET
- `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/preview.pdf/route.ts` - GET

**Citations:**
- `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/citations/route.ts` - GET, POST
- `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/citations/[citationId]/route.ts` - GET, PATCH, DELETE
- `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/citations/[citationId]/re-resolve/route.ts` - POST
- `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/citations/audit/route.ts` - GET
- `/Users/devs/Downloads/Apollo/apps/web/app/api/citations/search/route.ts` - GET

**Analyses & Datasets:**
- `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/analyses/route.ts` - GET, POST
- `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/analyses/[analysisId]/route.ts` - GET, PATCH, DELETE
- `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/analyses/auto-detect/route.ts` - POST
- `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/datasets/route.ts` - GET, POST
- `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/datasets/[datasetId]/route.ts` - GET, PATCH, DELETE
- `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/datasets/[datasetId]/download/route.ts` - GET
- `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/datasets/generate/route.ts` - POST

**Figures & Abbreviations:**
- `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/figures/route.ts` - GET, POST
- `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/figures/[figureId]/route.ts` - GET, PATCH, DELETE
- `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/figures/mermaid/route.ts` - POST
- `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/abbreviations/route.ts` - GET, POST
- `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/abbreviations/[abbrevId]/route.ts` - GET, PATCH, DELETE

**Quality Control & Compliance:**
- `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/qc/route.ts` - GET
- `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/qc/fix/route.ts` - POST
- `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/compliance/route.ts` - GET

**Export:**
- `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/export/pdf/route.ts` - GET
- `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/export/docx/route.ts` - GET
- `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/export/source/route.ts` - GET
- `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/export/stats/route.ts` - GET

**Licenses & Payments:**
- `/Users/devs/Downloads/Apollo/apps/web/app/api/licenses/route.ts` - GET, POST
- `/Users/devs/Downloads/Apollo/apps/web/app/api/licenses/[lid]/transfer/route.ts` - POST
- `/Users/devs/Downloads/Apollo/apps/web/app/api/licenses/[lid]/attach/[pid]/route.ts` - POST
- `/Users/devs/Downloads/Apollo/apps/web/app/api/checkout/route.ts` - POST

**Webhooks & External:**
- `/Users/devs/Downloads/Apollo/apps/web/app/api/webhooks/clerk/route.ts` - POST
- `/Users/devs/Downloads/Apollo/apps/web/app/api/webhooks/stripe/route.ts` - POST
- `/Users/devs/Downloads/Apollo/apps/web/app/api/webhooks/razorpay/route.ts` - POST
- `/Users/devs/Downloads/Apollo/apps/web/app/api/inngest/route.ts` - POST
- `/Users/devs/Downloads/Apollo/apps/web/app/api/upload/signed-url/route.ts` - POST

**Utilities:**
- `/Users/devs/Downloads/Apollo/apps/web/app/api/synopsis/parse/route.ts` - POST

**Review (Shared):**
- `/Users/devs/Downloads/Apollo/apps/web/app/api/review/[token]/route.ts` - GET
- `/Users/devs/Downloads/Apollo/apps/web/app/api/review/[token]/comments/route.ts` - GET, POST

---

## 2. ALL PAGES (11 page.tsx files)

**Root:**
- `/Users/devs/Downloads/Apollo/apps/web/app/page.tsx` - Landing page

**Authentication (Route Group):**
- `/Users/devs/Downloads/Apollo/apps/web/app/(auth)/sign-in/[[...sign-in]]/page.tsx` - Clerk sign-in
- `/Users/devs/Downloads/Apollo/apps/web/app/(auth)/sign-up/[[...sign-up]]/page.tsx` - Clerk sign-up

**Dashboard (Route Group):**
- `/Users/devs/Downloads/Apollo/apps/web/app/(dashboard)/dashboard/page.tsx` - Main dashboard
- `/Users/devs/Downloads/Apollo/apps/web/app/(dashboard)/projects/page.tsx` - Projects list
- `/Users/devs/Downloads/Apollo/apps/web/app/(dashboard)/projects/new/page.tsx` - New project wizard
- `/Users/devs/Downloads/Apollo/apps/web/app/(dashboard)/projects/[id]/page.tsx` - Project view
- `/Users/devs/Downloads/Apollo/apps/web/app/(dashboard)/projects/[id]/setup/page.tsx` - Project setup
- `/Users/devs/Downloads/Apollo/apps/web/app/(dashboard)/checkout/page.tsx` - Checkout
- `/Users/devs/Downloads/Apollo/apps/web/app/(dashboard)/licences/page.tsx` - Licenses management

**Public Review:**
- `/Users/devs/Downloads/Apollo/apps/web/app/review/[token]/page.tsx` - Shared review page

---

## 3. ALL COMPONENTS (80 component files)

**Layout Components:**
- `/Users/devs/Downloads/Apollo/apps/web/components/layout/navbar.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/layout/app-sidebar.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/layout/glass-sidebar.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/layout/glass-sidebar-provider.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/layout/dashboard-header.tsx`

**Landing Components (Locked):**
- `/Users/devs/Downloads/Apollo/apps/web/components/landing/hero-section.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/landing/hero-3d-scene.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/landing/features-section.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/landing/how-it-works-section.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/landing/pricing-section.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/landing/testimonials-section.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/landing/cta-section.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/landing/faq-section.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/landing/footer-section.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/landing/sponsors-section.tsx`

**Project Components (Locked):**
- `/Users/devs/Downloads/Apollo/apps/web/components/project/pipeline-timeline.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/project/license-banner.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/project/progress-dashboard.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/project/compliance-dashboard.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/project/phase-stepper.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/project/delete-project-button.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/project/share-dialog.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/project/export-menu.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/project/citation-search-dialog.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/project/citation-list-panel.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/project/ai-generate-button.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/project/compile-button.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/project/section-viewer.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/project/review-dialog.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/project/review-comments.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/project/figure-gallery.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/project/analysis-wizard.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/project/dataset-upload.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/project/mermaid-editor.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/project/abbreviation-manager.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/project/template-gallery.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/project/whatsapp-share-button.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/project/thesis-completion.tsx`

**Editor Components:**
- `/Users/devs/Downloads/Apollo/apps/web/components/editor/section-editor.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/editor/latex-source-view.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/editor/word-count-bar.tsx`

**Viewer Components:**
- `/Users/devs/Downloads/Apollo/apps/web/components/viewer/pdf-viewer.tsx`

**Wizard Components:**
- `/Users/devs/Downloads/Apollo/apps/web/components/wizard/setup-wizard.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/wizard/steps/synopsis-upload-step.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/wizard/steps/parsed-data-review-step.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/wizard/steps/university-step.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/wizard/steps/metadata-form-step.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/wizard/steps/title-page-preview-step.tsx`

**Upload Components:**
- `/Users/devs/Downloads/Apollo/apps/web/components/upload/file-uploader.tsx`

**Preview Components:**
- `/Users/devs/Downloads/Apollo/apps/web/components/preview/title-page-preview.tsx`

**Auth Components:**
- `/Users/devs/Downloads/Apollo/apps/web/components/auth/auth-3d-scene-loader.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/auth/auth-3d-scene.tsx`

**License Components:**
- `/Users/devs/Downloads/Apollo/apps/web/components/licences/attach-dialog.tsx`

**Onboarding Components:**
- `/Users/devs/Downloads/Apollo/apps/web/components/onboarding/tour-overlay.tsx`

**Provider Components:**
- `/Users/devs/Downloads/Apollo/apps/web/components/providers/pwa-provider.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/providers/posthog-provider.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/theme-provider.tsx`

**UI Components (shadcn/ui + custom):**
- `/Users/devs/Downloads/Apollo/apps/web/components/ui/button.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/ui/accordion.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/ui/alert-dialog.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/ui/avatar.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/ui/breadcrumb.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/ui/carousel.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/ui/input.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/ui/navigation-menu.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/ui/separator.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/ui/sheet.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/ui/sidebar.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/ui/skeleton.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/ui/tooltip.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/ui/animated-grid.tsx`

---

## 4. ALL LIB MODULES (97 files)

**AI & Generation:**
- `/Users/devs/Downloads/Apollo/apps/web/lib/ai/client.ts` - Claude API client
- `/Users/devs/Downloads/Apollo/apps/web/lib/ai/prompts.ts` - AI prompts
- `/Users/devs/Downloads/Apollo/apps/web/lib/ai/parse-synopsis-response.ts`
- `/Users/devs/Downloads/Apollo/apps/web/lib/ai/review-section.ts`
- `/Users/devs/Downloads/Apollo/apps/web/lib/ai/rate-limit.ts` + .test.ts
- `/Users/devs/Downloads/Apollo/apps/web/lib/ai/redact.ts` + .test.ts
- `/Users/devs/Downloads/Apollo/apps/web/lib/ai/token-budget.ts`
- `/Users/devs/Downloads/Apollo/apps/web/lib/ai/analysis-explanations.ts`

**API Utilities:**
- `/Users/devs/Downloads/Apollo/apps/web/lib/api/auth.ts`
- `/Users/devs/Downloads/Apollo/apps/web/lib/api/errors.ts`
- `/Users/devs/Downloads/Apollo/apps/web/lib/api/licence-gate.ts`

**Citations:**
- `/Users/devs/Downloads/Apollo/apps/web/lib/citations/resolve.ts` + .test.ts
- `/Users/devs/Downloads/Apollo/apps/web/lib/citations/crossref.ts` + .test.ts
- `/Users/devs/Downloads/Apollo/apps/web/lib/citations/pubmed.ts` + .test.ts
- `/Users/devs/Downloads/Apollo/apps/web/lib/citations/audit.ts` + .test.ts
- `/Users/devs/Downloads/Apollo/apps/web/lib/citations/auto-resolve.ts` + .test.ts
- `/Users/devs/Downloads/Apollo/apps/web/lib/citations/extract-keys.ts`
- `/Users/devs/Downloads/Apollo/apps/web/lib/citations/pre-seed.ts`

**Compliance & QC:**
- `/Users/devs/Downloads/Apollo/apps/web/lib/compliance/checker.ts` + .test.ts
- `/Users/devs/Downloads/Apollo/apps/web/lib/compliance/checklists.ts` + .test.ts
- `/Users/devs/Downloads/Apollo/apps/web/lib/compliance/nbems.ts` + .test.ts
- `/Users/devs/Downloads/Apollo/apps/web/lib/compliance/prisma-flow.ts` + .test.ts
- `/Users/devs/Downloads/Apollo/apps/web/lib/compliance/spell-check.ts`
- `/Users/devs/Downloads/Apollo/apps/web/lib/compliance/data-consistency.ts`
- `/Users/devs/Downloads/Apollo/apps/web/lib/qc/final-qc.ts`

**Compute & Semaphore:**
- `/Users/devs/Downloads/Apollo/apps/web/lib/compute/semaphore.ts` + .test.ts

**Datasets:**
- `/Users/devs/Downloads/Apollo/apps/web/lib/datasets/parse.ts` + .test.ts
- `/Users/devs/Downloads/Apollo/apps/web/lib/datasets/generate.ts`

**Inngest Workflow:**
- `/Users/devs/Downloads/Apollo/apps/web/lib/inngest/client.ts`
- `/Users/devs/Downloads/Apollo/apps/web/lib/inngest/events.ts`
- `/Users/devs/Downloads/Apollo/apps/web/lib/inngest/functions/thesis-workflow.ts`
- `/Users/devs/Downloads/Apollo/apps/web/lib/inngest/functions/analysis-runner.ts`

**LaTeX Processing:**
- `/Users/devs/Downloads/Apollo/apps/web/lib/latex/assemble.ts` + .test.ts
- `/Users/devs/Downloads/Apollo/apps/web/lib/latex/compile.ts`
- `/Users/devs/Downloads/Apollo/apps/web/lib/latex/escape.ts` + .test.ts
- `/Users/devs/Downloads/Apollo/apps/web/lib/latex/front-matter.ts` + .test.ts
- `/Users/devs/Downloads/Apollo/apps/web/lib/latex/generate-tex.ts` + .test.ts
- `/Users/devs/Downloads/Apollo/apps/web/lib/latex/latex-to-tiptap.ts` + .test.ts
- `/Users/devs/Downloads/Apollo/apps/web/lib/latex/parse-log.ts` + .test.ts
- `/Users/devs/Downloads/Apollo/apps/web/lib/latex/tiptap-to-latex.ts` + .test.ts
- `/Users/devs/Downloads/Apollo/apps/web/lib/latex/validate.ts` + .test.ts
- `/Users/devs/Downloads/Apollo/apps/web/lib/latex/abbreviations.ts` + .test.ts

**Logging:**
- `/Users/devs/Downloads/Apollo/apps/web/lib/logging/logger.ts`

**Payments:**
- `/Users/devs/Downloads/Apollo/apps/web/lib/payments/razorpay.ts`
- `/Users/devs/Downloads/Apollo/apps/web/lib/payments/stripe.ts`
- `/Users/devs/Downloads/Apollo/apps/web/lib/payments/provision-licence.ts`

**Phases:**
- `/Users/devs/Downloads/Apollo/apps/web/lib/phases/constants.ts`
- `/Users/devs/Downloads/Apollo/apps/web/lib/phases/transitions.ts` + .test.ts
- `/Users/devs/Downloads/Apollo/apps/web/lib/phases/word-count-targets.ts` + .test.ts

**Preview:**
- `/Users/devs/Downloads/Apollo/apps/web/lib/preview/title-page.ts`

**R/Plumber Analysis:**
- `/Users/devs/Downloads/Apollo/apps/web/lib/r-plumber/client.ts` + .test.ts
- `/Users/devs/Downloads/Apollo/apps/web/lib/r-plumber/analysis-runner.ts` + .test.ts

**R2 Storage:**
- `/Users/devs/Downloads/Apollo/apps/web/lib/r2/client.ts`

**Supabase:**
- `/Users/devs/Downloads/Apollo/apps/web/lib/supabase/client.ts`
- `/Users/devs/Downloads/Apollo/apps/web/lib/supabase/server.ts`
- `/Users/devs/Downloads/Apollo/apps/web/lib/supabase/admin.ts`

**Synopsis:**
- `/Users/devs/Downloads/Apollo/apps/web/lib/synopsis/parser.ts`

**Types:**
- `/Users/devs/Downloads/Apollo/apps/web/lib/types/api.ts`
- `/Users/devs/Downloads/Apollo/apps/web/lib/types/database.ts`

**Utilities:**
- `/Users/devs/Downloads/Apollo/apps/web/lib/utils.ts`
- `/Users/devs/Downloads/Apollo/apps/web/lib/format.ts`

**Validation Schemas:**
- `/Users/devs/Downloads/Apollo/apps/web/lib/validation/schemas.ts`
- `/Users/devs/Downloads/Apollo/apps/web/lib/validation/abbreviation-schemas.ts`
- `/Users/devs/Downloads/Apollo/apps/web/lib/validation/analysis-schemas.ts`
- `/Users/devs/Downloads/Apollo/apps/web/lib/validation/citation-schemas.ts`
- `/Users/devs/Downloads/Apollo/apps/web/lib/validation/compliance-schemas.ts`
- `/Users/devs/Downloads/Apollo/apps/web/lib/validation/dataset-schemas.ts`
- `/Users/devs/Downloads/Apollo/apps/web/lib/validation/figure-schemas.ts`
- `/Users/devs/Downloads/Apollo/apps/web/lib/validation/payment-schemas.ts`
- `/Users/devs/Downloads/Apollo/apps/web/lib/validation/section-schemas.ts`

---

## 5. DATABASE SCHEMA (3 migrations)

**Supabase Migrations:**
- `/Users/devs/Downloads/Apollo/supabase/migrations/016_create_abbreviations.sql` - Abbreviations table
- `/Users/devs/Downloads/Apollo/supabase/migrations/017_add_rich_content_to_sections.sql` - Rich content support
- `/Users/devs/Downloads/Apollo/supabase/migrations/018_add_rows_json_to_datasets.sql` - Dataset rows JSON

---

## 6. DOCKER FILES (6 files)

- `/Users/devs/Downloads/Apollo/docker/Dockerfile.latex` - LaTeX compilation service (TeX Live 2025)
- `/Users/devs/Downloads/Apollo/docker/Dockerfile.r-plumber` - R Plumber API service (R 4.4)
- `/Users/devs/Downloads/Apollo/docker/docker-compose.yml` - Orchestration (git-push deploys to Hetzner)
- `/Users/devs/Downloads/Apollo/docker/compile.sh` - LaTeX build automation
- `/Users/devs/Downloads/Apollo/docker/plumber.R` - R API endpoints
- `/Users/devs/Downloads/Apollo/docker/watermark.sh` - PDF watermarking

---

## 7. TEMPLATE FILES (9 files)

**LaTeX Templates:**
- `/Users/devs/Downloads/Apollo/templates/main.tex` - Topic-agnostic template
- `/Users/devs/Downloads/Apollo/templates/sskm-thesis.cls` - WBUHS/Kolkata class (50+ command API)
- `/Users/devs/Downloads/Apollo/templates/ssuhs-thesis.cls` - SSUHS/Assam class (50+ command API)

**Bibliography:**
- `/Users/devs/Downloads/Apollo/templates/template-references.bib` - Sample references
- `/Users/devs/Downloads/Apollo/templates/vancouver.bst` - Vancouver style bibliography

**Logos:**
- `/Users/devs/Downloads/Apollo/templates/logo/sskm-logo.png` - SSKM logo
- `/Users/devs/Downloads/Apollo/templates/logo/ssuhs-logo.png` - SSUHS logo
- `/Users/devs/Downloads/Apollo/templates/logo/wbuhs-logo.pdf` - WBUHS logo

---

## 8. TEST FILES (32 project tests + 5 E2E)

**Unit Tests (32 files):**
- `/Users/devs/Downloads/Apollo/apps/web/lib/ai/rate-limit.test.ts`
- `/Users/devs/Downloads/Apollo/apps/web/lib/ai/redact.test.ts`
- `/Users/devs/Downloads/Apollo/apps/web/lib/citations/audit.test.ts`
- `/Users/devs/Downloads/Apollo/apps/web/lib/citations/auto-resolve.test.ts`
- `/Users/devs/Downloads/Apollo/apps/web/lib/citations/crossref.test.ts`
- `/Users/devs/Downloads/Apollo/apps/web/lib/citations/pubmed.test.ts`
- `/Users/devs/Downloads/Apollo/apps/web/lib/citations/resolve.test.ts`
- `/Users/devs/Downloads/Apollo/apps/web/lib/compliance/checker.test.ts`
- `/Users/devs/Downloads/Apollo/apps/web/lib/compliance/checklists.test.ts`
- `/Users/devs/Downloads/Apollo/apps/web/lib/compliance/nbems.test.ts`
- `/Users/devs/Downloads/Apollo/apps/web/lib/compliance/prisma-flow.test.ts`
- `/Users/devs/Downloads/Apollo/apps/web/lib/compute/semaphore.test.ts`
- `/Users/devs/Downloads/Apollo/apps/web/lib/datasets/parse.test.ts`
- `/Users/devs/Downloads/Apollo/apps/web/lib/latex/abbreviations.test.ts`
- `/Users/devs/Downloads/Apollo/apps/web/lib/latex/assemble.test.ts`
- `/Users/devs/Downloads/Apollo/apps/web/lib/latex/escape.test.ts`
- `/Users/devs/Downloads/Apollo/apps/web/lib/latex/front-matter.test.ts`
- `/Users/devs/Downloads/Apollo/apps/web/lib/latex/generate-tex.test.ts`
- `/Users/devs/Downloads/Apollo/apps/web/lib/latex/latex-to-tiptap.test.ts`
- `/Users/devs/Downloads/Apollo/apps/web/lib/latex/parse-log.test.ts`
- `/Users/devs/Downloads/Apollo/apps/web/lib/latex/tiptap-to-latex.test.ts`
- `/Users/devs/Downloads/Apollo/apps/web/lib/latex/validate.test.ts`
- `/Users/devs/Downloads/Apollo/apps/web/lib/phases/transitions.test.ts`
- `/Users/devs/Downloads/Apollo/apps/web/lib/phases/word-count-targets.test.ts`
- `/Users/devs/Downloads/Apollo/apps/web/lib/r-plumber/analysis-runner.test.ts`
- `/Users/devs/Downloads/Apollo/apps/web/lib/r-plumber/client.test.ts`

**Integration/Security Tests (6 files):**
- `/Users/devs/Downloads/Apollo/apps/web/tests/security/auth.test.ts`
- `/Users/devs/Downloads/Apollo/apps/web/tests/security/licence-gates.test.ts`
- `/Users/devs/Downloads/Apollo/apps/web/tests/security/rls.test.ts`
- `/Users/devs/Downloads/Apollo/apps/web/tests/example.test.ts`
- `/Users/devs/Downloads/Apollo/apps/web/tests/compile.test.ts`
- `/Users/devs/Downloads/Apollo/apps/web/tests/setup.ts`

**E2E Tests (5 files via Playwright):**
- `/Users/devs/Downloads/Apollo/apps/web/e2e/smoke.spec.ts`
- `/Users/devs/Downloads/Apollo/apps/web/e2e/landing.spec.ts`
- `/Users/devs/Downloads/Apollo/apps/web/e2e/analysis-run.spec.ts`
- `/Users/devs/Downloads/Apollo/apps/web/e2e/dataset-upload.spec.ts`
- `/Users/devs/Downloads/Apollo/apps/web/e2e/compliance-check.spec.ts`
- `/Users/devs/Downloads/Apollo/apps/web/tests/pipeline-e2e.test.ts`
- `/Users/devs/Downloads/Apollo/apps/web/tests/citations-e2e.test.ts`

---

## 9. CONFIG FILES

**TypeScript & Build:**
- `/Users/devs/Downloads/Apollo/apps/web/tsconfig.json`
- `/Users/devs/Downloads/Apollo/apps/web/next.config.ts`
- `/Users/devs/Downloads/Apollo/apps/web/tailwind.config.ts`
- `/Users/devs/Downloads/Apollo/apps/web/components.json` - shadcn/ui config
- `/Users/devs/Downloads/Apollo/apps/web/postcss.config.mjs`

**Testing:**
- `/Users/devs/Downloads/Apollo/apps/web/vitest.config.ts`
- `/Users/devs/Downloads/Apollo/apps/web/vitest.config.security.ts`
- `/Users/devs/Downloads/Apollo/apps/web/playwright.config.ts`

**Package Management:**
- `/Users/devs/Downloads/Apollo/apps/web/package.json`
- `/Users/devs/Downloads/Apollo/apps/web/pnpm-lock.yaml`

**Linting & Code Quality:**
- `/Users/devs/Downloads/Apollo/apps/web/eslint.config.mjs`

**Environment:**
- `/Users/devs/Downloads/Apollo/.env.example` - Root env template
- `/Users/devs/Downloads/Apollo/.env.local` - Local development env
- `/Users/devs/Downloads/Apollo/apps/web/.env.example` - App-specific env template

**Monitoring & Error Tracking:**
- `/Users/devs/Downloads/Apollo/apps/web/sentry.client.config.ts`
- `/Users/devs/Downloads/Apollo/apps/web/sentry.server.config.ts`
- `/Users/devs/Downloads/Apollo/apps/web/sentry.edge.config.ts`

---

## 10. ROOT-LEVEL INFRASTRUCTURE

**App Core:**
- `/Users/devs/Downloads/Apollo/apps/web/app/layout.tsx` - Root layout
- `/Users/devs/Downloads/Apollo/apps/web/app/(auth)/layout.tsx` - Auth group layout
- `/Users/devs/Downloads/Apollo/apps/web/app/(dashboard)/layout.tsx` - Dashboard group layout
- `/Users/devs/Downloads/Apollo/apps/web/app/globals.css` - Global styles (dot grid, halos)
- `/Users/devs/Downloads/Apollo/apps/web/app/page.tsx` - Landing page
- `/Users/devs/Downloads/Apollo/apps/web/app/icon.svg` - App icon
- `/Users/devs/Downloads/Apollo/apps/web/app/apple-icon.svg` - Apple icon

**Middleware:**
- `/Users/devs/Downloads/Apollo/apps/web/middleware.ts` - Auth, RLS, request logging

**Hooks:**
- `/Users/devs/Downloads/Apollo/apps/web/hooks/use-mobile.tsx` - Mobile detection
- `/Users/devs/Downloads/Apollo/apps/web/hooks/use-sse.ts` - Server-sent events

**PWA Assets:**
- `/Users/devs/Downloads/Apollo/apps/web/public/manifest.json` - PWA manifest
- `/Users/devs/Downloads/Apollo/apps/web/public/sw.js` - Service worker
- `/Users/devs/Downloads/Apollo/apps/web/public/icon-192.svg`
- `/Users/devs/Downloads/Apollo/apps/web/public/icon-512.svg`

**LaTeX Assets (Copied to Docker):**
- `/Users/devs/Downloads/Apollo/apps/web/sskm-thesis.cls`
- `/Users/devs/Downloads/Apollo/apps/web/ssuhs-thesis.cls`
- `/Users/devs/Downloads/Apollo/apps/web/vancouver.bst`
- `/Users/devs/Downloads/Apollo/apps/web/logo/sskm-logo.png`
- `/Users/devs/Downloads/Apollo/apps/web/logo/ssuhs-logo.png`
- `/Users/devs/Downloads/Apollo/apps/web/logo/wbuhs-logo.pdf`

---

## 11. DOCUMENTATION & GUIDANCE

**Project Documentation:**
- `/Users/devs/Downloads/Apollo/CLAUDE.md` - Project overview (THIS FILE)
- `/Users/devs/Downloads/Apollo/README.md` - Repository readme
- `/Users/devs/Downloads/Apollo/docs/PLAN.md` - Frozen architecture & design (authoritative)
- `REDACTED.md` - Sprint documentation

**Agent Guidance (Read before development):**
- `/Users/devs/Downloads/Apollo/agent-guidance/rules.md` - Development rules & file org
- `/Users/devs/Downloads/Apollo/agent-guidance/code-standards.md` - TypeScript, React, API standards
- `/Users/devs/Downloads/Apollo/agent-guidance/workflow.md` - Sprint, branching, PR process
- `/Users/devs/Downloads/Apollo/agent-guidance/lessons.md` - Known issues, debugging, pitfalls
- `/Users/devs/Downloads/Apollo/agent-guidance/mcp-servers.md` - MCP setup

**Governance:**
- `/Users/devs/Downloads/Apollo/docs/governance/data-classification.md` - Data types, retention, DPDP Act
- `/Users/devs/Downloads/Apollo/docs/governance/incident-response.md` - Incident severity & response
- `/Users/devs/Downloads/Apollo/docs/governance/security-tests.md` - CI & deploy-time security
- `/Users/devs/Downloads/Apollo/docs/governance/release-gates.md` - Sprint release gates

**References:**
- `/Users/devs/Downloads/Apollo/docs/Thesis_guidelines/Guidelines_for_preparing_MD_MS_thesis.pdf`
- `/Users/devs/Downloads/Apollo/docs/Thesis_guidelines/Thesis protocol & thesis submission_NBE guidelines.pdf`

---

## 12. CI/CD & CONFIGURATION

**GitHub Actions:**
- `/Users/devs/Downloads/Apollo/.github/workflows/ci.yml` - Test, lint, security checks

**Project Configuration:**
- `/Users/devs/Downloads/Apollo/.mcp.json` - MCP server config
- `/Users/devs/Downloads/Apollo/.gitignore` - Git ignore rules

---

## SUMMARY STATISTICS

- **Total API Routes**: 47 (GET, POST, PATCH, DELETE, etc.)
- **Total Pages**: 11 (landing, auth, dashboard, checkout, projects, etc.)
- **Total Components**: 80 (UI, landing, project, editor, wizard, etc.)
- **Total Lib Modules**: 97 files (AI, LaTeX, citations, compliance, etc.)
- **Unit Tests**: 26 test files
- **E2E Tests**: 7 test files
- **Test Coverage**: 226+ tests across 17 files, 0 TypeScript errors
- **Docker Services**: 2 (LaTeX compilation, R Plumber analysis)
- **Database Migrations**: 3
- **Template Files**: 9 (LaTeX classes, logos, bibliography)

All file paths are absolute paths from `/Users/devs/Downloads/Apollo/`.</result>
<usage>total_tokens: 52633
tool_uses: 28
duration_ms: 78176</usage>
</task-notification>
Full transcript available at: /private/tmp/claude-501/-Users-devs-Downloads-Apollo/tasks/a61aad4.output

---

<task-notification>
<task-id>a680060</task-id>
<status>completed</status>
<summary>Agent "Read full PLAN.md document" completed</summary>
<result>The file is 1155 lines and I've read it in its entirety. Let me now compile the comprehensive summary.

---

# Comprehensive Summary of Apollo PLAN.md

## 1. All 12 Phases of the GOLD Standard Methodology

The GOLD Standard is a 12-phase workflow for thesis generation. Each phase uses Inngest's `step.waitForEvent('user.approved.phase.N')` for human-in-the-loop approval gates. The section status enum follows: `draft` -> `generating` -> `review` -> `approved` (no backward transitions except via explicit "Request Revision").

| Phase | Name | Type | Description |
|-------|------|------|-------------|
| **Phase 0** | Orientation | Auto | Validate inputs, setup workspace. Synopsis must be parsed and metadata populated before advancing. |
| **Phase 1** | Front Matter | Auto | Generate from metadata form (title page, certificates, acknowledgements, etc.). Front matter must compile without blocking errors. **Active thesis license required to advance to Phase 2.** |
| **Phase 2** | Introduction | AI + Human | AI generates draft introduction, user reviews. Requires `project.status = 'licensed'`. Uses Opus model. Target: 750-1000 words. |
| **Phase 3** | Aims & Objectives | AI + Human | Extract from synopsis. AI auto-populates aims from parsed synopsis data. |
| **Phase 4** | Review of Literature (ROL) | AI + Human | Literature search + draft. Target: 3500-4000 words. |
| **Phase 5** | Materials & Methods (M&M) | AI + Human | Follow synopsis exactly. AI auto-populates skeleton and ethics statement from synopsis. |
| **Phase 6a** | Dataset | Human | Upload/verify dataset. Dataset must be uploaded and column types confirmed before advancing. |
| **Phase 6b** | Results | AI + R | Statistical analysis + draft. R execution in sandboxed Docker with parameterised Plumber API. Publication-quality figures (300 DPI PDF) auto-inserted. |
| **Phase 7** | Discussion | AI + Human | Compare results with literature. Uses Opus model. |
| **Phase 8** | Conclusion | AI + Human | Map conclusions to objectives. |
| **Phase 9** | References | Auto | Bidirectional audit + provenance check. All `\cite{key}` must have corresponding BibTeX entries. |
| **Phase 10** | Appendices | Auto + Human | Generate annexures. |
| **Phase 11** | Final QC | Auto | Formatting/citation/data verification. All Tier D citations must be resolved or removed. All phases must be approved. Includes: British English check, tense consistency, data consistency, plagiarism estimate, citation provenance verification. |

**Transition Rules:**
- `projects.current_phase` can only increment by 1 (no skipping)
- `projects.phases_completed[]` is append-only
- Phase 1 -> 2 requires active thesis license attached + identity binding
- Phase 6a -> 6b requires dataset uploaded and column types confirmed
- Phase 11 -> Completed requires all phases approved + final QC pass
- Invalid transitions return 409 Conflict
- Approve endpoint is idempotent (re-approving already-approved phase is a no-op)

**AI Model Routing:**
- **Opus**: Introduction (Phase 2), Discussion (Phase 7) - quality-critical
- **Sonnet**: All other phases
- **Haiku**: QC checks

---

## 2. All API Routes

### Project Management
| Method | Route | Purpose |
|--------|-------|---------|
| `POST` | `/api/projects` | Create project (sandbox status) |
| `GET` | `/api/projects` | List user's projects |
| `GET` | `/api/projects/:id` | Get project + status + license info |
| `PATCH` | `/api/projects/:id` | Update metadata (locked fields after Phase 1 if licensed) |
| `DELETE` | `/api/projects/:id` | Soft-delete (retain 30 days) |

### Thesis Licenses
| Method | Route | Purpose |
|--------|-------|---------|
| `GET` | `/api/licenses` | List user's licenses |
| `POST` | `/api/licenses/:lid/attach/:pid` | Attach license to project (binds identity) |
| `POST` | `/api/licenses/:lid/transfer` | Transfer license to new project (max 1 per 6mo) |

### Sections
| Method | Route | Purpose |
|--------|-------|---------|
| `GET` | `/api/projects/:id/sections` | List all sections |
| `GET` | `/api/projects/:id/sections/:phase` | Get section content |
| `PUT` | `/api/projects/:id/sections/:phase` | Update section content |
| `POST` | `/api/projects/:id/sections/:phase/generate` | AI generation (SSE; Phase 2+ requires license) |
| `POST` | `/api/projects/:id/sections/:phase/approve` | Approve phase (Phase 1->2 requires license) |

### Compilation
| Method | Route | Purpose |
|--------|-------|---------|
| `POST` | `/api/projects/:id/compile` | Trigger LaTeX compilation |
| `GET` | `/api/projects/:id/compilations` | List compilation history |
| `GET` | `/api/projects/:id/preview.pdf` | Get latest PDF (signed URL) |

### Statistical Analysis
| Method | Route | Purpose |
|--------|-------|---------|
| `POST` | `/api/projects/:id/datasets` | Upload dataset |
| `POST` | `/api/projects/:id/analyses` | Run analysis |
| `GET` | `/api/projects/:id/analyses/:aid` | Get results + figures |

### Citations
| Method | Route | Purpose |
|--------|-------|---------|
| `GET` | `/api/projects/:id/citations` | List citations |
| `POST` | `/api/projects/:id/citations` | Add citation (DOI/PMID lookup) |
| `POST` | `/api/projects/:id/citations/audit` | Bidirectional integrity check |
| `GET` | `/api/citations/search?q=` | Search PubMed/CrossRef |

### Figures
| Method | Route | Purpose |
|--------|-------|---------|
| `POST` | `/api/projects/:id/figures` | Upload figure |
| `POST` | `/api/projects/:id/figures/mermaid` | Generate from Mermaid syntax |
| `GET` | `/api/projects/:id/figures` | List figures |
| `DELETE` | `/api/projects/:id/figures/:fid` | Remove figure |

### Compliance
| Method | Route | Purpose |
|--------|-------|---------|
| `GET` | `/api/projects/:id/compliance` | Dashboard status |
| `POST` | `/api/projects/:id/compliance/check` | Run guideline check |

### Export
| Method | Route | Purpose |
|--------|-------|---------|
| `GET` | `/api/projects/:id/export/pdf` | Thesis PDF (signed URL) |
| `GET` | `/api/projects/:id/export/docx` | DOCX via pandoc (signed URL) |
| `GET` | `/api/projects/:id/export/source` | All source files (.zip, signed URL) |
| `GET` | `/api/projects/:id/export/stats` | R scripts + dataset (.zip, signed URL) |

### Other Implied Routes
| Method | Route | Purpose |
|--------|-------|---------|
| `POST` | `/api/projects/:id/share` | Share project with supervisor (checks license plan_type) |
| Webhooks | Razorpay/Stripe webhooks | Payment -> license provisioning |

### Entitlement Gates per Endpoint
| Endpoint | Gate |
|----------|------|
| `POST /api/projects` | Freely allowed, creates `sandbox` status |
| `POST /.../sections/:phase/generate` (Phase 0-1) | Allowed in sandbox |
| `POST /.../sections/:phase/approve` (Phase 1->2) | Requires active license + identity binding |
| `POST /.../sections/:phase/generate` (Phase 2+) | Requires `project.status = 'licensed'` |
| `POST /.../compile` | Sandbox: watermarked PDF. Licensed: clean PDF |
| `GET /.../export/*` | Blocked without active license (402) |
| Supervisor sharing | Requires Professional Monthly, One-Time, or Institutional license |

### API Error Response Schema
Standard JSON envelope: `{ "error": { "code", "message", "action", "details" } }`

Standard error codes: `VALIDATION_ERROR` (400), `UNAUTHENTICATED` (401), `LICENSE_REQUIRED` (402), `FORBIDDEN` (403), `NOT_FOUND` (404), `INVALID_TRANSITION` (409), `ALREADY_ATTACHED` (409), `RATE_LIMITED` (429), `QUEUE_FULL` (429), `INTERNAL_ERROR` (500), `SERVICE_UNAVAILABLE` (503).

---

## 3. All Database Tables/Schema

### `organisations`
- `id`, `name`, `university_type`, `cls_config_json`, `logo_urls`, `created_at`

### `users`
- `id`, `supabase_auth_id`, `email`, `name`, `role`, `organisation_id`, `created_at`

### `thesis_licenses`
- `id`, `user_id`, `project_id` (UNIQUE, null until attached)
- `plan_type`: `'student_monthly'` | `'professional_monthly'` | `'addon'` | `'one_time'` | `'institutional'`
- `status`: `'available'` | `'active'` | `'expired'` | `'transferred'`
- `candidate_name_hash` (SHA-256), `registration_no_hash` (SHA-256), `university` (plain text), `guide_name_hash` (SHA-256)
- `identity_locked_at` (immutable once set, DB trigger enforced)
- `activated_at`, `expires_at`
- `transfer_count`, `last_transferred_at` (DB trigger rejects if < 6 months since last transfer)
- `created_at`

### `projects`
- `id`, `user_id`, `organisation_id`
- `status`: `'sandbox'` | `'licensed'` | `'completed'` | `'archived'`
- `license_id` (FK to thesis_licenses, UNIQUE; null = sandbox)
- `title`, `synopsis_text`, `study_type`, `university_type`
- `metadata_json` (candidate_name, guide_name, hod_name, etc.)
- `current_phase`, `phases_completed[]`
- `created_at`, `updated_at`

### `sections`
- `id`, `project_id`, `phase_number`, `phase_name`
- `latex_content`, `word_count`, `citation_keys[]`
- `status` (enum: `draft` -> `generating` -> `review` -> `approved`)
- `ai_conversation_id`
- `created_at`, `updated_at`

### `citations`
- `id`, `project_id`, `cite_key`, `bibtex_entry`
- `provenance_tier`: `'A'` | `'B'` | `'C'` | `'D'`
- `evidence_type`: `'doi'` | `'pmid'` | `'isbn'` | `'url'` | `'manual'` | `null` (Tier D)
- `evidence_value` (DOI string, PMID, ISBN, URL, or free-text)
- `source_doi`, `source_pmid` (convenience fields for Tier A, indexed for dedup)
- `attested_by_user_id` (null for Tier A, set for Tier B/C)
- `attested_at` (timestamp of student attestation)
- `used_in_sections[]`, `serial_number`
- `verified_at` (set when Tier A auto-verification succeeds)
- `created_at`

### `datasets`
- `id`, `project_id`, `file_url`, `row_count`, `columns_json`, `created_at`

### `analyses`
- `id`, `project_id`, `dataset_id`, `analysis_type`
- `parameters_json`, `results_json`, `figures_urls[]`
- `r_script`, `status`, `created_at`

### `figures`
- `id`, `project_id`, `section_id`, `figure_type`
- `source_tool`: `'ggplot2'` | `'mermaid'` | `'tikz'` | `'upload'`
- `source_code`, `file_url`, `caption`, `label`
- `width_pct`, `dpi`, `format`, `created_at`

### `compliance_checks`
- `id`, `project_id`, `guideline_type`: `'CONSORT'` | `'STROBE'` | `'PRISMA'` | `'STARD'` | `'CARE'`
- `checklist_json` (array of `{item_id, description, status, section_ref, suggestion}`)
- `overall_score`, `last_checked_at`

### `compilations`
- `id`, `project_id`, `trigger`, `status`
- `pdf_url`, `log_text`, `warnings[]`, `errors[]`
- `compile_time_ms`, `created_at`

### `ai_conversations`
- `id`, `project_id`, `phase_number`
- `messages_json[]`, `model_used`, `total_tokens`
- `created_at`

### `audit_log`
- `id`, `user_id`, `project_id`, `action`, `entity_type`, `entity_id`
- `old_value_json`, `new_value_json`, `ip_address`
- `created_at`

### `processed_webhooks` (implied by payment webhook hardening)
- Stores provider event IDs for idempotency

### Schema Migration Rules
- All migrations non-destructive (never DROP in production)
- Every migration includes rollback comment block
- New columns must have defaults or be nullable
- Test against production data snapshot before deploy

---

## 4. All UI Pages/Components

### Authentication
- Sign-up page with email/password + Google OAuth
- Sign-in page
- Consent screen at registration (data collection disclosure)

### Landing Page
- Hero section
- Features section (cursor-tracking sage glow)
- How It Works section
- Pricing section (cursor-tracking amber glow)
- Testimonials section
- CTA section
- FAQ section
- Footer section
- Sponsors section (marquee)

### Dashboard Layout
- Glass sidebar (floating pill collapsed, frosted glass strip)
- Dashboard header (glass header)
- Sidebar spacer
- Dot grid background

### Dashboard Pages
- **Dashboard home** (`/dashboard`): Serif headings, brand font, zen pill buttons
- **Projects list** (`/projects`): ProjectCard with cursor-tracking sage glow, TemplateGallery (6 study types)
- **Project detail** (`/projects/[id]`): Metadata panel with landing-card halo
- **Project workspace** (`/projects/[id]`): Editor/PDF panels with landing-card-elevated
- **Checkout** (`/checkout`): Payment flow
- **Licences** (`/licences`): License management

### Project Workspace Components
- **Pipeline timeline**: 12-phase stepper with short labels, flex-1 lines, 3-tier dot hierarchy (current/completed/future), quality gate status (green/yellow/red)
- **Novel editor** (rich text): Tiptap-based WYSIWYG with slash commands, "Add Citation", "Add Table", "Add Figure" buttons
- **CodeMirror LaTeX source view**: Advanced toggle, syntax highlighting, folding, autocomplete
- **PDF viewer** (react-pdf): Split-pane layout, text selection, zoom
- **AI generate button**: "Generate Draft" per phase, SSE streaming, actions: Regenerate, Expand, Condense, Add Citations
- **Citation list panel**: Provenance badges (green=A, amber=B/C, red=D)
- **Compile button**: One-click compile
- **Word count tracker**: Per chapter with target ranges
- **Thesis completion component**

### Setup Wizard (5 Steps)
1. Select university (WBUHS/SSUHS/Generic) -> loads CLS + logos
2. Upload synopsis (PDF/text) -> AI parses: title, PICO, study design, sample size, methods, stats plan, ethics
3. Review auto-populated data; fill personal details (name, guide, HOD, registration)
4. Optional: upload dataset (CSV/Excel) -> auto-detect column types
5. Generate front matter -> compile -> PDF preview

### Citation Management UI
- PubMed/CrossRef search + insert in editor
- Provenance badge display: green (Tier A), amber (Tier B/C), red (Tier D)
- "Confirm Source" / "Add Manually" / "Remove" options for unverified citations
- Bidirectional integrity checker view

### Statistical Analysis UI
- Dataset upload + column detection
- Analysis wizard: select variables, test type, significance level
- Results with figures display

### Figure Management
- Upload figure (PNG/PDF) with caption editor
- Mermaid diagram editor (CONSORT flowcharts)
- Subfigure support

### Compliance Dashboards
- CONSORT (RCTs): 25-item checklist
- STROBE (Observational): 22-item checklist
- PRISMA (Systematic Reviews): 27-item checklist + auto-generated Mermaid flow diagram
- STARD (Diagnostic Accuracy): 30-item checklist
- CARE (Case Reports): 13-item checklist
- NBEMS compliance checker (80-page max, 300-word abstract limit, PICO elements, 12 mandatory sections)
- Items mapped to sections with "Fix" suggestions

### Abbreviation Management UI
- Add, edit, delete abbreviations
- Auto-generates `\begin{abbreviations}` longtable
- Cross-check warnings (used but not listed, listed but not used)

### Export UI
- Download thesis PDF
- DOCX export with pre-download fidelity warning notice
- Download source files (.tex, .bib, .cls, .bst, figures)
- Download R scripts + dataset + stats report
- Version history (all compilations preserved)

### Supervisor Collaboration (Sprint 9-10, Minimal)
- Read-only dashboard: phase progress and word counts
- Per-section threaded text comments (no inline annotations, no track changes)
- Phase approval button
- DOCX export for offline review

### PWA Components (Sprint 9-10)
- PWA manifest + service worker + add-to-home-screen
- Three mobile-optimised pages: **Dashboard** (phase stepper + word counts), **AI Chat** (generation + review), **PDF Preview** (full-screen viewer)
- "Share via WhatsApp" for thesis PDF
- Web Push notifications (Android Chrome)
- Bottom nav bar, touch-friendly controls

### Auth 3D Scene
- `auth-3d-scene-loader.tsx`
- `auth-3d-scene.tsx`

---

## 5. All Docker/Infrastructure Requirements

### VPS: Hetzner CX23
- 2 vCPU, 4GB RAM, 40GB NVMe SSD
- ~$4/month
- Managed by Coolify (docker-compose, git-push deploys)
- Let's Encrypt SSL via nginx reverse proxy

### Docker Containers

#### Next.js App + API
- Next.js 15 (App Router)
- Serves both web app and API routes
- RAM: 400MB baseline, CPU: 0.2 baseline

#### LaTeX Service (`docker/Dockerfile.latex`)
- TeX Live 2025 in Docker
- REST API for compilation
- **Isolation**: Read-only filesystem except `/tmp`, no network access (`--network=none`), 120-second timeout, 1GB memory limit, Linux seccomp profiles
- Compile cycle: `pdflatex -> bibtex -> pdflatex -> pdflatex`
- RAM per job: 800MB, CPU per job: 1.0

#### R Plumber Service (`docker/Dockerfile.r-plumber`)
- R 4.4 + Plumber API
- Parameterised endpoints only (no raw code execution)
- **Isolation**: Same as LaTeX, AppArmor profiles, no `system()` calls
- RAM per job: 300-500MB (depends on analysis type), CPU per job: 0.4-0.6

#### nginx Reverse Proxy
- Let's Encrypt SSL
- RAM: 50MB, CPU: 0.01

#### Inngest Worker
- Durable 12-phase pipeline
- `step.waitForEvent` for human-in-the-loop gates
- RAM: 150MB, CPU: 0.1

### Docker Compose (`docker/docker-compose.yml`)
- Orchestrates all containers
- Compile script (`docker/compile.sh`)
- R Plumber script (`docker/plumber.R`)

### Admission Control (Global Semaphore)
- Shared semaphore tracks active compute slots
- Slot costs: compile = 2 units, analysis = 1 unit, max = 3 units
- Max concurrent: 1 compile + 1 analysis (2+1=3), or 3 analyses, or 1 compile alone
- Never 2 compiles simultaneously
- Queue depths: compile queue = 5, analysis queue = 5, AI generation queue = 10
- Queue full returns 429

### Runtime Limits per R Analysis
| Analysis Type | Timeout | Max RAM |
|--------------|---------|---------|
| Descriptive | 15s | 200MB |
| Chi-square/Fisher/t-test | 30s | 300MB |
| Survival/Kaplan-Meier | 45s | 400MB |
| ROC/Logistic | 45s | 400MB |
| Meta-analysis | 60s | 500MB |

### External Services
- **Supabase Free Tier**: PostgreSQL + Auth (50K MAU free) + Realtime + RLS. Region: ap-south-1 (Mumbai)
- **Cloudflare R2 Free Tier**: Zero egress, 10GB free, S3-compatible, signed URLs. Signed PUT URLs: 5min expiry. Signed GET URLs: 15min expiry
- **Claude API**: Sonnet 4.5 (primary), Opus 4.5 (quality-critical), Haiku (QC). Prompt caching (60-70% savings)
- **Resend**: Transactional email (3K/month free) with React Email templates
- **Sentry**: Error tracking (5K errors/month free, `tracesSampleRate: 0.2` in prod)
- **PostHog**: Product analytics (1M events/month free, capture only key events)
- **Razorpay**: India payments
- **Stripe**: International payments
- **Betterstack**: Uptime monitoring (free)

### Backup Strategy
| Data | Method | Frequency | Retention |
|------|--------|-----------|-----------|
| Supabase PostgreSQL | Supabase built-in daily backups | Daily | 7 days |
| Cloudflare R2 objects | `rclone sync` to Hetzner Storage Box (BX11, ~$4/mo) | Weekly | 2 most recent copies |
| VPS configuration | Git repository | Every deploy | Git history |
| Secrets | Coolify env vars + 1Password vault | On change | N/A |

### CI/CD
- GitHub Actions -> Coolify webhook deploy
- Docker build + push to Hetzner
- Pipeline: lint + type-check + build + security tests + compile test + citation audit + Playwright + schema migration test

### Scale-up Path
1. **First**: CX23 -> CX33 (8GB RAM, 4 vCPU, ~$7/mo) when >20% of requests hit 429
2. **Later**: Add Vercel Pro ($20/mo) for Next.js frontend only at 200+ active users

---

## 6. Other Key Implementation Details

### Security
- **RLS on every table**: `user_id = auth.uid()` or organisation membership
- **Roles**: Student (own projects), Supervisor (read students in org), Admin (full org access)
- **File access**: All via time-limited signed URLs, no public bucket access
- **Upload validation**: File type whitelist (PDF, CSV, XLSX, PNG, JPG only), max 50MB, ClamAV virus scan
- **Rate limiting**: `@upstash/ratelimit` - 10 AI generations/hour (Student), 30/hour (Professional)
- **Token budgets**: Max 100K output tokens per phase, max 1.2M total tokens per thesis
- **Pre-prompt PII redaction gate**: Regex-based, mandatory in middleware before Claude API calls. Detects Indian phone numbers, Aadhaar, emails, names, DOBs. Replaces with `[PHONE_REDACTED]`, etc.

### Payment Webhook Hardening
- Signature verification (HMAC-SHA256 for Razorpay, `stripe.webhooks.constructEvent` for Stripe)
- Idempotency via `processed_webhooks` table using provider event ID
- Replay protection: Razorpay rejects >5min stale; Stripe relies on signature + idempotency only
- Atomic license provisioning: payment confirmed -> insert `thesis_licenses` -> return 200

### University Template System
- Two CLS files: `sskm-thesis.cls` (WBUHS) and `ssuhs-thesis.cls` (SSUHS)
- Harmonised 50+ command API
- Switching requires only changing `\documentclass`
- **Never use `\def\@variable`** - use `\renewcommand` pattern
- Vancouver BST for bibliography style

### Compile Success Criteria
- **Blocking**: Missing packages, syntax errors, undefined control sequences, undefined `\ref{}` targets
- **Tolerated (budget <= 20)**: Overfull/underfull hbox, font substitution, float positioning
- **Ignored**: Package-specific noise (hyperref anchors, microtype warnings)

### Citation Provenance Pipeline
- AI generates `\cite{key}` -> system attempts DOI/PMID lookup (Tier A) -> if found, auto-insert with `verified_at` set
- If lookup fails: shown with warning, student can confirm (Tier B: ISBN/URL) or add manually (Tier C)
- Tier D (unresolvable): never emitted as `\cite{key}` in LaTeX source, shown with red badge, blocks only at Final QC (Phase 11)
- Every `\cite{key}` MUST have corresponding BibTeX entry (enforced by construction)

### AI Quality Rubric
| Check | Method | Threshold |
|-------|--------|-----------|
| Citation provenance | Tier classification | 0 Tier D at Final QC |
| Section completeness | Word count | Introduction: 750-1000, ROL: 3500-4000 |
| British English | Spell-check | 0 American spellings |
| Tense consistency | NLP detection | Intro/ROL: present, M&M/Results: past |
| Hallucination detection | Cross-reference against cited papers | Flag unsupported claims |
| Data consistency | Cross-section comparison | Numbers match across Abstract/Results/Discussion |
| Plagiarism estimate | n-gram similarity | Warn if >10% |

### SLOs
| Metric | Target |
|--------|--------|
| LaTeX compile latency | p95 < 60s |
| AI generation first-token | p95 < 3s |
| AI generation throughput | p95 < 120s per phase |
| R analysis latency | p95 < 30s |
| API response (non-compute) | p95 < 500ms |
| Uptime | 99.5% monthly |
| PDF signed URL generation | p95 < 200ms |
| Error budget | < 0.5% 5xx |

### Data Classification & Retention
| Data Type | Retention |
|-----------|-----------|
| User PII | Account lifetime + 30 days |
| Synopsis/Thesis content | Project lifetime + 90 days |
| Dataset (patient data) | Project lifetime only, immediate delete |
| AI conversations | 90 days after completion |
| Audit logs | 2 years |
| Compiled PDFs | Project lifetime + 30 days |
| Payment records | 7 years (legal) |

### Reporting Guidelines Supported
- CONSORT (RCTs): 25-item checklist
- STROBE (Observational): 22-item checklist
- PRISMA (Systematic Reviews): 27-item checklist + Mermaid flow diagram
- STARD (Diagnostic Accuracy): 30-item checklist
- CARE (Case Reports): 13-item checklist
- NBEMS compliance: 80-page max (Intro to Conclusion), 300-word abstract, PICO elements, 12 mandatory sections
- UGC compliance: <10% plagiarism similarity target

### Statistical Analysis Types
- **Sprint 7**: Descriptive stats (gtsummary), chi-square/Fisher's exact, t-test/Mann-Whitney (auto-selected by Shapiro-Wilk), correlation (Pearson/Spearman), survival/Kaplan-Meier
- **Sprint 8**: ROC curves, logistic regression, Kruskal-Wallis, meta-analysis (forest/funnel plots via metafor/meta)

### Figure Generation Engines
- **ggplot2** (R): Statistical figures
- **Mermaid** (text-to-diagram): CONSORT flowcharts, study design diagrams
- **TikZ** (LaTeX-native): Font-matched flowcharts; tikzDevice for ggplot2 -> TikZ
- **Upload**: Manual PNG/PDF with caption editor
- Subfigure support via `subcaption`, min 300 DPI

### Export Formats
- **PDF**: Primary deliverable, pixel-perfect
- **DOCX**: Via pandoc, limited fidelity (supported: body text, headings, inline citations, simple tables, figures; degraded: longtables, subfigures, landscape; unsupported: TikZ diagrams, page-level formatting)
- **Source files**: .tex, .bib, .cls, .bst, figures (.zip)
- **Stats**: R scripts + dataset (.zip)

### Pricing Tiers
| Tier | Price | Licenses |
|------|-------|----------|
| Free Trial | 7 days | 0 (sandbox only) |
| Student Monthly | INR 2,499/mo | 1 active thesis |
| Professional Monthly | INR 4,999/mo | 1 active thesis + supervisor features |
| Extra License Add-on | INR 4,999 one-time | +1 thesis |
| One-Time Thesis | INR 14,999 | 1 thesis, 6-month validity |
| Institutional | INR 1,999/student/semester | 1 per student |

### Sprint Roadmap Summary
- **Sprint 0**: Dev rules, governance docs, CI pipeline
- **Sprint 1-2**: Foundation, setup wizard, license system, Supabase schema, Hetzner+Coolify
- **Sprint 3-4**: LaTeX/R Docker containers, Inngest workflow, Novel editor, CodeMirror, word counts, abbreviations
- **Sprint 5-6**: Claude API integration, SSE streaming, citation provenance pipeline, PubMed/CrossRef search, rate limiting
- **Sprint 7**: Compliance dashboards, PDF preview, dataset upload + core R analyses (descriptive, inferential, survival)
- **Sprint 8**: Advanced R analyses (ROC, logistic, Kruskal-Wallis, meta-analysis), observability, PII scrubbing
- **Sprint 9-10**: Razorpay/Stripe payments, export endpoints, DOCX, supervisor dashboard, PWA, landing page, launch
- **Post-MVP A**: Flutter app, PaperBanana, plagiarism pre-check, additional university CLS files
- **Post-MVP B**: DNB workflow, full collaboration, HOD dashboard, Zotero, version history, WhatsApp Business API

### Observability
- **Sentry**: Transaction traces with custom spans for Claude API, compile, R analysis. `beforeSend` strips PII
- **Structured logging**: JSON to stdout, searchable by `project_id`, `user_id`, `phase`
- **Inngest dashboard**: Workflow monitoring, step durations, failure replay
- **PostHog**: Product analytics, key events only (project_created, phase_approved, compile_triggered, export_downloaded, payment_completed)
- **Alerts**: Compile error rate >10%/hr, AI timeout >5min, R analysis failure, Supabase connection errors

### Key Files to Reuse
| File | Purpose |
|------|---------|
| `templates/sskm-thesis.cls` | WBUHS class, copy to Docker image |
| `templates/ssuhs-thesis.cls` | SSUHS class, copy to Docker image |
| `templates/vancouver.bst` | Vancouver BST, copy to Docker image |
| `templates/main.tex` | Template for new projects |
| `templates/logo/*.png/pdf` | University logos, upload to R2 |
| `guides/GOLD_Standard_Phased_Plan.md` | Encode as AI system prompt per phase |
| `guides/lessons_learned.md` | Encode as QC rules |
| `scripts/analysis.R` | Reference for R analysis endpoints |</result>
<usage>total_tokens: 46359
tool_uses: 1
duration_ms: 189741</usage>
</task-notification>
Full transcript available at: /private/tmp/claude-501/-Users-devs-Downloads-Apollo/tasks/a680060.output

---

<task-notification>
<task-id>a517ad3</task-id>
<status>completed</status>
<summary>Agent "Read database schema from PLAN" completed</summary>
<result>Now I have all the information needed. Let me compile the comprehensive report.

---

# Complete PLAN.md Extraction and Migration Comparison Report

## 1. COMPLETE DATABASE SCHEMA (from PLAN.md)

### Table: `organisations`
| Column | Type (inferred) | Constraints |
|--------|----------------|-------------|
| `id` | UUID PK | |
| `name` | TEXT | NOT NULL |
| `university_type` | TEXT | CHECK IN ('wbuhs', 'ssuhs', 'generic') |
| `cls_config_json` | JSONB | DEFAULT '{}' |
| `logo_urls` | JSONB | DEFAULT '{}' |
| `created_at` | TIMESTAMPTZ | DEFAULT now() |

### Table: `users`
| Column | Type (inferred) | Constraints |
|--------|----------------|-------------|
| `id` | UUID PK | |
| `supabase_auth_id` | TEXT | (plan says `supabase_auth_id`) |
| `email` | TEXT | NOT NULL |
| `name` | TEXT | |
| `role` | TEXT | |
| `organisation_id` | UUID FK | REFERENCES organisations(id) |
| `created_at` | TIMESTAMPTZ | |

### Table: `thesis_licenses`
| Column | Type (inferred) | Constraints |
|--------|----------------|-------------|
| `id` | UUID PK | |
| `user_id` | UUID FK | REFERENCES users(id) |
| `project_id` | UUID FK | UNIQUE, REFERENCES projects(id), nullable |
| `plan_type` | TEXT | CHECK IN ('student_monthly', 'professional_monthly', 'addon', 'one_time', 'institutional') |
| `status` | TEXT | CHECK IN ('available', 'active', 'expired', 'transferred') |
| `candidate_name_hash` | TEXT | SHA-256 |
| `registration_no_hash` | TEXT | SHA-256 |
| `university` | TEXT | plain text |
| `guide_name_hash` | TEXT | SHA-256 |
| `identity_locked_at` | TIMESTAMPTZ | immutable once set |
| `activated_at` | TIMESTAMPTZ | |
| `expires_at` | TIMESTAMPTZ | |
| `transfer_count` | INTEGER | DEFAULT 0 |
| `last_transferred_at` | TIMESTAMPTZ | trigger rejects if < 6 months |
| `created_at` | TIMESTAMPTZ | |

### Table: `projects`
| Column | Type (inferred) | Constraints |
|--------|----------------|-------------|
| `id` | UUID PK | |
| `user_id` | UUID FK | REFERENCES users(id) |
| `organisation_id` | UUID FK | REFERENCES organisations(id) |
| `status` | TEXT | CHECK IN ('sandbox', 'licensed', 'completed', 'archived') |
| `license_id` | UUID FK UNIQUE | REFERENCES thesis_licenses(id) |
| `title` | TEXT | |
| `synopsis_text` | TEXT | |
| `study_type` | TEXT | |
| `university_type` | TEXT | |
| `metadata_json` | JSONB | candidate_name, guide_name, hod_name, etc. |
| `current_phase` | INTEGER | |
| `phases_completed` | INTEGER[] | |
| `created_at` | TIMESTAMPTZ | |
| `updated_at` | TIMESTAMPTZ | |

### Table: `sections`
| Column | Type (inferred) | Constraints |
|--------|----------------|-------------|
| `id` | UUID PK | |
| `project_id` | UUID FK | REFERENCES projects(id) |
| `phase_number` | INTEGER | |
| `phase_name` | TEXT | |
| `latex_content` | TEXT | |
| `word_count` | INTEGER | |
| `citation_keys` | TEXT[] | |
| `status` | TEXT | CHECK IN ('draft', 'generating', 'review', 'approved') |
| `ai_conversation_id` | UUID FK | |
| `created_at` | TIMESTAMPTZ | |
| `updated_at` | TIMESTAMPTZ | |

### Table: `citations`
| Column | Type (inferred) | Constraints |
|--------|----------------|-------------|
| `id` | UUID PK | |
| `project_id` | UUID FK | REFERENCES projects(id) |
| `cite_key` | TEXT | |
| `bibtex_entry` | TEXT | |
| `provenance_tier` | TEXT | CHECK IN ('A', 'B', 'C', 'D') |
| `evidence_type` | TEXT | CHECK IN ('doi', 'pmid', 'isbn', 'url', 'manual', null) |
| `evidence_value` | TEXT | |
| `source_doi` | TEXT | indexed for dedup |
| `source_pmid` | TEXT | indexed for dedup |
| `attested_by_user_id` | UUID FK | |
| `attested_at` | TIMESTAMPTZ | |
| `used_in_sections` | TEXT[] | |
| `serial_number` | INTEGER | |
| `verified_at` | TIMESTAMPTZ | |
| `created_at` | TIMESTAMPTZ | |

### Table: `datasets`
| Column | Type (inferred) | Constraints |
|--------|----------------|-------------|
| `id` | UUID PK | |
| `project_id` | UUID FK | REFERENCES projects(id) |
| `file_url` | TEXT | |
| `row_count` | INTEGER | |
| `columns_json` | JSONB | |
| `created_at` | TIMESTAMPTZ | |

### Table: `analyses`
| Column | Type (inferred) | Constraints |
|--------|----------------|-------------|
| `id` | UUID PK | |
| `project_id` | UUID FK | REFERENCES projects(id) |
| `dataset_id` | UUID FK | REFERENCES datasets(id) |
| `analysis_type` | TEXT | |
| `parameters_json` | JSONB | |
| `results_json` | JSONB | |
| `figures_urls` | TEXT[] | |
| `r_script` | TEXT | |
| `status` | TEXT | |
| `created_at` | TIMESTAMPTZ | |

### Table: `figures`
| Column | Type (inferred) | Constraints |
|--------|----------------|-------------|
| `id` | UUID PK | |
| `project_id` | UUID FK | REFERENCES projects(id) |
| `section_id` | UUID FK | REFERENCES sections(id) |
| `figure_type` | TEXT | |
| `source_tool` | TEXT | CHECK IN ('ggplot2', 'mermaid', 'tikz', 'upload') |
| `source_code` | TEXT | |
| `file_url` | TEXT | |
| `caption` | TEXT | |
| `label` | TEXT | |
| `width_pct` | INTEGER | |
| `dpi` | INTEGER | |
| `format` | TEXT | |
| `created_at` | TIMESTAMPTZ | |

### Table: `compliance_checks`
| Column | Type (inferred) | Constraints |
|--------|----------------|-------------|
| `id` | UUID PK | |
| `project_id` | UUID FK | REFERENCES projects(id) |
| `guideline_type` | TEXT | CHECK IN ('CONSORT', 'STROBE', 'PRISMA', 'STARD', 'CARE') |
| `checklist_json` | JSONB | array of {item_id, description, status, section_ref, suggestion} |
| `overall_score` | NUMERIC | |
| `last_checked_at` | TIMESTAMPTZ | |

### Table: `compilations`
| Column | Type (inferred) | Constraints |
|--------|----------------|-------------|
| `id` | UUID PK | |
| `project_id` | UUID FK | REFERENCES projects(id) |
| `trigger` | TEXT | |
| `status` | TEXT | |
| `pdf_url` | TEXT | |
| `log_text` | TEXT | |
| `warnings` | TEXT[] | |
| `errors` | TEXT[] | |
| `compile_time_ms` | INTEGER | |
| `created_at` | TIMESTAMPTZ | |

### Table: `ai_conversations`
| Column | Type (inferred) | Constraints |
|--------|----------------|-------------|
| `id` | UUID PK | |
| `project_id` | UUID FK | REFERENCES projects(id) |
| `phase_number` | INTEGER | |
| `messages_json` | JSONB[] | |
| `model_used` | TEXT | |
| `total_tokens` | INTEGER | |
| `created_at` | TIMESTAMPTZ | |

### Table: `audit_log`
| Column | Type (inferred) | Constraints |
|--------|----------------|-------------|
| `id` | UUID PK | |
| `user_id` | UUID FK | REFERENCES users(id) |
| `project_id` | UUID FK | REFERENCES projects(id) |
| `action` | TEXT | |
| `entity_type` | TEXT | |
| `entity_id` | UUID | |
| `old_value_json` | JSONB | |
| `new_value_json` | JSONB | |
| `ip_address` | INET | |
| `created_at` | TIMESTAMPTZ | |

### RLS Policies (from PLAN.md -- general description)
- Every table has RLS enabled
- `user_id = auth.uid()` or organisation membership check
- Roles: Student (own projects), Supervisor (read students in org), Admin (full org access)

---

## 2. ALL API ROUTES (from PLAN.md)

### Project Management
| Method | Route | Description |
|--------|-------|-------------|
| `POST` | `/api/projects` | Create project (sandbox status) |
| `GET` | `/api/projects` | List user's projects |
| `GET` | `/api/projects/:id` | Get project + status + license info |
| `PATCH` | `/api/projects/:id` | Update metadata (locked fields after Phase 1 if licensed) |
| `DELETE` | `/api/projects/:id` | Soft-delete (retain 30 days) |

### Thesis Licenses
| Method | Route | Description |
|--------|-------|-------------|
| `GET` | `/api/licenses` | List user's licenses |
| `POST` | `/api/licenses/:lid/attach/:pid` | Attach license to project |
| `POST` | `/api/licenses/:lid/transfer` | Transfer license to new project |

### Sections
| Method | Route | Description |
|--------|-------|-------------|
| `GET` | `/api/projects/:id/sections` | List all sections |
| `GET` | `/api/projects/:id/sections/:phase` | Get section content |
| `PUT` | `/api/projects/:id/sections/:phase` | Update section content |
| `POST` | `/api/projects/:id/sections/:phase/generate` | AI generation (SSE; Phase 2+ requires license) |
| `POST` | `/api/projects/:id/sections/:phase/approve` | Approve phase |

### Compilation
| Method | Route | Description |
|--------|-------|-------------|
| `POST` | `/api/projects/:id/compile` | Trigger LaTeX compilation |
| `GET` | `/api/projects/:id/compilations` | List compilation history |
| `GET` | `/api/projects/:id/preview.pdf` | Get latest PDF (signed URL) |

### Statistical Analysis
| Method | Route | Description |
|--------|-------|-------------|
| `POST` | `/api/projects/:id/datasets` | Upload dataset |
| `POST` | `/api/projects/:id/analyses` | Run analysis |
| `GET` | `/api/projects/:id/analyses/:aid` | Get results + figures |

### Citations
| Method | Route | Description |
|--------|-------|-------------|
| `GET` | `/api/projects/:id/citations` | List citations |
| `POST` | `/api/projects/:id/citations` | Add citation (DOI/PMID lookup) |
| `POST` | `/api/projects/:id/citations/audit` | Bidirectional integrity check |
| `GET` | `/api/citations/search?q=` | Search PubMed/CrossRef |

### Figures
| Method | Route | Description |
|--------|-------|-------------|
| `POST` | `/api/projects/:id/figures` | Upload figure |
| `POST` | `/api/projects/:id/figures/mermaid` | Generate from Mermaid syntax |
| `GET` | `/api/projects/:id/figures` | List figures |
| `DELETE` | `/api/projects/:id/figures/:fid` | Remove figure |

### Compliance
| Method | Route | Description |
|--------|-------|-------------|
| `GET` | `/api/projects/:id/compliance` | Dashboard status |
| `POST` | `/api/projects/:id/compliance/check` | Run guideline check |

### Export
| Method | Route | Description |
|--------|-------|-------------|
| `GET` | `/api/projects/:id/export/pdf` | Thesis PDF (signed URL) |
| `GET` | `/api/projects/:id/export/docx` | DOCX via pandoc (signed URL) |
| `GET` | `/api/projects/:id/export/source` | All source files (.zip, signed URL) |
| `GET` | `/api/projects/:id/export/stats` | R scripts + dataset (.zip, signed URL) |

### Supervisor Collaboration (mentioned)
| Method | Route | Description |
|--------|-------|-------------|
| `POST` | `/api/projects/:id/share` | Create supervisor share link (checks license plan_type) |

### Workflow Gates (mentioned in Pricing section)
| Endpoint | Gate |
|----------|------|
| `POST /api/projects` | Free -- sandbox status |
| `POST .../sections/:phase/generate` (Phase 0-1) | Allowed in sandbox |
| `POST .../sections/:phase/approve` (Phase 1->2) | Requires active license + identity binding |
| `POST .../sections/:phase/generate` (Phase 2+) | Requires `project.status = 'licensed'` |
| `POST .../compile` | Sandbox: watermarked. Licensed: clean. |
| `GET .../export/*` | Blocked without active license (402) |

### API Error Response Schema
```json
{
  "error": {
    "code": "LICENSE_REQUIRED",
    "message": "...",
    "action": "upgrade",
    "details": {}
  }
}
```

Standard error codes: `VALIDATION_ERROR` (400), `UNAUTHENTICATED` (401), `LICENSE_REQUIRED` (402), `FORBIDDEN` (403), `NOT_FOUND` (404), `INVALID_TRANSITION` (409), `ALREADY_ATTACHED` (409), `RATE_LIMITED` (429), `QUEUE_FULL` (429), `INTERNAL_ERROR` (500), `SERVICE_UNAVAILABLE` (503).

---

## 3. INNGEST WORKFLOW FUNCTIONS/EVENTS (from PLAN.md + Implementation)

### PLAN.md Workflow
12-phase pipeline with `step.waitForEvent('user.approved.phase.N')` for human-in-the-loop gates:

| Phase | Name | Mode |
|-------|------|------|
| Phase 0 | Orientation | Auto: validate inputs, setup workspace |
| Phase 1 | Front Matter | Auto: generate from metadata form |
| Phase 2 | Introduction | AI + Human |
| Phase 3 | Aims | AI + Human |
| Phase 4 | ROL | AI + Human |
| Phase 5 | M&M | AI + Human |
| Phase 6a | Dataset | Human |
| Phase 6b | Results | AI + R |
| Phase 7 | Discussion | AI + Human |
| Phase 8 | Conclusion | AI + Human |
| Phase 9 | References | Auto: bidirectional audit + provenance check |
| Phase 10 | Appendices | Auto + Human |
| Phase 11 | Final QC | Auto: formatting/citation/data verification |

### Actual Implemented Inngest Functions

**File: `/Users/devs/Downloads/Apollo/apps/web/lib/inngest/functions/thesis-workflow.ts`**
- Function ID: `thesis-phase-workflow`
- Event: `thesis/phase.approved`
- Behaviour: On phase approval, creates the next section as draft, then waits 90 days for the next `thesis/phase.approved` event (matched by `data.projectId`)

**File: `/Users/devs/Downloads/Apollo/apps/web/lib/inngest/functions/analysis-runner.ts`**
- Function ID: `analysis-runner`
- Event: `analysis/run.requested`
- Retries: 1
- Behaviour: Calls `executeAnalysis(analysisId)`, releases compute semaphore on completion/failure

**File: `/Users/devs/Downloads/Apollo/apps/web/lib/inngest/client.ts`**
- Client ID: `apollo`
- Uses `INNGEST_EVENT_KEY` env var

**Events sent from API routes:**
- `inngest.send({ name: "thesis/phase.approved", data: { projectId, phaseNumber } })` -- from approve route
- `inngest.send({ name: "analysis/run.requested", data: { analysisId, jobId } })` -- from analyses route

---

## 4. DOCKER CONTAINER SPECS

### LaTeX Container (`apollo-latex`)
| Property | Value |
|----------|-------|
| Base image | `texlive/texlive:latest-minimal` |
| Additional TeX packages | scheme-small + natbib, titlesec, tocloft, enumitem, doi, draftwatermark, needspace, lastpage, hyphenat, datetime, fmtcount, emptypage, lettrine, nomencl, threeparttable, multirow, bookmark, xstring, babel-english |
| System packages | ghostscript, pandoc |
| Network mode | `none` (no network access) |
| Filesystem | `read_only: true`, `/tmp` writable (tmpfs 512m) |
| Memory limit | `1g` |
| PID limit | `256` |
| Security options | `no-new-privileges:true`, `seccomp:unconfined` |
| Capabilities dropped | ALL |
| Capabilities added | `DAC_OVERRIDE`, `FOWNER` |
| Volumes | `../templates:/templates:ro` |
| Entrypoint | `sleep infinity` (container stays idle; web app exec's into it per compile) |
| Working directory | `/thesis` |
| Env vars | `TEXMFVAR=/tmp/texmf-var`, `HOME=/tmp` |

### R Plumber Container (`apollo-r-plumber`)
| Property | Value |
|----------|-------|
| Base image | `r-base:4.4.0` |
| R packages | plumber, tidyverse, gtsummary, ggplot2, jsonlite, survival, survminer, pROC, meta, broom, readr, base64enc, gt |
| Network | Ports `8787:8787` exposed (NOT network_mode:none) |
| Filesystem | `read_only: true`, `/tmp` writable (tmpfs 256m) |
| Memory limit | `512m` |
| PID limit | `256` |
| Security options | `no-new-privileges:true`, `seccomp:unconfined` |
| Capabilities dropped | ALL |
| Capabilities added | `DAC_OVERRIDE`, `FOWNER`, `NET_BIND_SERVICE` |
| Healthcheck | `curl -f http://localhost:8787/health` every 30s, 5s timeout, 3 retries, 30s start period |
| Command | `R -e "plumber::pr_run(plumber::pr('/app/plumber.R'), host='0.0.0.0', port=8787)"` |

### PLAN.md Docker Security Spec (vs actual)
| Spec from PLAN.md | LaTeX Actual | R Plumber Actual |
|--------------------|-------------|-----------------|
| Read-only filesystem except /tmp | Yes | Yes |
| No network access | Yes (`network_mode: none`) | **NO** -- has ports `8787:8787`, no network restriction |
| 120-second timeout | Not in compose (enforced in code) | Not in compose (enforced per analysis type in code) |
| 1GB memory limit | Yes | 512m (matches capacity model, not the "1GB" stated for LaTeX) |
| Linux seccomp profiles | `seccomp:unconfined` (NOT a seccomp profile) | Same |
| AppArmor profiles (R) | N/A | **NOT CONFIGURED** |

---

## 5. SPRINT ASSIGNMENTS

### Sprint 0 (Day 1): Development Rules + Governance Setup
- Guidance files, governance docs, MCP server config, CI pipeline

### Sprint 1-2 (Weeks 1-4): Foundation + Setup Wizard + License System
- Bootstrap from SaaS boilerplate
- Supabase schema + RLS + Auth
- Hetzner VPS + Coolify + docker-compose
- Thesis license system (CRUD, attach, identity binding, workflow gates)
- 5-step setup wizard
- R2 signed URL uploads
- Study type detection
- Audit log

### Sprint 3-4 (Weeks 5-8): Compute Services + Editor
- LaTeX Docker container (seccomp, no network, 120s timeout)
- R Docker container (Plumber, AppArmor)
- Inngest workflow (phase sequencing + waitForEvent gates)
- Novel editor integration (rich text to LaTeX)
- CodeMirror LaTeX source view
- Word count tracking
- Abbreviation management UI

### Sprint 5-6 (Weeks 9-12): AI Integration + Citations
- Claude API proxy (prompt caching, model routing, token budgets)
- SSE streaming to frontend
- AI conversation persistence per phase
- Citation provenance pipeline
- PubMed/CrossRef search UI
- Bidirectional citation integrity audit
- Synopsis-driven auto-population
- Rate limiting (@upstash/ratelimit)

### Sprint 7 (Weeks 13-14): Dashboard + Compliance + Core Analysis
- 12-phase progress dashboard
- PDF preview (react-pdf split-pane)
- CONSORT/STROBE/PRISMA compliance dashboards
- NBEMS section checker
- Mermaid integration (CONSORT flowcharts)
- Dataset upload + column detection + analysis wizard
- R Sprint 7: Descriptive, chi-square/Fisher, t-test/Mann-Whitney, correlation, survival/Kaplan-Meier
- Template gallery (6 study types)

### Sprint 8 (Weeks 15-16): Advanced Analysis + Observability
- R Sprint 8: ROC, logistic regression, Kruskal-Wallis, meta-analysis
- Runtime limits enforced per analysis type
- Queue fairness (round-robin)
- Observability (Sentry traces, structured JSON logging)
- PII scrubbing in Sentry/PostHog/logs
- Playwright MCP for E2E testing

### Sprint 9-10 (Weeks 17-20): Export + Payments + Collaboration + Launch
- Razorpay integration (payment -> auto-provision license)
- Stripe integration
- Export endpoints with license gate (PDF, DOCX, source, stats)
- DOCX export via pandoc
- Supervisor dashboard (minimal: read-only, comments, phase approval)
- Quality gate automation
- Landing page
- PWA (manifest, service worker, 3 mobile pages)
- Velocity rules + abuse controls
- Release gate checklist

### Post-MVP Phase A (after 500+ users)
- Flutter native app, PaperBanana, plagiarism pre-check, additional CLS files

### Post-MVP Phase B
- DNB workflow, full supervisor collaboration, HOD batch dashboard, Zotero, version history, WhatsApp Business API

---

## 6. DISCREPANCIES: PLAN.md vs Migration Files vs TypeScript Types

### DISCREPANCY 1: Auth System -- `supabase_auth_id` vs `clerk_user_id`

**PLAN.md** says the `users` table has a column called `supabase_auth_id` and the auth system uses "Supabase Auth".

**Migration 002** (`/Users/devs/Downloads/Apollo/apps/web/supabase/migrations/002_create_users.sql`) creates the column as `clerk_user_id TEXT NOT NULL UNIQUE`. All RLS policies reference `clerk_user_id = (select auth.jwt()->>'sub')`.

**TypeScript** (`/Users/devs/Downloads/Apollo/apps/web/lib/types/database.ts`) defines the interface as `clerk_user_id: string`.

**Verdict**: The implementation uses Clerk for authentication, not Supabase Auth as stated in PLAN.md. The column name and all RLS policies consistently use `clerk_user_id`, so the codebase is internally consistent, but it deviates from the plan.

### DISCREPANCY 2: Tables NOT in PLAN.md but present in migrations

The following tables exist in migrations but are not mentioned in the PLAN.md data model section:

1. **`abbreviations`** (migrations 016/017) -- PLAN.md mentions abbreviation management as a feature (Feature 10) but does not include the table in the data model schema. The migration creates it with `(id, project_id, short_form, long_form, created_at, updated_at)`.

2. **`processed_webhooks`** (migration 022) -- PLAN.md mentions this table in the "Payment Webhook Hardening" section prose ("stores the provider's event ID in a `processed_webhooks` table") but it is absent from the formal data model schema. The migration creates `(id, provider, event_id, event_type, processed_at)`.

3. **`review_tokens`** (migration 023) -- Not in PLAN.md data model. Created with `(id, project_id, token, expires_at, created_by, created_at)`.

4. **`review_comments`** (migration 023) -- Not in PLAN.md data model. Created with `(id, project_id, review_token_id, reviewer_name, phase_number, comment_text, created_at)`.

### DISCREPANCY 3: Columns added by later migrations NOT in PLAN.md

1. **`sections.rich_content_json`** (migration 018) -- JSONB column for Tiptap JSON. Not in PLAN.md data model.

2. **`sections.ai_generated_latex`** (migration 019) -- TEXT column for preserving original AI-generated LaTeX. Not in PLAN.md data model.

3. **`datasets.rows_json`** (migration 021) -- JSONB column for storing parsed row data. Not in PLAN.md data model.

### DISCREPANCY 4: TypeScript types include columns not in PLAN.md

The `Section` interface in `/Users/devs/Downloads/Apollo/apps/web/lib/types/database.ts` includes:
- `rich_content_json: Record<string, unknown> | null` -- not in PLAN.md
- `ai_generated_latex: string | null` -- not in PLAN.md

The `Dataset` interface includes:
- `rows_json: Record<string, unknown>[] | null` -- not in PLAN.md

The TypeScript types also include `Abbreviation` interface -- not in PLAN.md data model.

### DISCREPANCY 5: Duplicate migration files in two locations

There are migration files in TWO separate directories:
- `/Users/devs/Downloads/Apollo/supabase/migrations/` (016, 017, 018)
- `/Users/devs/Downloads/Apollo/apps/web/supabase/migrations/` (001-023)

The `apps/web/supabase/migrations/` directory is the authoritative set with the complete migration chain (001-023). The root `supabase/migrations/` directory contains what appear to be earlier versions of migrations 016-018 with slightly different content (e.g., the root 016 uses `auth.uid()` in RLS policies, while the `apps/web` 017 uses `public.get_current_user_id()` helper functions introduced in migration 016_fix_users_rls_recursion).

### DISCREPANCY 6: Migration numbering conflict

In `apps/web/supabase/migrations/`:
- `016_fix_users_rls_recursion.sql` -- fixes RLS recursion bug
- `017_create_abbreviations.sql` -- creates abbreviations table

In root `supabase/migrations/`:
- `016_create_abbreviations.sql` -- creates abbreviations table (different numbering)
- `017_add_rich_content_to_sections.sql`
- `018_add_rows_json_to_datasets.sql`

This means the root directory has stale/conflicting migration numbering.

### DISCREPANCY 7: RLS policy style inconsistency

Early migrations (001-015) use inline subqueries joining `public.users` to check `clerk_user_id = (select auth.jwt()->>'sub')`. Migration 016 introduces `SECURITY DEFINER` helper functions (`get_current_user_id()`, `get_current_user_org_id()`, `is_current_user_admin()`) to fix infinite recursion.

However, only `users` and `projects` RLS policies are updated in migration 016. The following tables still use the old inline subquery pattern and may be vulnerable to the same recursion issue:
- `sections` (005)
- `citations` (006)
- `datasets` (007)
- `analyses` (008)
- `figures` (009)
- `compliance_checks` (010)
- `compilations` (011)
- `ai_conversations` (012)
- `audit_log` (013)

Only `abbreviations` (017) and later tables use the new helper function pattern.

### DISCREPANCY 8: Docker security vs PLAN.md specs

**PLAN.md states**: "Linux seccomp profiles" for LaTeX containers and "AppArmor profiles" for R containers.

**docker-compose.yml actual**: Both containers use `seccomp:unconfined`, which **disables** seccomp rather than applying a profile. No AppArmor configuration is present for the R container.

**PLAN.md states**: R containers have "no network access" (same isolation as LaTeX).

**docker-compose.yml actual**: R Plumber container has `ports: "8787:8787"` and does NOT use `network_mode: none`. It is network-accessible (which is required for the Plumber API to function, but contradicts the "no network access" claim in PLAN.md).

### DISCREPANCY 9: API routes implemented beyond PLAN.md

The following API routes exist in the codebase but are not mentioned in PLAN.md:
- `POST /api/webhooks/clerk/route.ts` -- Clerk webhook handler (PLAN.md says Supabase Auth)
- `POST /api/synopsis/parse/route.ts` -- Synopsis parsing endpoint
- `POST /api/upload/signed-url/route.ts` -- Signed URL generation for uploads
- `POST /api/checkout/route.ts` -- Payment checkout
- `POST /api/webhooks/razorpay/route.ts` -- Razorpay webhook
- `POST /api/webhooks/stripe/route.ts` -- Stripe webhook
- `GET /api/projects/:id/sections/:phase/review/route.ts` -- Section review endpoint
- `POST /api/projects/:id/sections/:phase/refine/route.ts` -- AI refinement endpoint
- `POST /api/projects/:id/citations/:citationId/re-resolve/route.ts` -- Re-resolve a citation
- `POST /api/projects/:id/analyses/auto-detect/route.ts` -- Auto-detect analysis type
- `POST /api/projects/:id/datasets/generate/route.ts` -- Generate synthetic dataset
- `GET /api/projects/:id/datasets/:datasetId/download/route.ts` -- Download dataset
- `GET /api/projects/:id/qc/route.ts` -- QC checks
- `POST /api/projects/:id/qc/fix/route.ts` -- QC auto-fix
- `POST /api/projects/:id/share/route.ts` -- Share project (mentioned in prose but not in the formal API table)
- `GET /api/review/:token/route.ts` -- Token-based review access
- `POST /api/review/:token/comments/route.ts` -- Add review comments
- `POST /api/inngest/route.ts` -- Inngest webhook handler
- `POST /api/projects/:id/compile/route.ts` -- Compile (PLAN.md says just `/compile`, implementation uses this path)

### DISCREPANCY 10: PLAN.md compile route vs actual

**PLAN.md**: `POST /api/projects/:id/compile` and `GET /api/projects/:id/compilations` are separate routes.

**Actual**: There is both `/api/projects/[id]/compile/route.ts` AND `/api/projects/[id]/compilations/route.ts` -- consistent with PLAN.md. However, `preview.pdf` is also implemented at `/api/projects/[id]/preview.pdf/route.ts`, matching the plan.

### DISCREPANCY 11: `compliance_checks` unique constraint

Migration 020 adds `UNIQUE (project_id, guideline_type)` constraint to `compliance_checks`. This is not mentioned in PLAN.md but is a reasonable addition.

### DISCREPANCY 12: `analyses.status` type

**PLAN.md**: Does not specify status enum values for `analyses`.
**Migration 008**: `CHECK (status IN ('pending', 'running', 'completed', 'failed'))`.
**TypeScript**: `AnalysisStatus = "pending" | "running" | "completed" | "failed"`.
These are consistent between migration and TypeScript but absent from the formal PLAN.md schema.

### DISCREPANCY 13: `compilations.status` type

**PLAN.md**: Does not specify status enum values for `compilations`.
**Migration 011**: `CHECK (status IN ('pending', 'running', 'completed', 'failed'))`.
**TypeScript**: `CompilationStatus = "pending" | "running" | "completed" | "failed"`.
Again consistent between implementation artifacts but absent from the formal PLAN.md schema.

---

## Summary of Key Findings

**Schema alignment**: The core 11 tables from PLAN.md are all implemented in migrations. Four additional tables (`abbreviations`, `processed_webhooks`, `review_tokens`, `review_comments`) exist in migrations but not in the PLAN.md formal data model (though `abbreviations` and `processed_webhooks` are mentioned in feature descriptions/prose). Three extra columns were added to existing tables (`sections.rich_content_json`, `sections.ai_generated_latex`, `datasets.rows_json`) that are not in the plan.

**Auth system deviation**: The most significant architectural deviation is the use of Clerk instead of Supabase Auth. This affects the `users` table column name, all RLS policies, and introduces a Clerk webhook handler not in the plan.

**Docker security gaps**: Both containers use `seccomp:unconfined` rather than actual seccomp profiles, and the R container is not restricted to no-network as stated in the plan. AppArmor is not configured.

**Duplicate migrations**: Two migration directories exist with conflicting numbering, which could cause issues if the wrong directory is referenced during deployment.

**RLS recursion fix incomplete**: The fix in migration 016 only updates `users` and `projects` policies. Other tables still use the old pattern that may trigger the same infinite recursion bug.</result>
<usage>total_tokens: 76473
tool_uses: 50
duration_ms: 230458</usage>
</task-notification>
Full transcript available at: /private/tmp/claude-501/-Users-devs-Downloads-Apollo/tasks/a517ad3.output

---

I need you to check few other issues in addition as well. Check the actual business code, the thesis generation pipeline, from beginning to end. Focus hard on the AI integration lacunae, AI system prompts which I feel are just bare minimum, the citation pipeline and its integration to the main thesis pipeline, the Refine,Re-verify citations, etc pipelines and their integration to the main pipeline, the Data Analysis pipeline in detail and depth, its weaknesses, failure points, and its integration to the main pipeline. The figure generation pipeline (not just single plots per analysis and none for descriptive), the figure storage and downloadability lacunae. There should be a minimum number of figures and tables requirement per thesis. Flow of each step from the previous one, the stop gap fixes applied in haste in prior coding sessions. Wire up the entire pipeline in your mind, visualise it, and find the issues (eg maybe latex to tiptap back to latex is causing maximum number of issues, and rather than doing this round about way, which was introduced in haste, we can do it better, or differently?) The latex templates are mixed up, the generic university defaults to SSKM or other such issues, the latex packages, fonts , math notations etc may cause issues etc etc. every weak link needs to be identified and planned for removal robustly. Everything needs to be checked against plan and gaps need to identified, but a better solution can supercede minor notes in the plan (eg Clerk instead of supabase auth was by design). All your findings from this pass will then need to be assimilated as part II of the review (part I done above)

---

This session is being continued from a previous conversation that ran out of context. The summary below covers the earlier portion of the conversation.

Analysis:
Let me chronologically analyze the entire conversation to create a comprehensive summary.

1. **User's first request**: "check the codebase. Do a gap analysis with /docs/PLAN. Do a git diff. Check last commit CI status. Be thorough, meticulous, and Think ultra hard before you act."

2. **My approach - Part I (Infrastructure & Schema Gap Analysis)**:
   - Launched parallel agents to read PLAN.md, explore codebase structure, check git diff, CI status
   - Found CI failure on last commit (8a900a2) - ESLint `prefer-const` error in `auto-resolve.ts`
   - Ran TypeScript check (clean), unit tests (343/343 pass), lint (1 error + 15 warnings)
   - Produced comprehensive Part I gap analysis covering sprints 0-10, security, Docker, schema
   - Schema agent found critical additional discrepancies: Clerk vs Supabase Auth, RLS recursion bug, duplicate migration directories

3. **User's second request**: Deep dive into business logic - AI prompts, citation pipeline, LaTeX pipeline, R analysis pipeline, figure pipeline, phase transitions, etc. User said: "I need you to check few other issues in addition as well. Check the actual business code, the thesis generation pipeline, from beginning to end. Focus hard on the AI integration lacunae, AI system prompts which I feel are just bare minimum, the citation pipeline and its integration to the main thesis pipeline, the Refine,Re-verify citations, etc pipelines and their integration to the main pipeline, the Data Analysis pipeline in detail and depth, its weaknesses, failure points, and its integration to the main pipeline. The figure generation pipeline (not just single plots per analysis and none for descriptive), the figure storage and downloadability lacunae. There should be a minimum number of figures and tables requirement per thesis. Flow of each step from the previous one, the stop gap fixes applied in haste in prior coding sessions. Wire up the entire pipeline in your mind, visualise it, and find the issues..."

4. **My approach - Part II**: Launched 5 parallel deep-dive agents:
   - Agent 1 (a3d46a3): AI prompts and generation pipeline
   - Agent 2 (a8dc46a): Citation pipeline end-to-end
   - Agent 3 (a54e776): LaTeX pipeline end-to-end
   - Agent 4 (a5afa5e): R analysis and figure pipeline
   - Agent 5 (a77af11): Phase transitions and generation routes

All 5 agents completed successfully. The summary request came before I could synthesize the findings into a Part II report.

Let me capture all the critical findings from each agent:

**Agent 1 - AI Prompts**: 
- Found prompts for all phases (Front Matter, Introduction, Aims, ROL, M&M, Results, Discussion, Conclusion, Appendices, Refine)
- COMMON_RULES shared across all prompts include LaTeX formatting, citation, British English rules
- QC system with `final-qc.ts` runs 5 checks: citation provenance, section completeness, British English, NBEMS compliance, undefined references
- Token budget tracking exists but needs verification of enforcement in generate route
- AI conversation persistence uses `ai_conversations` table but `messages_json` is stored as empty array (no multi-turn)
- Review system (`review-section.ts`) checks citations, word count, structure, British English, citation quality

**Agent 2 - Citation Pipeline**:
- Complete pipeline: AI generates \cite{key}  auto-resolve via CrossRef/PubMed  DB upsert  compile assembly
- Critical bug: orphan cite keys without DB records bypass Tier D stripping in compile
- No retry logic for API failures
- Re-resolve Strategy 2 lacks title verification (could assign wrong paper)
- Pre-seeded references not persisted to DB upfront
- Timeout budget mismatch for ROL phase (30+ citations vs 15-second timeout)

**Agent 3 - LaTeX Pipeline**:
- Round-trip IS LOSSY: \label{}, \footnote{}, \url{}, \textsuperscript{} destroyed
- CRITICAL: Inline math ($p < 0.05$) destroyed by escapeLatex() in tiptap-to-latex.ts
- mathrsfs package NOT installed in Docker but added by generate-tex.ts
- Phase 10 (Appendices) content never \input-ed by template
- Abbreviations never injected during assembly
- PDF storage ephemeral (os.tmpdir()) - no R2 integration
- Local compile mode ignores watermark
- Warning budget (<=20) not programmatically enforced
- front-matter.ts is dead code for compile pipeline
- Brace-checking has subtle bug with \\{ pattern
- Alternative approaches: Option B (selective sanitization) or Option C (keep AI LaTeX canonical) recommended over full round-trip

**Agent 4 - R Analysis & Figures**:
- All Sprint 7 (descriptive, chi-square, t-test, survival) AND Sprint 8 (ROC, logistic, Kruskal-Wallis, meta-analysis) types implemented
- Descriptive analysis produces NO figures (only Table 1)
- PDF figures at 300 DPI 
- Shapiro-Wilk normality testing 
- R2 NOT wired for figures (ephemeral tmpdir storage)
- PDF figure preview impossible in UI (no download endpoint)
- No minimum figure/table enforcement
- Subfigure support absent
- In-memory semaphore not durable, queue promotion bug (resolve callbacks are no-ops)
- Chart type/colour scheme options not exposed in wizard UI

**Agent 5 - Phase Transitions**:
- Phase transitions properly enforce: section must be approved, license required for Phase 12, sandbox blocks Phase 2+ generation
- Token budget check exists in token-budget.ts but need to verify it's called in generate route
- Review system checks structure per phase (Introduction needs background, ROL needs search strategy, etc.)
- QC route stores results as JSON in Phase 11 section's latex_content field (hacky)
- Refine route uses same SSE streaming pattern as generate
- The workspace component orchestrates the full pipeline

Key findings from all agents that I had NOT yet synthesized into a report for the user.

Summary:
1. Primary Request and Intent:
   The user requested a comprehensive, two-part gap analysis of the Apollo thesis generation platform:
   
   **Part I (completed, report delivered)**: Infrastructure-level gap analysis comparing the codebase against `/docs/PLAN.md`. Check git diff, CI status, sprint completion, database schema, Docker security, API routes, and all deviations from the plan.
   
   **Part II (data gathered, synthesis pending)**: Deep-dive audit of ALL business logic pipelines end-to-end:
   - AI system prompts quality and completeness for each thesis phase
   - Citation pipeline: auto-resolve, re-resolve, pre-seed, audit, integration with compile
   - LaTeX pipeline: the round-trip (LaTeXTiptapLaTeX) lossiness, assembly, compilation, template issues
   - R analysis pipeline: all analysis types, figure generation, storage, downloadability
   - Figure pipeline: storage gaps, minimum requirements, subfigure support
   - Phase transition flow: every step from Phase 011, stop-gap fixes, integration gaps
   - User specifically noted: "AI system prompts which I feel are just bare minimum" and "There should be a minimum number of figures and tables requirement per thesis"
   - User noted Clerk instead of Supabase Auth was intentional ("by design")

2. Key Technical Concepts:
   - **GOLD Standard 12-Phase Methodology**: Phases 0-11 for thesis generation with human-in-the-loop approval gates
   - **LaTeX Round-Trip**: AI generates LaTeX  `latexToTiptap()` for rich editor  `tiptapToLatex()` for compile  `assembleThesisContent()`  Docker compile
   - **3-Tier DB Fallback**: `rich_content_json` (primary)  `latex_content` with round-trip sanitization (fallback)  empty (skip)
   - **Citation Provenance Tiers**: A (DOI/PMID auto-verified), B (ISBN/URL student-confirmed), C (manual), D (unresolvable, blocks Phase 11)
   - **BibTeX Separator Pattern**: AI outputs `---BIBTEX---` trailer after chapter content; split for assembly
   - **Pre-seeded References**: PubMed search results injected into AI prompts for citation-heavy phases
   - **Inngest Workflows**: `thesis/phase.approved` and `analysis/run.requested` events
   - **Semaphore Admission Control**: In-memory, 3 units max (compile=2, analysis=1)
   - **Docker Isolation**: LaTeX (`network_mode: none`, read-only, 1GB limit) and R Plumber (port 8787, 512MB limit)
   - **SSE Streaming**: Used for AI generation and refinement, with post-stream citation resolution
   - **University Template System**: `sskm-thesis.cls` (WBUHS) and `ssuhs-thesis.cls` (SSUHS) with harmonized 50+ command API

3. Files and Code Sections:
   
   **AI Integration Layer:**
   - `apps/web/lib/ai/prompts.ts`  System prompts for all 12 phases. Has `COMMON_RULES` shared block, phase-specific prompts for Front Matter, Introduction, Aims, ROL, M&M, Results, Discussion, Conclusion, Appendices, and a `REFINE_SYSTEM_PROMPT`. Results prompt instructs AI to include R-generated tables VERBATIM and reference figures with `\includegraphics{}`.
   - `apps/web/lib/ai/client.ts`  Claude API client
   - `apps/web/lib/ai/review-section.ts`  Deterministic review: checks citations preserved, word count, structure per phase, British English, citation quality (Tier D ratio). Returns `passedReview` boolean.
   - `apps/web/lib/ai/token-budget.ts`  Tracks token usage via `ai_conversations` table. Limits: 100K output tokens/phase, 1.2M total/thesis. `checkTokenBudget()` and `recordTokenUsage()` functions. Note: `messages_json` stored as empty array `[]`  no actual multi-turn conversation persistence.
   - `apps/web/lib/ai/redact.ts`  PII redaction for AI prompts
   
   **Citation Pipeline:**
   - `apps/web/lib/citations/auto-resolve.ts`  `resolveSectionCitations()`: splits at `---BIBTEX---`, resolves entries, upserts to DB, creates Tier D placeholders for orphan `\cite{key}` references. **CRITICAL BUG**: If this times out (15s generate / 10s refine), orphan keys get NO Tier D placeholder, and `\cite{key}` persists through compilation causing BibTeX warnings.
   - `apps/web/lib/citations/resolve.ts`  Core 4-step resolution: DOI hint  PMID hint  title search (0.85 Levenshtein threshold)  Tier D fallback
   - `apps/web/lib/citations/crossref.ts`  CrossRef API with 10s timeout, content negotiation for BibTeX
   - `apps/web/lib/citations/pubmed.ts`  PubMed esearch+esummary with cascade to CrossRef DOI lookup
   - `apps/web/lib/citations/pre-seed.ts`  `preSeedReferences()`: Builds PubMed queries from project metadata, fetches within 8s budget, formats for AI prompt. Called for phases 2, 4, 5, 7. NOT persisted to DB.
   - `apps/web/lib/citations/audit.ts`  Pure function bidirectional audit using `section.citation_keys[]`. Forward (keys in sections not in DB) + reverse (DB citations not in sections) + Tier D blocking detection.
   - `apps/web/app/api/projects/[id]/citations/[citationId]/re-resolve/route.ts`  3-strategy re-resolve: (1) re-resolve from BibTeX, (2) CrossRef search by key pattern (lacks title similarity check), (3) manual attestation prompt.
   
   **LaTeX Pipeline:**
   - `apps/web/lib/latex/latex-to-tiptap.ts`  Converts LaTeX to Tiptap JSON. Preprocessing strips `---BIBTEX---`, `\label{}`, `\needspace{}`, comments, converts markdown headings. Complex environments become `codeBlock` nodes (raw LaTeX pass-through). **Lossy**: destroys `\footnote{}`, `\url{}`, `\textsuperscript{}`, `\textsubscript{}`. Inline math `$p < 0.05Analysis:
Let me chronologically analyze the entire conversation to create a comprehensive summary.

1. **User's first request**: "check the codebase. Do a gap analysis with /docs/PLAN. Do a git diff. Check last commit CI status. Be thorough, meticulous, and Think ultra hard before you act."

2. **My approach - Part I (Infrastructure & Schema Gap Analysis)**:
   - Launched parallel agents to read PLAN.md, explore codebase structure, check git diff, CI status
   - Found CI failure on last commit (8a900a2) - ESLint `prefer-const` error in `auto-resolve.ts`
   - Ran TypeScript check (clean), unit tests (343/343 pass), lint (1 error + 15 warnings)
   - Produced comprehensive Part I gap analysis covering sprints 0-10, security, Docker, schema
   - Schema agent found critical additional discrepancies: Clerk vs Supabase Auth, RLS recursion bug, duplicate migration directories

3. **User's second request**: Deep dive into business logic - AI prompts, citation pipeline, LaTeX pipeline, R analysis pipeline, figure pipeline, phase transitions, etc. User said: "I need you to check few other issues in addition as well. Check the actual business code, the thesis generation pipeline, from beginning to end. Focus hard on the AI integration lacunae, AI system prompts which I feel are just bare minimum, the citation pipeline and its integration to the main thesis pipeline, the Refine,Re-verify citations, etc pipelines and their integration to the main pipeline, the Data Analysis pipeline in detail and depth, its weaknesses, failure points, and its integration to the main pipeline. The figure generation pipeline (not just single plots per analysis and none for descriptive), the figure storage and downloadability lacunae. There should be a minimum number of figures and tables requirement per thesis. Flow of each step from the previous one, the stop gap fixes applied in haste in prior coding sessions. Wire up the entire pipeline in your mind, visualise it, and find the issues..."

4. **My approach - Part II**: Launched 5 parallel deep-dive agents:
   - Agent 1 (a3d46a3): AI prompts and generation pipeline
   - Agent 2 (a8dc46a): Citation pipeline end-to-end
   - Agent 3 (a54e776): LaTeX pipeline end-to-end
   - Agent 4 (a5afa5e): R analysis and figure pipeline
   - Agent 5 (a77af11): Phase transitions and generation routes

All 5 agents completed successfully. The summary request came before I could synthesize the findings into a Part II report.

Let me capture all the critical findings from each agent:

**Agent 1 - AI Prompts**: 
- Found prompts for all phases (Front Matter, Introduction, Aims, ROL, M&M, Results, Discussion, Conclusion, Appendices, Refine)
- COMMON_RULES shared across all prompts include LaTeX formatting, citation, British English rules
- QC system with `final-qc.ts` runs 5 checks: citation provenance, section completeness, British English, NBEMS compliance, undefined references
- Token budget tracking exists but needs verification of enforcement in generate route
- AI conversation persistence uses `ai_conversations` table but `messages_json` is stored as empty array (no multi-turn)
- Review system (`review-section.ts`) checks citations, word count, structure, British English, citation quality

**Agent 2 - Citation Pipeline**:
- Complete pipeline: AI generates \cite{key}  auto-resolve via CrossRef/PubMed  DB upsert  compile assembly
- Critical bug: orphan cite keys without DB records bypass Tier D stripping in compile
- No retry logic for API failures
- Re-resolve Strategy 2 lacks title verification (could assign wrong paper)
- Pre-seeded references not persisted to DB upfront
- Timeout budget mismatch for ROL phase (30+ citations vs 15-second timeout)

**Agent 3 - LaTeX Pipeline**:
- Round-trip IS LOSSY: \label{}, \footnote{}, \url{}, \textsuperscript{} destroyed
- CRITICAL: Inline math ($p < 0.05$) destroyed by escapeLatex() in tiptap-to-latex.ts
- mathrsfs package NOT installed in Docker but added by generate-tex.ts
- Phase 10 (Appendices) content never \input-ed by template
- Abbreviations never injected during assembly
- PDF storage ephemeral (os.tmpdir()) - no R2 integration
- Local compile mode ignores watermark
- Warning budget (<=20) not programmatically enforced
- front-matter.ts is dead code for compile pipeline
- Brace-checking has subtle bug with \\{ pattern
- Alternative approaches: Option B (selective sanitization) or Option C (keep AI LaTeX canonical) recommended over full round-trip

**Agent 4 - R Analysis & Figures**:
- All Sprint 7 (descriptive, chi-square, t-test, survival) AND Sprint 8 (ROC, logistic, Kruskal-Wallis, meta-analysis) types implemented
- Descriptive analysis produces NO figures (only Table 1)
- PDF figures at 300 DPI 
- Shapiro-Wilk normality testing 
- R2 NOT wired for figures (ephemeral tmpdir storage)
- PDF figure preview impossible in UI (no download endpoint)
- No minimum figure/table enforcement
- Subfigure support absent
- In-memory semaphore not durable, queue promotion bug (resolve callbacks are no-ops)
- Chart type/colour scheme options not exposed in wizard UI

**Agent 5 - Phase Transitions**:
- Phase transitions properly enforce: section must be approved, license required for Phase 12, sandbox blocks Phase 2+ generation
- Token budget check exists in token-budget.ts but need to verify it's called in generate route
- Review system checks structure per phase (Introduction needs background, ROL needs search strategy, etc.)
- QC route stores results as JSON in Phase 11 section's latex_content field (hacky)
- Refine route uses same SSE streaming pattern as generate
- The workspace component orchestrates the full pipeline

Key findings from all agents that I had NOT yet synthesized into a report for the user.

 in paragraphs gets `Analysis:
Let me chronologically analyze the entire conversation to create a comprehensive summary.

1. **User's first request**: "check the codebase. Do a gap analysis with /docs/PLAN. Do a git diff. Check last commit CI status. Be thorough, meticulous, and Think ultra hard before you act."

2. **My approach - Part I (Infrastructure & Schema Gap Analysis)**:
   - Launched parallel agents to read PLAN.md, explore codebase structure, check git diff, CI status
   - Found CI failure on last commit (8a900a2) - ESLint `prefer-const` error in `auto-resolve.ts`
   - Ran TypeScript check (clean), unit tests (343/343 pass), lint (1 error + 15 warnings)
   - Produced comprehensive Part I gap analysis covering sprints 0-10, security, Docker, schema
   - Schema agent found critical additional discrepancies: Clerk vs Supabase Auth, RLS recursion bug, duplicate migration directories

3. **User's second request**: Deep dive into business logic - AI prompts, citation pipeline, LaTeX pipeline, R analysis pipeline, figure pipeline, phase transitions, etc. User said: "I need you to check few other issues in addition as well. Check the actual business code, the thesis generation pipeline, from beginning to end. Focus hard on the AI integration lacunae, AI system prompts which I feel are just bare minimum, the citation pipeline and its integration to the main thesis pipeline, the Refine,Re-verify citations, etc pipelines and their integration to the main pipeline, the Data Analysis pipeline in detail and depth, its weaknesses, failure points, and its integration to the main pipeline. The figure generation pipeline (not just single plots per analysis and none for descriptive), the figure storage and downloadability lacunae. There should be a minimum number of figures and tables requirement per thesis. Flow of each step from the previous one, the stop gap fixes applied in haste in prior coding sessions. Wire up the entire pipeline in your mind, visualise it, and find the issues..."

4. **My approach - Part II**: Launched 5 parallel deep-dive agents:
   - Agent 1 (a3d46a3): AI prompts and generation pipeline
   - Agent 2 (a8dc46a): Citation pipeline end-to-end
   - Agent 3 (a54e776): LaTeX pipeline end-to-end
   - Agent 4 (a5afa5e): R analysis and figure pipeline
   - Agent 5 (a77af11): Phase transitions and generation routes

All 5 agents completed successfully. The summary request came before I could synthesize the findings into a Part II report.

Let me capture all the critical findings from each agent:

**Agent 1 - AI Prompts**: 
- Found prompts for all phases (Front Matter, Introduction, Aims, ROL, M&M, Results, Discussion, Conclusion, Appendices, Refine)
- COMMON_RULES shared across all prompts include LaTeX formatting, citation, British English rules
- QC system with `final-qc.ts` runs 5 checks: citation provenance, section completeness, British English, NBEMS compliance, undefined references
- Token budget tracking exists but needs verification of enforcement in generate route
- AI conversation persistence uses `ai_conversations` table but `messages_json` is stored as empty array (no multi-turn)
- Review system (`review-section.ts`) checks citations, word count, structure, British English, citation quality

**Agent 2 - Citation Pipeline**:
- Complete pipeline: AI generates \cite{key}  auto-resolve via CrossRef/PubMed  DB upsert  compile assembly
- Critical bug: orphan cite keys without DB records bypass Tier D stripping in compile
- No retry logic for API failures
- Re-resolve Strategy 2 lacks title verification (could assign wrong paper)
- Pre-seeded references not persisted to DB upfront
- Timeout budget mismatch for ROL phase (30+ citations vs 15-second timeout)

**Agent 3 - LaTeX Pipeline**:
- Round-trip IS LOSSY: \label{}, \footnote{}, \url{}, \textsuperscript{} destroyed
- CRITICAL: Inline math ($p < 0.05$) destroyed by escapeLatex() in tiptap-to-latex.ts
- mathrsfs package NOT installed in Docker but added by generate-tex.ts
- Phase 10 (Appendices) content never \input-ed by template
- Abbreviations never injected during assembly
- PDF storage ephemeral (os.tmpdir()) - no R2 integration
- Local compile mode ignores watermark
- Warning budget (<=20) not programmatically enforced
- front-matter.ts is dead code for compile pipeline
- Brace-checking has subtle bug with \\{ pattern
- Alternative approaches: Option B (selective sanitization) or Option C (keep AI LaTeX canonical) recommended over full round-trip

**Agent 4 - R Analysis & Figures**:
- All Sprint 7 (descriptive, chi-square, t-test, survival) AND Sprint 8 (ROC, logistic, Kruskal-Wallis, meta-analysis) types implemented
- Descriptive analysis produces NO figures (only Table 1)
- PDF figures at 300 DPI 
- Shapiro-Wilk normality testing 
- R2 NOT wired for figures (ephemeral tmpdir storage)
- PDF figure preview impossible in UI (no download endpoint)
- No minimum figure/table enforcement
- Subfigure support absent
- In-memory semaphore not durable, queue promotion bug (resolve callbacks are no-ops)
- Chart type/colour scheme options not exposed in wizard UI

**Agent 5 - Phase Transitions**:
- Phase transitions properly enforce: section must be approved, license required for Phase 12, sandbox blocks Phase 2+ generation
- Token budget check exists in token-budget.ts but need to verify it's called in generate route
- Review system checks structure per phase (Introduction needs background, ROL needs search strategy, etc.)
- QC route stores results as JSON in Phase 11 section's latex_content field (hacky)
- Refine route uses same SSE streaming pattern as generate
- The workspace component orchestrates the full pipeline

Key findings from all agents that I had NOT yet synthesized into a report for the user.

 escaped to `\Analysis:
Let me chronologically analyze the entire conversation to create a comprehensive summary.

1. **User's first request**: "check the codebase. Do a gap analysis with /docs/PLAN. Do a git diff. Check last commit CI status. Be thorough, meticulous, and Think ultra hard before you act."

2. **My approach - Part I (Infrastructure & Schema Gap Analysis)**:
   - Launched parallel agents to read PLAN.md, explore codebase structure, check git diff, CI status
   - Found CI failure on last commit (8a900a2) - ESLint `prefer-const` error in `auto-resolve.ts`
   - Ran TypeScript check (clean), unit tests (343/343 pass), lint (1 error + 15 warnings)
   - Produced comprehensive Part I gap analysis covering sprints 0-10, security, Docker, schema
   - Schema agent found critical additional discrepancies: Clerk vs Supabase Auth, RLS recursion bug, duplicate migration directories

3. **User's second request**: Deep dive into business logic - AI prompts, citation pipeline, LaTeX pipeline, R analysis pipeline, figure pipeline, phase transitions, etc. User said: "I need you to check few other issues in addition as well. Check the actual business code, the thesis generation pipeline, from beginning to end. Focus hard on the AI integration lacunae, AI system prompts which I feel are just bare minimum, the citation pipeline and its integration to the main thesis pipeline, the Refine,Re-verify citations, etc pipelines and their integration to the main pipeline, the Data Analysis pipeline in detail and depth, its weaknesses, failure points, and its integration to the main pipeline. The figure generation pipeline (not just single plots per analysis and none for descriptive), the figure storage and downloadability lacunae. There should be a minimum number of figures and tables requirement per thesis. Flow of each step from the previous one, the stop gap fixes applied in haste in prior coding sessions. Wire up the entire pipeline in your mind, visualise it, and find the issues..."

4. **My approach - Part II**: Launched 5 parallel deep-dive agents:
   - Agent 1 (a3d46a3): AI prompts and generation pipeline
   - Agent 2 (a8dc46a): Citation pipeline end-to-end
   - Agent 3 (a54e776): LaTeX pipeline end-to-end
   - Agent 4 (a5afa5e): R analysis and figure pipeline
   - Agent 5 (a77af11): Phase transitions and generation routes

All 5 agents completed successfully. The summary request came before I could synthesize the findings into a Part II report.

Let me capture all the critical findings from each agent:

**Agent 1 - AI Prompts**: 
- Found prompts for all phases (Front Matter, Introduction, Aims, ROL, M&M, Results, Discussion, Conclusion, Appendices, Refine)
- COMMON_RULES shared across all prompts include LaTeX formatting, citation, British English rules
- QC system with `final-qc.ts` runs 5 checks: citation provenance, section completeness, British English, NBEMS compliance, undefined references
- Token budget tracking exists but needs verification of enforcement in generate route
- AI conversation persistence uses `ai_conversations` table but `messages_json` is stored as empty array (no multi-turn)
- Review system (`review-section.ts`) checks citations, word count, structure, British English, citation quality

**Agent 2 - Citation Pipeline**:
- Complete pipeline: AI generates \cite{key}  auto-resolve via CrossRef/PubMed  DB upsert  compile assembly
- Critical bug: orphan cite keys without DB records bypass Tier D stripping in compile
- No retry logic for API failures
- Re-resolve Strategy 2 lacks title verification (could assign wrong paper)
- Pre-seeded references not persisted to DB upfront
- Timeout budget mismatch for ROL phase (30+ citations vs 15-second timeout)

**Agent 3 - LaTeX Pipeline**:
- Round-trip IS LOSSY: \label{}, \footnote{}, \url{}, \textsuperscript{} destroyed
- CRITICAL: Inline math ($p < 0.05$) destroyed by escapeLatex() in tiptap-to-latex.ts
- mathrsfs package NOT installed in Docker but added by generate-tex.ts
- Phase 10 (Appendices) content never \input-ed by template
- Abbreviations never injected during assembly
- PDF storage ephemeral (os.tmpdir()) - no R2 integration
- Local compile mode ignores watermark
- Warning budget (<=20) not programmatically enforced
- front-matter.ts is dead code for compile pipeline
- Brace-checking has subtle bug with \\{ pattern
- Alternative approaches: Option B (selective sanitization) or Option C (keep AI LaTeX canonical) recommended over full round-trip

**Agent 4 - R Analysis & Figures**:
- All Sprint 7 (descriptive, chi-square, t-test, survival) AND Sprint 8 (ROC, logistic, Kruskal-Wallis, meta-analysis) types implemented
- Descriptive analysis produces NO figures (only Table 1)
- PDF figures at 300 DPI 
- Shapiro-Wilk normality testing 
- R2 NOT wired for figures (ephemeral tmpdir storage)
- PDF figure preview impossible in UI (no download endpoint)
- No minimum figure/table enforcement
- Subfigure support absent
- In-memory semaphore not durable, queue promotion bug (resolve callbacks are no-ops)
- Chart type/colour scheme options not exposed in wizard UI

**Agent 5 - Phase Transitions**:
- Phase transitions properly enforce: section must be approved, license required for Phase 12, sandbox blocks Phase 2+ generation
- Token budget check exists in token-budget.ts but need to verify it's called in generate route
- Review system checks structure per phase (Introduction needs background, ROL needs search strategy, etc.)
- QC route stores results as JSON in Phase 11 section's latex_content field (hacky)
- Refine route uses same SSE streaming pattern as generate
- The workspace component orchestrates the full pipeline

Key findings from all agents that I had NOT yet synthesized into a report for the user.

.
   - `apps/web/lib/latex/tiptap-to-latex.ts`  Converts Tiptap JSON back to LaTeX. `escapeLatex()` escapes `Analysis:
Let me chronologically analyze the entire conversation to create a comprehensive summary.

1. **User's first request**: "check the codebase. Do a gap analysis with /docs/PLAN. Do a git diff. Check last commit CI status. Be thorough, meticulous, and Think ultra hard before you act."

2. **My approach - Part I (Infrastructure & Schema Gap Analysis)**:
   - Launched parallel agents to read PLAN.md, explore codebase structure, check git diff, CI status
   - Found CI failure on last commit (8a900a2) - ESLint `prefer-const` error in `auto-resolve.ts`
   - Ran TypeScript check (clean), unit tests (343/343 pass), lint (1 error + 15 warnings)
   - Produced comprehensive Part I gap analysis covering sprints 0-10, security, Docker, schema
   - Schema agent found critical additional discrepancies: Clerk vs Supabase Auth, RLS recursion bug, duplicate migration directories

3. **User's second request**: Deep dive into business logic - AI prompts, citation pipeline, LaTeX pipeline, R analysis pipeline, figure pipeline, phase transitions, etc. User said: "I need you to check few other issues in addition as well. Check the actual business code, the thesis generation pipeline, from beginning to end. Focus hard on the AI integration lacunae, AI system prompts which I feel are just bare minimum, the citation pipeline and its integration to the main thesis pipeline, the Refine,Re-verify citations, etc pipelines and their integration to the main pipeline, the Data Analysis pipeline in detail and depth, its weaknesses, failure points, and its integration to the main pipeline. The figure generation pipeline (not just single plots per analysis and none for descriptive), the figure storage and downloadability lacunae. There should be a minimum number of figures and tables requirement per thesis. Flow of each step from the previous one, the stop gap fixes applied in haste in prior coding sessions. Wire up the entire pipeline in your mind, visualise it, and find the issues..."

4. **My approach - Part II**: Launched 5 parallel deep-dive agents:
   - Agent 1 (a3d46a3): AI prompts and generation pipeline
   - Agent 2 (a8dc46a): Citation pipeline end-to-end
   - Agent 3 (a54e776): LaTeX pipeline end-to-end
   - Agent 4 (a5afa5e): R analysis and figure pipeline
   - Agent 5 (a77af11): Phase transitions and generation routes

All 5 agents completed successfully. The summary request came before I could synthesize the findings into a Part II report.

Let me capture all the critical findings from each agent:

**Agent 1 - AI Prompts**: 
- Found prompts for all phases (Front Matter, Introduction, Aims, ROL, M&M, Results, Discussion, Conclusion, Appendices, Refine)
- COMMON_RULES shared across all prompts include LaTeX formatting, citation, British English rules
- QC system with `final-qc.ts` runs 5 checks: citation provenance, section completeness, British English, NBEMS compliance, undefined references
- Token budget tracking exists but needs verification of enforcement in generate route
- AI conversation persistence uses `ai_conversations` table but `messages_json` is stored as empty array (no multi-turn)
- Review system (`review-section.ts`) checks citations, word count, structure, British English, citation quality

**Agent 2 - Citation Pipeline**:
- Complete pipeline: AI generates \cite{key}  auto-resolve via CrossRef/PubMed  DB upsert  compile assembly
- Critical bug: orphan cite keys without DB records bypass Tier D stripping in compile
- No retry logic for API failures
- Re-resolve Strategy 2 lacks title verification (could assign wrong paper)
- Pre-seeded references not persisted to DB upfront
- Timeout budget mismatch for ROL phase (30+ citations vs 15-second timeout)

**Agent 3 - LaTeX Pipeline**:
- Round-trip IS LOSSY: \label{}, \footnote{}, \url{}, \textsuperscript{} destroyed
- CRITICAL: Inline math ($p < 0.05$) destroyed by escapeLatex() in tiptap-to-latex.ts
- mathrsfs package NOT installed in Docker but added by generate-tex.ts
- Phase 10 (Appendices) content never \input-ed by template
- Abbreviations never injected during assembly
- PDF storage ephemeral (os.tmpdir()) - no R2 integration
- Local compile mode ignores watermark
- Warning budget (<=20) not programmatically enforced
- front-matter.ts is dead code for compile pipeline
- Brace-checking has subtle bug with \\{ pattern
- Alternative approaches: Option B (selective sanitization) or Option C (keep AI LaTeX canonical) recommended over full round-trip

**Agent 4 - R Analysis & Figures**:
- All Sprint 7 (descriptive, chi-square, t-test, survival) AND Sprint 8 (ROC, logistic, Kruskal-Wallis, meta-analysis) types implemented
- Descriptive analysis produces NO figures (only Table 1)
- PDF figures at 300 DPI 
- Shapiro-Wilk normality testing 
- R2 NOT wired for figures (ephemeral tmpdir storage)
- PDF figure preview impossible in UI (no download endpoint)
- No minimum figure/table enforcement
- Subfigure support absent
- In-memory semaphore not durable, queue promotion bug (resolve callbacks are no-ops)
- Chart type/colour scheme options not exposed in wizard UI

**Agent 5 - Phase Transitions**:
- Phase transitions properly enforce: section must be approved, license required for Phase 12, sandbox blocks Phase 2+ generation
- Token budget check exists in token-budget.ts but need to verify it's called in generate route
- Review system checks structure per phase (Introduction needs background, ROL needs search strategy, etc.)
- QC route stores results as JSON in Phase 11 section's latex_content field (hacky)
- Refine route uses same SSE streaming pattern as generate
- The workspace component orchestrates the full pipeline

Key findings from all agents that I had NOT yet synthesized into a report for the user.

, `\`, `{`, `}`, `^`, `_`, `~`, `#`, `%`, `&`. Citation `\cite{}` nodes pass through via strict regex `/^\\cite\{[^}]+\}$/`. CodeBlock content gets `normaliseUnicode()` only.
   - `apps/web/lib/latex/assemble.ts`  `assembleThesisContent()`: builds full thesis. Primary path uses `tiptapToLatex(rich_content_json)`. Fallback does full round-trip. `PHASE_CHAPTER_MAP` maps phases 2-8,10 to chapter files. BibTeX collected from `ai_generated_latex` trailers + citations table (excluding Tier D). Dedup, Unicode normalization, ampersand escaping, DOI underscore escaping. `stripTierDCitations()` replaces Tier D `\cite{key}` with `% UNRESOLVED` comments. **Phase 10 (Appendices) generates chapter file but template never `\input`s it.** **Abbreviations never injected.**
   - `apps/web/lib/latex/compile.ts`  Docker and local modes. Docker: `--network=none --read-only --memory=1g`. 4-pass: `pdflatexbibtexpdflatexpdflatex`. PDF stored at `os.tmpdir()/apollo-pdfs/{id}.pdf` (ephemeral!). **Local mode ignores watermark.**
   - `apps/web/lib/latex/generate-tex.ts`  Fills template placeholders. Adds `\usepackage{mathrsfs}` (NOT installed in Docker!), `amssymb`, `graphicx`. University switching via regex on `\documentclass`.
   - `apps/web/lib/latex/validate.ts`  Pre-flight (`preflightChapter()`): blocks on unescaped `#`, unbalanced braces/environments, markdown headings. AI validation via Haiku (non-blocking).
   - `apps/web/lib/latex/escape.ts`  `escapeLatex()`, `normaliseUnicode()` (full Latin-1/Extended-A mapping + safety net), `escapeBareAmpersands()` (tabular-depth tracking)
   - `apps/web/lib/latex/front-matter.ts`  `generateFrontMatterLatex()` and `generateAcknowledgements()`  **dead code** for compile pipeline (assembly uses `injectFrontMatter()` instead)
   - `apps/web/lib/latex/parse-log.ts`  Compilation log parser: fatal vs non-fatal errors, warning counting
   - `templates/main.tex`  Uses `\input{chapters/...}` for all chapters. **Missing `\input{chapters/appendices}`.**
   - `docker/compile.sh`  Copies files to `/tmp`, runs 4-pass, applies watermark for sandbox via Ghostscript
   
   **R Analysis & Figure Pipeline:**
   - `docker/plumber.R`  9 analysis endpoints: `/descriptive` (NO figures, Table 1 only), `/chi-square`, `/t-test`, `/correlation`, `/survival`, `/roc`, `/logistic`, `/kruskal`, `/meta-analysis` (2 figures: forest+funnel). All produce PDF at 300 DPI. Shapiro-Wilk normality testing for t-test and correlation. `tryCatch()` error handling.
   - `apps/web/lib/r-plumber/analysis-runner.ts`  `executeAnalysis()`: fetches analysis+dataset, calls R Plumber, decodes base64 figures, writes to `os.tmpdir()/apollo-figures/`, inserts figure DB records. `FIGURES_BASE_DIR` is ephemeral. **R2 NOT wired for figures.**
   - `apps/web/lib/r-plumber/client.ts`  R Plumber HTTP client with per-type timeouts (15s-60s), `AbortController`, `RPlumberError` wrapping
   - `apps/web/lib/compute/semaphore.ts`  In-memory admission control. 3 units max, compile=2, analysis=1. Max 2 per user. Queue depth 5. **Queue promotion bug**: resolve callbacks are no-ops `() => {}`, so queued jobs never get promoted.
   - `apps/web/lib/inngest/functions/analysis-runner.ts`  Inngest function for async analysis execution with semaphore release in `finally`
   - `apps/web/components/project/figure-gallery.tsx`  Shows thumbnails for images, placeholder icon for PDFs. **No PDF preview or download link for R-generated figures.**
   - `apps/web/components/project/analysis-wizard.tsx`  Analysis UI with polling every 3s. Shows toast when all complete. Does NOT expose chart_type/colour_scheme options.
   
   **Phase Transitions & QC:**
   - `apps/web/lib/phases/transitions.ts`  `canAdvancePhase()`: checks section approved, license required for Phase 12 (returns `LICENCE_REQUIRED`), blocks beyond Phase 11
   - `apps/web/lib/phases/constants.ts`  Phase definitions
   - `apps/web/lib/qc/final-qc.ts`  `finalQC()` runs 5 checks: citation provenance (blocking), section completeness (non-blocking warning), British English (non-blocking), NBEMS compliance (page count, abstract 300 words, M&M 12 sections), undefined references (blocking). Word count targets differ from PLAN.md (e.g., Phase 2: 500-750 vs PLAN's 750-1000).
   - `apps/web/app/api/projects/[id]/qc/route.ts`  POST runs QC, stores report as JSON in Phase 11 section's `latex_content` field. GET retrieves stored report.
   - `apps/web/app/api/projects/[id]/sections/[phase]/generate/route.ts`  Full generation flow: auth  license gate  token budget check  pre-seed references (phases 2,4,5,7)  fetch analysis context (phase 6)  Claude API streaming  save to 3 columns  auto-resolve citations (15s timeout)  SSE complete event
   - `apps/web/app/api/projects/[id]/sections/[phase]/approve/route.ts`  Approval flow: validates transition, updates phase, fires Inngest event
   - `apps/web/app/api/projects/[id]/sections/[phase]/refine/route.ts`  Same SSE pattern as generate, uses `REFINE_SYSTEM_PROMPT`, includes current content for targeted edits, 10s citation resolution timeout
   
   **Database Migrations (authoritative: `apps/web/supabase/migrations/`):**
   - 23 migration files (001-023)
   - Migration 016: fixes RLS recursion with `SECURITY DEFINER` helper functions  but only for `users` and `projects` tables (9 other tables still use old pattern)
   - Migration 022: `processed_webhooks` table (EXISTS, contrary to initial Part I finding)
   - Migration 023: `review_tokens` and `review_comments` tables
   - Root `supabase/migrations/` has 3 stale files with conflicting numbering

4. Errors and Fixes:
   - **CI Failure**: Last commit `8a900a2` failed CI due to ESLint `prefer-const` error in `lib/citations/auto-resolve.ts:151` (`let tier` should be `const`). Not yet fixed.
   - **Initial incorrect finding**: I initially reported `processed_webhooks` table as MISSING. The schema comparison agent later found it EXISTS in migration 022. I corrected this in the Addendum.
   - **TypeScript check command**: `pnpm --filter apollo-web run typecheck` failed because no "typecheck" script exists. Fixed by running `npx tsc --noEmit` directly (which passed clean).

5. Problem Solving:
   - **Part I Gap Analysis**: Completed and delivered. Identified CI failure, 51 uncommitted files, sprint completion status, security gaps (Docker seccomp, AppArmor, network isolation), schema discrepancies (Clerk vs Supabase Auth, RLS recursion, duplicate migrations).
   - **Part II Deep Dive**: All 5 research agents completed. Data gathered from 80+ files. Major findings synthesized but report NOT yet delivered to user. Key issues found:
     1. Inline math destroyed by round-trip (critical for medical theses with p-values)
     2. `mathrsfs` package not in Docker image
     3. Phase 10 appendices never rendered
     4. Abbreviations never injected
     5. Orphan cite keys bypass Tier D stripping
     6. PDF/figure storage ephemeral (no R2)
     7. No figure download/preview for PDFs
     8. No minimum figure/table requirement
     9. Semaphore queue promotion bug
     10. Word count targets in QC differ from PLAN.md

6. All User Messages:
   - **Message 1**: "check the codebase. Do a gap analysis with /docs/PLAN. Do a git diff. Check last commit CI status. Be thorough, meticulous, and Thinnk ultra hard before you act."
   - **Message 2**: (After Part I delivered) User acknowledged findings, no explicit response text captured. System notifications about agent completions were received.
   - **Message 3**: "I need you to check few other issues in addition as well. Check the actual business code, the thesis generation pipeline, from beginning to end. Focus hard on the AI integration lacunae, AI system prompts which I feel are just bare minimum, the citation pipeline and its integration to the main thesis pipeline, the Refine,Re-verify citations, etc pipelines and their integration to the main pipeline, the Data Analysis pipeline in detail and depth, its weaknesses, failure points, and its integration to the main pipeline. The figure generation pipeline (not just single plots per analysis and none for descriptive), the figure storage and downloadability lacunae. There should be a minimum number of figures and tables requirement per thesis. Flow of each step from the previous one, the stop gap fixes applied in haste in prior coding sessions. Wire up the entire pipeline in your mind, visualise it, and find the issues (eg maybe latex to tiptap back to latex is causing maximum number of issues, and rather than doing this round about way, which was introduced in haste, we can do it better, or differently?) The latex templates are mixed up, the generic university defaults to SSKM or other such issues, the latex packages, fonts , math notations etc may cause issues etc etc. every weak link needs to be identified and planned for removal robustly. Everything needs to be checked against plan and gaps need to identified, but a better solution can supercede minor notes in the plan (eg Clerk instead of supabase auth was by design). All your findings from this pass will then need to be assimilated as part II of the review (part I done above)"

7. Pending Tasks:
   - **Synthesize Part II Report**: All 5 deep-dive agents completed. Their findings need to be compiled into a structured Part II report for the user, covering all the pipelines they requested.
   - **Fix P0 items**: The user hasn't explicitly approved fixing yet, but was asked "Want me to start fixing the P0 items (lint error + commit)?"  no response received before Part II request.
   - **No code changes have been made yet**  this has been purely a research/analysis session.

8. Current Work:
   All 5 deep-dive research agents (AI prompts, citation pipeline, LaTeX pipeline, R analysis/figures, phase transitions) completed successfully. I was about to synthesize their findings into the Part II report when the summary request was triggered. The agents read 80+ files across the entire business logic layer and produced detailed analyses of every pipeline, identifying ~30+ issues of varying severity.

9. Optional Next Step:
   Synthesize the Part II deep-dive report from all 5 completed agents and deliver it to the user. The user explicitly said: "All your findings from this pass will then need to be assimilated as part II of the review (part I done above)". The data is fully gathered; only the synthesis and presentation remains.

If you need specific details from before compaction (like exact code snippets, error messages, or content you generated), read the full transcript at: /Users/devs/.REDACTED.jsonl
Please continue the conversation from where we left off without asking the user any further questions. Continue with the last task that you were asked to work on.

---

<task-notification>
<task-id>a8dc46a</task-id>
<status>completed</status>
<summary>Agent "Audit citation pipeline end-to-end" completed</summary>
<result>Now I have the complete picture. Here is the thorough analysis.

---

## Complete Citation Pipeline Analysis

### 1. File-by-File Content Summary

All 13 files have been read in full. Here is a structural summary before diving into the analysis:

**Library Layer (`/Users/devs/Downloads/Apollo/apps/web/lib/citations/`):**
- **`extract-keys.ts`** -- Simple regex utility. Parses `\cite{key1,key2}` patterns from LaTeX strings, returning unique keys.
- **`crossref.ts`** -- CrossRef integration. `lookupDOI()` fetches BibTeX via content negotiation + structured metadata. `searchCrossRef()` queries by title/keywords. `stripDoiField()` removes DOI fields to avoid vancouver.bst underscore crashes. 10-second AbortController timeout on all network calls.
- **`pubmed.ts`** -- PubMed integration. `lookupPMID()` via esummary, `searchPubMed()` via esearch+esummary two-step. `pubmedArticleToBibtex()` cascades to CrossRef DOI lookup for higher-quality BibTeX. 10-second timeout.
- **`resolve.ts`** -- Core resolution engine. `resolveEntry()` follows a 4-step algorithm: DOI hint -> PMID hint -> title search with 0.85 Levenshtein similarity threshold -> Tier D fallback. `resolveAllEntries()` parses BibTeX, resolves entries in chunks of 3 concurrently.
- **`auto-resolve.ts`** -- Post-generation auto-resolver. `resolveSectionCitations()` splits AI output at `---BIBTEX---`, resolves entries, upserts to DB, then finds orphan `\cite{key}` references and attempts to resolve them too via CrossRef.
- **`pre-seed.ts`** -- Pre-seeds real PubMed references into AI prompts. Builds 2-3 search queries from thesis metadata, fetches articles within an 8-second budget, and formats BibTeX + human-readable summaries for the AI to use.
- **`audit.ts`** -- Pure function bidirectional audit. Checks forward (cite keys in sections not in DB) and reverse (DB citations not referenced in any section). Computes integrity score and identifies Tier D blockers.

**API Route Layer:**
- **`citations/route.ts`** (CRUD) -- GET lists all, POST creates via DOI/PMID/raw-BibTeX with auto-resolution.
- **`citations/[citationId]/route.ts`** -- PUT updates (including attestation which promotes D->C or to B with isbn/url evidence), DELETE removes.
- **`citations/[citationId]/re-resolve/route.ts`** -- POST re-resolves a citation using two strategies: re-resolve from existing BibTeX, then CrossRef search by cite key pattern.
- **`citations/audit/route.ts`** -- POST fetches all sections + citations, runs the pure audit function.
- **`citations/search/route.ts`** -- GET searches CrossRef or PubMed by query string. Returns structured results for the "Add Citation" workflow.

**UI Layer:**
- **`citation-list-panel.tsx`** -- Collapsible panel showing all citations with tier badges, audit button, re-resolve/attest/delete actions per citation. Auto-expands when Tier D citations exist.

---

### 2. Deep Analysis

#### Q: How does AI-generated text trigger citation creation? When AI generates `\cite{key}`, what happens next?

The flow is:

1. **Generation phase** (`/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/sections/[phase]/generate/route.ts`, lines 240-265): For citation-heavy phases (2, 4, 5, 7), the system pre-seeds real PubMed references into the AI prompt via `preSeedReferences()` and `formatReferencesForPrompt()`. The AI is instructed to use these verified references and include a `---BIBTEX---` trailer.

2. **Post-generation save** (lines 373-432): The full AI response (including `---BIBTEX---` trailer) is saved to `ai_generated_latex`, `latex_content`, and `rich_content_json`. Citation keys are extracted from the Tiptap parse and saved to `section.citation_keys[]`.

3. **Auto-resolution** (lines 436-445): `resolveSectionCitations()` is called with a **15-second timeout** (via `Promise.race`). This:
   - Splits the response at `---BIBTEX---`
   - Falls back to regex extraction if no separator found (`fallbackBibtexExtraction`)
   - Resolves each BibTeX entry through CrossRef/PubMed (DOI -> PMID -> title search -> Tier D)
   - Upserts resolved citations to the `citations` table, skipping already-verified ones
   - For any `\cite{key}` in the body without a matching BibTeX entry, creates Tier D placeholders (with a heuristic CrossRef search by key pattern like "smith2023" -> "smith 2023")

4. **Same flow for refine** (`/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/sections/[phase]/refine/route.ts`, line 156): Also calls `resolveSectionCitations()` with a 10-second timeout.

**Key finding: Citation creation is AUTOMATIC on generation/refine.** The user does not need to manually trigger it. However, it runs with a timeout -- if resolution takes too long, it silently drops the result (returns null from Promise.race) and the citations may not be created.

#### Q: Is there automatic resolution on generation, or must the user manually trigger it?

**Automatic.** Both `generate` and `refine` routes call `resolveSectionCitations()` after the AI stream completes. The summary is sent back to the client in the SSE `complete` event. However:

- **Risk 1**: The 15-second (generate) / 10-second (refine) timeout means that for sections with many citations (e.g., Review of Literature with 30+ references), resolution may time out and some citations won't be resolved.
- **Risk 2**: The resolution is fire-and-forget from the SSE stream perspective -- if it times out, the client receives `citationSummary: null` but no explicit error.
- **Risk 3**: No retry mechanism -- if resolution fails, citations remain unresolved until the user manually triggers re-resolve on individual citations.

#### Q: Does the audit actually catch orphaned citations and missing BibTeX entries?

**Yes, but with a critical dependency on `section.citation_keys[]`.** The audit function (`/Users/devs/Downloads/Apollo/apps/web/lib/citations/audit.ts`) works by:

- **Forward check**: Iterating `section.citation_keys[]` for each section and checking if the key exists in the citations table. Missing ones are flagged as `missingCitations`.
- **Reverse check**: Iterating all DB citations and checking if they appear in any section's `citation_keys[]`. Unreferenced ones are flagged as `orphanedCitations`.
- **Tier D blocking**: Any Tier D citation that IS used in sections is flagged as blocking Final QC.

**Potential gap**: The audit relies on `section.citation_keys[]` being accurately maintained. This array is populated from:
- `latexToTiptap().citationKeys` during generation (line 356 of generate route)
- `tiptapToLatex().citationKeys` during rich text save (line 125 of section PUT route)
- `extractCiteKeys()` during raw LaTeX save (line 134 of section PUT route)

If a user edits LaTeX directly and the save route fails to update `citation_keys[]`, the audit would have stale data. However, the code does correctly extract keys on every save, so this is well-covered.

**The audit does NOT directly scan LaTeX content** -- it only uses the pre-computed `citation_keys[]` array. This is a design choice for performance (pure function, no I/O, trivially testable), but means the accuracy depends on the save pipeline always keeping `citation_keys[]` in sync.

#### Q: How are citations integrated into the compile pipeline? Where does `bibtex_entry` get assembled?

The compile pipeline is in `/Users/devs/Downloads/Apollo/apps/web/lib/latex/assemble.ts`:

**BibTeX assembly** (lines 410-523) collects from TWO sources:

1. **Section BibTeX trailers** (lines 491-498): For each chapter section, it prefers `ai_generated_latex` (preserves the original `---BIBTEX---` trailer even after user edits) over `latex_content`, then splits at the separator to extract BibTeX entries.

2. **Citations table** (lines 501-506): Iterates all `Citation` records. Includes only entries where `bibtex_entry` is non-empty AND `provenance_tier !== "D"`. Tier D entries are explicitly excluded.

**Deduplication** (line 510): `deduplicateBibEntries()` uses last-write-wins, so citations table entries (appended after section entries) override AI-generated ones. This is the correct ordering -- verified entries from CrossRef/PubMed should supersede raw AI BibTeX.

**Sanitization chain** (lines 514-520): `normaliseUnicode` -> `escapeBareAmpersands` -> `escapeDOIUnderscores`. This handles the common failure modes documented in MEMORY.md.

**Tier D handling** (lines 413-477): Tier D cite keys are identified, and their `\cite{key}` commands are stripped from chapter bodies and replaced with `% UNRESOLVED` comments. This prevents LaTeX "undefined citation" errors during compilation. The `stripTierDCitations` function correctly handles multi-key citations like `\cite{a,b,c}` -- it keeps non-D keys and only removes D keys.

#### Q: Is re-resolve actually wired up and functional?

**Yes.** The full chain is:

1. **UI**: `citation-list-panel.tsx` (lines 136-154) has a `handleReResolve` function that calls `POST /api/projects/:id/citations/:citationId/re-resolve`. The button only appears for Tier D citations (line 306).

2. **API Route**: `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/citations/[citationId]/re-resolve/route.ts` implements a 3-strategy approach:
   - **Strategy 1** (lines 47-69): Re-resolve from existing BibTeX via `resolveAllEntries()`. If the entry resolves to non-D, update the citation.
   - **Strategy 2** (lines 72-104): Parse the cite key pattern (e.g., `kumar2023` -> `kumar 2023`) and search CrossRef. If a DOI result is found, update to **Tier B** (not A -- because it's a heuristic match, not a DOI/PMID from the BibTeX itself).
   - **Strategy 3** (lines 107-109): Return a message telling the user to attest manually or replace.

**Observation**: Strategy 2 uses Tier B (not A) for CrossRef search matches, which is correct -- the match is heuristic. However, there's no title similarity check here unlike in `resolveEntry()`, so it could potentially assign a wrong paper to the cite key. The `searchCrossRef()` call with just "kumar 2023" could return any paper with those terms.

#### Q: What happens when CrossRef/PubMed APIs fail? Retry logic? Graceful degradation?

**There is NO explicit retry logic.** Every API call is wrapped in try/catch with a 10-second AbortController timeout:

- **CrossRef `lookupDOI()`** (crossref.ts line 137): Returns `null` on any error.
- **CrossRef `searchCrossRef()`** (crossref.ts line 182): Returns `{ items: [], totalResults: 0 }` on any error.
- **PubMed `lookupPMID()`** (pubmed.ts line 94): Returns `null` on any error.
- **PubMed `searchPubMed()`** (pubmed.ts line 158): Returns `{ items: [], totalResults: 0 }` on any error.

**Graceful degradation**: When APIs fail, the resolution algorithm continues to the next strategy:
- DOI fails -> try PMID -> try title search -> fall back to Tier D
- This is solid -- no single API failure crashes the pipeline.

**Pre-seed failures** are explicitly non-blocking (generate route line 262-264: `console.warn("Pre-seed references failed (non-blocking):")`).

**Auto-resolution failures** (generate route lines 438-445): Wrapped in try/catch with a timeout. If it fails or times out, `citationSummary` is just null.

**Missing**: No exponential backoff, no retry queue, no circuit breaker. If CrossRef is down during generation, all citations for that session fall to Tier D. The user's only recourse is manual re-resolve later. This is acceptable for the current scale but could be improved with a background job queue.

#### Q: Is there a gap between citation keys in generated LaTeX and actual citation DB records?

**Yes, and this is by design.** The system handles this through the "Tier D placeholder" mechanism:

1. When AI generates `\cite{smith2023}` in the body but the `---BIBTEX---` trailer doesn't include a matching entry (or has no trailer at all), the auto-resolve creates a Tier D placeholder for `smith2023`.

2. The audit catches any remaining gaps: `missingCitations` reports keys used in sections but not in the DB.

3. During compilation, Tier D citations are stripped from the output and replaced with `% UNRESOLVED` comments.

**Potential gap**: If auto-resolution times out (15 seconds), some cite keys may not get Tier D placeholders created at all. In this case:
- The `section.citation_keys[]` array WILL contain the key (it's extracted from the Tiptap parse, not from the resolution).
- The audit WILL flag it as missing.
- But the compile pipeline WON'T strip it -- `stripTierDCitations` only removes keys that are in the `citations` table as Tier D. A key with NO DB record at all would survive as a `\cite{key}` in the chapter body, causing an "undefined citation" warning from BibTeX.

This is a **real bug**: if auto-resolution times out before creating Tier D placeholders for orphan keys, those `\cite{}` commands persist through to compilation and produce BibTeX warnings.

#### Q: How does pre-seed work and when is it called?

**`preSeedReferences()`** (`/Users/devs/Downloads/Apollo/apps/web/lib/citations/pre-seed.ts`):

1. **When**: Called during generation for phases 2 (Introduction), 4 (Review of Literature), 5 (M&M), and 7 (Discussion). ROL gets 30 max refs; others get 20.

2. **How**:
   - Builds 2-3 PubMed queries of decreasing specificity from project metadata (title keywords + study type, keywords, department + keywords).
   - Runs all queries in parallel via `Promise.allSettled`.
   - Deduplicates by PMID.
   - Converts each article to BibTeX (cascading to CrossRef DOI lookup for higher quality).
   - Respects an 8-second time budget.
   - Generates unique cite keys in `surname+year` format with a/b/c suffixes for collisions.

3. **Integration**: `formatReferencesForPrompt()` produces two blocks appended to the user message:
   - `--- AVAILABLE REFERENCES ---`: Human-readable list with `\cite{key}` mappings.
   - `--- PRE-SEEDED BIBTEX ---`: Full BibTeX entries the AI should include in its `---BIBTEX---` trailer.

4. **Important**: Pre-seeded references are NOT automatically saved to the `citations` table. They're only included in the AI prompt. If the AI uses them and includes them in the `---BIBTEX---` trailer, THEN `resolveSectionCitations()` will resolve and upsert them. If the AI ignores a pre-seeded reference, it simply isn't used. This is correct -- pre-seeding is a suggestion, not a commitment.

#### Q: What's the UX flow for Tier B/C/D citations?

**Tier D (Unverified):**
- Created automatically when resolution fails (CrossRef + PubMed both come up empty or the entry lacks DOI/PMID and title search yields no >85% match).
- UI: The `citation-list-panel.tsx` auto-expands when Tier D citations exist. Shows amber warning box explaining options. Each Tier D citation gets three action buttons: Re-resolve (RefreshCw icon), Attest (ClipboardCheck icon), Delete (Trash2 icon).
- Re-resolve: Calls the re-resolve API which retries BibTeX resolution + CrossRef search by key pattern.
- Attest: Calls PUT with `{ attested: true, evidence_type: "manual" }`, which promotes D -> C.
- Delete: Removes the citation record entirely.
- Tier D citations block Final QC only (Phase 11).
- During compilation, Tier D `\cite{}` commands are stripped and replaced with comments.

**Tier C (Attested):**
- Created when a user attests a Tier D citation without providing external evidence (or with `evidence_type: "manual"`).
- In the PUT route (`/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/citations/[citationId]/route.ts`, lines 59-75): if `attested: true` and evidence_type is "manual" or the existing tier is D, it promotes to C.
- Tier C citations ARE included in compilation (they're not excluded by the `provenance_tier !== "D"` filter in assemble).

**Tier B (Confirmed):**
- Created when a user attests with evidence_type "isbn" or "url" (lines 67-68 of the PUT route).
- Also created by re-resolve Strategy 2 when a CrossRef search match is found (re-resolve route line 97: `provenance_tier: "B"`).
- Included in compilation.

**Tier A (Verified):**
- Created when DOI or PMID lookup succeeds during resolution.
- Has `verified_at` timestamp set.
- The gold standard -- these have verified provenance from authoritative databases.

---

### 3. Summary of Identified Issues

**Critical Bug -- Orphan keys without DB records bypass Tier D stripping:**
In `/Users/devs/Downloads/Apollo/apps/web/lib/latex/assemble.ts`, `stripTierDCitations()` only strips keys that are in the `citations` table as Tier D. If `resolveSectionCitations()` times out before creating Tier D placeholders for orphan cite keys, those `\cite{key}` commands persist in the compiled output and produce "undefined citation" BibTeX warnings. The fix would be to also strip cite keys that exist in `section.citation_keys[]` but have NO matching record in the citations table at all.

**Medium -- No retry logic for API failures:**
All CrossRef/PubMed calls are one-shot with timeout. A transient network failure during generation permanently loses resolution for that batch. A background retry queue (via Inngest, which is already in the stack) would help.

**Medium -- Re-resolve Strategy 2 lacks title verification:**
The re-resolve route searches CrossRef by key pattern ("kumar 2023") and takes the first result with a DOI, without checking title similarity. This could assign the wrong paper. The `resolveEntry()` function in resolve.ts correctly uses a 0.85 title similarity threshold -- re-resolve should do the same.

**Low -- Pre-seeded references not persisted to DB:**
Pre-seeded references are only injected into the AI prompt. If the AI uses a pre-seeded reference but doesn't include it in the `---BIBTEX---` trailer (possible if the trailer gets truncated by token limits), the cite key will become a Tier D orphan or go missing entirely. Persisting pre-seeded references to the citations table upfront (as Tier A, since they came from PubMed with DOIs) would be more robust.

**Low -- Timeout budget mismatch:**
Generation has a 15-second timeout for resolution, but ROL phase has up to 30 pre-seeded refs and potentially 30+ AI-generated refs. Each ref requires up to 3 network calls (DOI lookup + PMID lookup + title search), with concurrency limited to 3. This could easily exceed 15 seconds for 30+ citations.</result>
<usage>total_tokens: 68567
tool_uses: 29
duration_ms: 168792</usage>
</task-notification>
Full transcript available at: /private/tmp/claude-501/-Users-devs-Downloads-Apollo/tasks/a8dc46a.output

---

<task-notification>
<task-id>a3d46a3</task-id>
<status>completed</status>
<summary>Agent "Audit AI prompts and generation" completed</summary>
<result>Now I have a thorough understanding of the entire AI integration. Here is my comprehensive critical analysis.

---

## Critical Analysis: Apollo AI Integration for Thesis Generation

### FILE 1: `/Users/devs/Downloads/Apollo/apps/web/lib/ai/prompts.ts`

**Complete content**: Shown in full above (440 lines). Contains 12 exported prompts/functions:
- `COMMON_RULES` (shared LaTeX rules)
- `SYNOPSIS_PARSE_SYSTEM_PROMPT` (Phase 0)
- `FRONT_MATTER_SYSTEM_PROMPT` (Phase 1)
- `INTRODUCTION_SYSTEM_PROMPT` (Phase 2)
- `AIMS_SYSTEM_PROMPT` (Phase 3)
- `ROL_SYSTEM_PROMPT` (Phase 4)
- `MATERIALS_METHODS_SYSTEM_PROMPT` (Phase 5)
- `RESULTS_SYSTEM_PROMPT` (Phase 6)
- `DISCUSSION_SYSTEM_PROMPT` (Phase 7)
- `CONCLUSION_SYSTEM_PROMPT` (Phase 8)
- `APPENDICES_SYSTEM_PROMPT` (Phase 10)
- `REFINE_SYSTEM_PROMPT` (editing)
- `DATASET_GENERATION_SYSTEM_PROMPT` (synthetic data)
- `getPhaseSystemPrompt()` and `getPhaseUserMessage()` functions

#### Strengths

1. **Comprehensive structure**: Each phase has a detailed structural template with numbered subsections. The prompts are not bare-minimum placeholders -- they specify exact section ordering, LaTeX formatting conventions, and content expectations.

2. **Citation handling is well-designed**: The `---BIBTEX---` separator convention is explicit and consistent. Every citation-heavy phase includes a mandatory BibTeX trailer instruction with example format. The system correctly instructs `\cite{key}` usage rather than hardcoded numbers.

3. **British English is enforced at multiple layers**: In `COMMON_RULES` rule #1, in the synopsis parser, and then validated post-generation by `review-section.ts` and `final-qc.ts`.

4. **Word count enforcement**: Each prompt specifies a target range AND a hard limit (e.g., Introduction: 700-1,200 words, hard limit 1,380). The hard limits correctly note that BibTeX entries don't count.

5. **Medical domain specificity**: NBEMS 12-section requirement for Materials & Methods, ICMR 2017 guidelines, ethics statement templates, STROBE/CONSORT references, PICO format for aims -- these are all genuinely useful for Indian medical PG theses.

6. **GOLD Standard methodology**: The 12-phase pipeline is fully represented. Each prompt specifies tense conventions (past for M&M/Results, present for Introduction, mixed for Discussion).

#### Critical Issues

**ISSUE 1: Phase 9 (References) is completely missing.**

In `getPhaseSystemPrompt()`, there is no `case 9`. The plan specifies Phase 9 as "References" but there is no prompt for it. The switch statement jumps from Phase 8 (Conclusion) to Phase 10 (Appendices). This means the references phase is either handled entirely by the BibTeX aggregation pipeline or is simply skipped. Given that citation management is core to the product, this gap is concerning -- there should at least be a prompt that consolidates and validates all BibTeX entries across chapters.

**ISSUE 2: Phase 6a (Dataset) and 6b (Results) are conflated.**

The PLAN.md specifies Phase 6a (Dataset generation) and Phase 6b (Results writing) as separate sub-phases. But `getPhaseSystemPrompt(6)` returns `RESULTS_SYSTEM_PROMPT`. There is no Phase 6a prompt in the switch statement. Dataset generation uses a separate prompt (`DATASET_GENERATION_SYSTEM_PROMPT`) but is invoked through a completely different API route (`/datasets/generate`), not through the phase pipeline. This means the phase numbering is inconsistent with the plan.

**ISSUE 3: Results prompt lacks specificity about analysis integration.**

The `RESULTS_SYSTEM_PROMPT` says "Include R-generated `\texttt{table\_latex}` content VERBATIM" but doesn't provide structured guidance on how to integrate multiple analysis types. For a thesis with descriptive stats, chi-square, ROC, and logistic regression, the prompt gives no ordering guidance beyond the generic structure. The user message in `getPhaseUserMessage(6)` doesn't mention analysis context at all -- that injection happens only in the route handler. The prompt should acknowledge that analysis summaries will be appended.

**ISSUE 4: Previous section context is truncated to 3,000 characters per section.**

In `getPhaseUserMessage()`, line 376:
```typescript
.map((s) => `--- ${s.phaseName} ---\n${s.content.slice(0, 3000)}`)
```

For the Review of Literature (which can be 3,500-4,500 words / ~20,000+ characters), only the first ~500 words are passed as context to subsequent phases. This means the Discussion chapter -- which must compare findings with literature -- receives almost no ROL context. For a thesis generation product, this is a severe quality limitation.

**ISSUE 5: No prompt for Phase 11 (Final QC) AI-assisted fixes.**

The QC route at `/api/projects/[id]/qc/route.ts` calls `finalQC()` which is purely deterministic. There is a `/qc/fix` route in the file listing, but the QC fix prompt is absent from `prompts.ts`. The plan likely envisions AI-assisted auto-fixes (e.g., replacing American spellings, expanding thin sections), but there is no AI prompt for this.

**ISSUE 6: Synopsis parse prompt is duplicated.**

`SYNOPSIS_PARSE_SYSTEM_PROMPT` in `prompts.ts` extracts `title, study_type, department, objectives, methodology_summary, sample_size, duration, setting, keywords`. But the standalone `/api/synopsis/parse/route.ts` uses a completely different inline prompt (`SYNOPSIS_WIZARD_PROMPT`) that extracts a different schema: `title, aims, objectives, study_type, study_design, sample_size, inclusion_criteria, exclusion_criteria, methodology_summary`. The two prompts disagree on field names and structure. This is confusing and error-prone -- which one is the source of truth?

**ISSUE 7: `COMMON_RULES` should include Unicode avoidance.**

The project's MEMORY.md documents that Unicode in LaTeX causes critical BibTeX failures ("Invalid UTF-8 byte sequence"). But `COMMON_RULES` never tells the AI to avoid Unicode characters. The escaping happens downstream in `escape.ts`, but preventing it at the source would reduce compilation failures.

---

### FILE 2: `/Users/devs/Downloads/Apollo/apps/web/lib/ai/client.ts`

**Complete content**: 14 lines. A singleton factory for the Anthropic SDK client.

```typescript
let _client: Anthropic | null = null;

export function getAnthropicClient(): Anthropic {
  if (!_client) {
    const apiKey = process.env.ANTHROPIC_API_KEY;
    if (!apiKey) throw new Error("ANTHROPIC_API_KEY environment variable is not set");
    _client = new Anthropic({ apiKey });
  }
  return _client;
}
```

#### Critical Issues

**ISSUE 1: `datasets/generate.ts` bypasses the singleton.**

Line 82 of `generate.ts`: `const anthropic = new Anthropic();` -- this creates a new client instance directly instead of using `getAnthropicClient()`. Same for `compliance/checker.ts` line 166: `const anthropic = new Anthropic();`. This means those call sites rely on the `ANTHROPIC_API_KEY` environment variable being auto-detected by the SDK's constructor, which is a different code path. It works, but it's inconsistent and means changes to the singleton (e.g., adding request timeout defaults, custom headers, or retry configuration) won't apply everywhere.

**ISSUE 2: No retry configuration.**

The Anthropic SDK supports automatic retries. The client is created with only `{ apiKey }` -- no `maxRetries`, no `timeout` configuration. For a production service where AI generation takes 10-30 seconds and can be rate-limited by Anthropic, this is risky. A transient 429 or 500 from Anthropic will immediately fail the generation.

**ISSUE 3: No base URL override for testing.**

There's no way to point the client at a mock server during tests. The `ANTHROPIC_API_URL` env var would work through the SDK, but there's no documentation or test helper for this.

---

### FILE 3: `/Users/devs/Downloads/Apollo/apps/web/lib/ai/review-section.ts`

**Complete content**: 315 lines. A **purely local, deterministic** review system -- no AI API calls despite the file name.

#### Architecture

The review runs 5 checks:
1. **Citation diff**: Compares current vs AI-generated citation keys, warns on removals/additions
2. **Word count**: Checks against phase-specific targets from `word-count-targets.ts`
3. **Structure checks**: Phase-specific structural validation (ROL needs longtable, M&M needs 8+ sections, Discussion needs strengths/limitations, Conclusion needs recommendations)
4. **British English spot-check**: 21 American-to-British spelling patterns
5. **Citation quality**: Checks Tier D ratio and missing keys in DB

#### Critical Issues

**ISSUE 1: The name "review-section" is misleading.**

The PLAN.md and the code comments on the generate route (line 283: "Haiku used separately for QC/review -- see review route") suggest this should include an AI-powered review step. But the actual review route at `/api/projects/[id]/sections/[phase]/review/route.ts` calls only the local `reviewSection()` function. There is **no AI-powered review of section quality**. The AI validation via Haiku exists in `validate.ts`, but it's for LaTeX syntax checking during compilation, not for content quality review. This means the product has no AI-assisted feedback on whether the Introduction adequately covers the knowledge gap, whether the Discussion sufficiently addresses limitations, etc.

**ISSUE 2: The M&M section check requires only 8 sections, but the prompt mandates 12.**

The review check on line 138: `if (sectionCount < 8)` -- but the `MATERIALS_METHODS_SYSTEM_PROMPT` specifies "MANDATORY 12 sections (NBEMS requirement)". The final QC in `final-qc.ts` checks for `< 12`. There's an inconsistency: the mid-pipeline review is lenient (8) while final QC is strict (12).

**ISSUE 3: Word count targets disagree across files.**

In `word-count-targets.ts`:
- Phase 2 (Introduction): min 750, max 1200
- Phase 3 (Aims): min 200, max 500
- Phase 8 (Conclusion): min 400, max 800

In `final-qc.ts`:
- Phase 2 (Introduction): min 500, max 750
- Phase 3 (Aims): min 150, max 200
- Phase 8 (Conclusion): min 500, max 750

These two modules have **completely different word count targets**. The mid-pipeline review uses `word-count-targets.ts` (more generous), while the final QC uses its own hardcoded values (more restrictive). A section could pass mid-pipeline review but fail final QC on the same metric. The Introduction target in `final-qc.ts` (500-750 words) is also below the prompt's instruction (700-1,200 words), meaning the AI will generate content that the QC considers "over target".

**ISSUE 4: British English list is duplicated.**

The same 21-entry American-to-British dictionary exists in both `review-section.ts` (lines 192-215) and `final-qc.ts` (lines 36-58). This should be a shared constant. More importantly, the list misses common medical terms like "gynecology/gynaecology", "hematology/haematology", "edema/oedema", "diarrhea/diarrhoea", "leukocyte/leucocyte".

---

### FILE 4: `/Users/devs/Downloads/Apollo/apps/web/lib/ai/token-budget.ts`

**Complete content**: 124 lines.

**Limits**:
- 100,000 output tokens per phase
- 1,200,000 total tokens per thesis

#### How It Works

`checkTokenBudget()` queries the `ai_conversations` table to sum `total_tokens` (input + output combined) per project and per phase. If either limit is exceeded, it returns `{ allowed: false }`.

`recordTokenUsage()` inserts a row into `ai_conversations` with `messages_json: []` (always empty) and links the conversation to the section.

#### Critical Issues

**ISSUE 1: Token budget is checked but records input+output as a single sum.**

Line 342-344 of the generate route:
```typescript
const totalTokens = (finalMessage.usage?.input_tokens ?? 0) + (finalMessage.usage?.output_tokens ?? 0);
```

The budget limits say "100K output tokens per phase" but the recording combines input AND output. A single generation call for the ROL chapter with a large synopsis + pre-seeded references could easily use 10,000+ input tokens. This inflates the recorded usage, making the budget artificially tighter. The variable names and documentation say "output tokens" but the implementation counts both.

**ISSUE 2: Refinement calls don't record token usage.**

The refine route (`/sections/[phase]/refine/route.ts`) does not call `checkTokenBudget()` or `recordTokenUsage()`. A student could refine a section unlimited times, consuming unlimited tokens, and the budget system would never know. This is a cost-control blind spot.

**ISSUE 3: Dataset generation doesn't record token usage.**

`/datasets/generate/route.ts` calls `generateDataset()` which calls Claude directly without any budget check or recording.

**ISSUE 4: Synopsis parsing (Phase 0) doesn't record token usage.**

The `handlePhase0Generate()` function in the generate route streams Sonnet without calling `recordTokenUsage()`.

**ISSUE 5: `messages_json` is always empty -- no conversation persistence.**

The `ai_conversations` table has a `messages_json` column, but `recordTokenUsage()` always inserts `messages_json: []`. The column exists in the schema but is never populated. This means:
- There is **zero conversation history** stored
- There is **no multi-turn capability** -- every generation is a single-turn request
- The "AI conversation persistence" mentioned in the table design is entirely unused

---

### FILE 5: `/Users/devs/Downloads/Apollo/apps/web/lib/ai/analysis-explanations.ts`

**Complete content**: 67 lines. A static dictionary of "ELI15" (Explain Like I'm 15) descriptions for 9 analysis types: descriptive, chi-square, t-test, correlation, survival, roc, logistic, kruskal, meta-analysis.

Each entry has:
- `title`: Display name
- `eli15`: Plain-language explanation
- `when`: Guidance on when to use it

#### Assessment

This is well-written educational content. The explanations are genuinely helpful for medical PG students without statistics backgrounds. The "when" descriptions correctly guide usage.

**Minor issue**: The `suggested_figures` field in the auto-detect prompt (line 114 of `auto-detect/route.ts`) references chart types like `violin` and `heatmap`, but the ELI15 dictionary doesn't explain these visualization types. The analysis-to-figure mapping guidance exists only in the AI prompt, not in the user-facing explanations.

---

### FILE 6: `/Users/devs/Downloads/Apollo/apps/web/lib/ai/parse-synopsis-response.ts`

**Complete content**: 38 lines. Parses Claude's JSON response from synopsis parsing with:
- Markdown code fence stripping (`\`\`\`json ... \`\`\``)
- Type-safe field extraction with `typeof` guards
- Array filtering for `objectives` and `keywords`
- Returns `null` on parse failure (graceful degradation)

#### Assessment

This is clean, defensive code. It correctly handles the common Claude behavior of wrapping JSON in markdown fences.

**Issue**: There is no validation that the parsed `study_type` matches known types. The synopsis prompt suggests specific types ("Cross-sectional", "Prospective cohort", etc.) but the parser accepts any string. Downstream code may depend on specific study type values for analysis recommendations.

---

### FILE 7: `/Users/devs/Downloads/Apollo/apps/web/lib/ai/redact.ts`

**Complete content**: 43 lines. Redacts 4 types of Indian PII:
- Phone numbers (Indian +91 format, 10-digit)
- Aadhaar numbers (12 digits with optional separators)
- Email addresses
- PAN numbers (5 letters + 4 digits + 1 letter)

#### Assessment

This is appropriate for the Indian market. The regex patterns are correct.

**Issues**:
1. **No address redaction**: Indian postal addresses with PIN codes could be present in synopses.
2. **No name redaction**: Patient names in case reports within the synopsis would pass through unredacted. For DPDP Act compliance (referenced in the governance docs), this could be a gap.
3. **The Aadhaar regex is too broad**: `\b\d{4}[\s-]?\d{4}[\s-]?\d{4}\b` would match any 12-digit number, including ICD codes, statistical values, etc. It could false-positive on legitimate data.
4. **Redaction runs only on synopsis text before generation** -- it does not run on the AI output. If the AI somehow regenerates PII-like patterns, they pass through to the database unredacted.

---

### Model Routing Analysis

From the grep results across the codebase:

| Use Case | Model | Correct per Plan? |
|---|---|---|
| Synopsis parse (Phase 0) | Sonnet 4.5 | Should be Haiku for simple extraction |
| Section generation (Phases 1-8) | Sonnet 4.5 for ALL | **Wrong** -- Plan says Opus for Intro/Discussion |
| Refine/editing | Sonnet 4.5 | Acceptable |
| Auto-detect analyses | Haiku 4.5 | Correct |
| LaTeX validation | Haiku 4.5 | Correct |
| Compliance checking | Haiku 4.5 | Correct |
| Dataset generation | Sonnet 4.5 | Overkill -- Haiku would suffice |
| Synopsis wizard (/synopsis/parse) | Sonnet 4.5 | Should be Haiku |

The critical TODO on line 285 of the generate route:
```typescript
const model = [2, 7].includes(phaseNumber)
    ? "claude-sonnet-4-5-20250929" // TODO: Switch to Opus when API access available
    : "claude-sonnet-4-5-20250929";
```

This is a dead conditional. Both branches return the same model. The comment acknowledges the plan calls for Opus on Introduction (Phase 2) and Discussion (Phase 7), but it's unimplemented. This means the highest-stakes chapters (Introduction and Discussion are the most academically demanding, requiring nuanced synthesis of literature) are generated with the same model as simpler chapters like Aims.

---

### SSE Streaming Analysis

Streaming is properly implemented. The pattern is:

1. Create a `ReadableStream` with an `async start()` controller
2. Use `client.messages.stream()` for incremental text delivery
3. Emit SSE events: `data: {"type": "delta", "text": "..."}` for chunks
4. Emit `data: {"type": "complete", ...}` with metadata at the end
5. Emit `data: [DONE]` as the terminal signal
6. On error: reset section status to "draft", emit error event
7. On client disconnect (`cancel()`): reset section status if stream hadn't completed

**This is well-engineered.** The cancel handler and stale detection (2-minute timeout for stuck "generating" status) are good production safeguards. Prompt caching via `cache_control: { type: "ephemeral" }` on the system prompt is correctly applied for cost savings.

**Issues with streaming**:
1. Phase 0 (synopsis parse) is streamed, but the response is JSON -- there's no benefit to streaming JSON incrementally to the client. It could be a regular request.
2. The refine route correctly avoids setting "generating" status, with a comment explaining why. Good defensive design.

---

### Summary of Most Critical Findings

1. **No AI-powered content quality review** -- The review system is purely rule-based. There is no AI feedback on whether the content is academically sound, properly argues the thesis, or adequately covers the topic.

2. **Opus model routing is unimplemented** -- Introduction and Discussion (the most important chapters) use the same model as everything else. The conditional is dead code.

3. **Zero conversation persistence** -- The `ai_conversations` table schema supports multi-turn, but every generation is single-turn. `messages_json` is always empty. There is no iterative dialogue with the AI.

4. **Token budget has 4 blind spots** -- Refine, dataset generation, synopsis parsing, and auto-detect all bypass budget tracking. Only initial section generation records usage.

5. **Word count targets are inconsistent across 3 locations** -- `prompts.ts`, `word-count-targets.ts`, and `final-qc.ts` all specify different ranges for the same phases. A section could be compliant in one check and non-compliant in another.

6. **Previous section context is brutally truncated** -- 3,000 characters per section means the Discussion chapter has almost no knowledge of the Review of Literature it's supposed to reference.

7. **Phase 9 (References) has no AI prompt** -- Citation consolidation is apparently handled without AI guidance.

8. **Synopsis parse prompt is duplicated with different schemas** -- Two different routes parse synopses with incompatible field structures.

9. **The `COMMON_RULES` don't warn about Unicode** -- Despite Unicode being documented as a critical BibTeX-breaking issue, the AI is never told to avoid it.

10. **Input tokens are counted against output budget limits** -- The token budget system conflates input and output tokens but describes its limits as "output tokens per phase".</result>
<usage>total_tokens: 73948
tool_uses: 35
duration_ms: 180389</usage>
</task-notification>
Full transcript available at: /private/tmp/claude-501/-Users-devs-Downloads-Apollo/tasks/a3d46a3.output

---

<task-notification>
<task-id>a5afa5e</task-id>
<status>completed</status>
<summary>Agent "Audit R analysis and figure pipeline" completed</summary>
<result>Now I have a complete picture. Let me provide the thorough analysis.

---

## Complete Analysis: R Analysis + Figure Pipeline

### FILE CONTENTS SUMMARY

All 19 files have been read in full. Here is the complete trace of every moving part.

---

## R ANALYSIS PIPELINE

### Endpoints Implemented in plumber.R

`/Users/devs/Downloads/Apollo/docker/plumber.R` implements **9 endpoints** plus a health check:

| # | Endpoint | R Libraries | Figures Produced | Table LaTeX | Summary JSON |
|---|----------|------------|-----------------|-------------|-------------|
| 1 | `POST /descriptive` | gtsummary | **None** (empty list) | Yes (Table 1) | Yes (tbl_summary data frame) |
| 2 | `POST /chi-square` | base R (chisq.test/fisher.test), ggplot2 | 1 PDF (bar or heatmap) | Yes | Yes (test name, p-value, contingency table) |
| 3 | `POST /t-test` | base R (t.test/wilcox.test), ggplot2 | 1 PDF (box, violin, or bar) | Yes | Yes (test name, p-value, statistic, CIs, normality) |
| 4 | `POST /correlation` | base R (cor.test), ggplot2 | 1 PDF (scatter + regression line) | Yes | Yes (method, r, p-value, CI, n) |
| 5 | `POST /survival` | survival, survminer | 1 PDF (KM curve + risk table) | Yes (median survival) | Yes (median survival, log-rank p, n, events) |
| 6 | `POST /roc` | pROC, ggplot2 | 1 PDF (ROC curve) | Yes | Yes (AUC, CI, optimal cutoff coords) |
| 7 | `POST /logistic` | broom, ggplot2 | 1 PDF (forest plot of ORs) or 0 if only intercept | Yes (coefficients table) | Yes (coefficients, model fit, formula) |
| 8 | `POST /kruskal` | base R (kruskal.test, pairwise.wilcox.test), ggplot2 | 1 PDF (boxplot) | Yes | Yes (H statistic, df, p-value, post-hoc p-values) |
| 9 | `POST /meta-analysis` | meta | **2 PDFs** (forest plot + funnel plot) | Yes (fixed + random effects) | Yes (fixed/random effects, heterogeneity I2/tau2/Q) |

**Key finding: Descriptive statistics produces NO figures** -- only a LaTeX table (Table 1) and summary JSON. All other tests produce at least one figure.

### Sprint 7 Types (descriptive, chi-square, t-test, survival): ALL IMPLEMENTED AND WORKING

- **Descriptive**: Uses `gtsummary::tbl_summary()`. Groups by a column if provided, adds `add_p()` and `add_overall()`. Produces Table 1.
- **Chi-square**: Auto-selects Fisher's exact test when any expected cell count < 5. Supports bar chart or heatmap via `chart_type` parameter.
- **T-test**: Auto-selects Wilcoxon rank-sum test via **Shapiro-Wilk normality testing** (lines 262-264). If both groups pass normality (p > 0.05), uses t-test; otherwise Wilcoxon. Supports box, violin, or bar chart types.
- **Survival**: Full Kaplan-Meier with `survfit`, `ggsurvplot` (risk table included), and log-rank test via `survdiff`. Group stratification is optional.

### Sprint 8 Types (ROC, logistic, Kruskal-Wallis, meta-analysis): ALL IMPLEMENTED AND WORKING

- **ROC**: Uses `pROC::roc()`, calculates AUC with CI, finds optimal cutoff via Youden's index (`coords(roc_obj, "best")`).
- **Logistic**: Supports comma-separated multiple predictors, falls back to all-other-columns if none specified. Forest plot shows odds ratios with CI on log scale.
- **Kruskal-Wallis**: Non-parametric ANOVA alternative. Post-hoc uses `pairwise.wilcox.test` with Bonferroni correction (not Dunn's test per se, but the base R equivalent).
- **Meta-analysis**: Uses `meta::metagen()`. Produces BOTH forest plot and funnel plot. Warns when I2 > 75% (high heterogeneity).

Additionally, **correlation** is implemented as a bonus type (not explicitly listed in Sprint 7-8 but fully functional with auto Pearson/Spearman selection via Shapiro-Wilk).

### Figure Format

All figures are produced as **PDF at 300 DPI** via `ggsave(..., dpi = 300, device = "pdf")` (line 40 of `plumber.R`). The helper function `save_plot_base64()` saves to a temp file, base64-encodes it, then deletes the temp file. Survival and meta-analysis use manual `pdf()` + `dev.off()` because they use specialized plot functions (`ggsurvplot`, `forest`, `funnel`) that don't go through `ggsave`.

### Shapiro-Wilk Normality Testing

**Yes, implemented** for:
- **T-test** (lines 262-264): Tests normality of each group separately. Falls back to Wilcoxon if either group fails.
- **Correlation** (lines 357-359): Tests normality of both variables. Falls back to Spearman if either fails.

The normality test results are included in the summary JSON (e.g., `normality: { group1_normal, group2_normal }` for t-test) and a warning is emitted when the non-parametric alternative is used.

### Error Handling

Every R endpoint is wrapped in `tryCatch()`. On error, the endpoint returns `list(error = e$message)`. The client-side (`/Users/devs/Downloads/Apollo/apps/web/lib/r-plumber/client.ts`) checks for this:

```typescript
// Line 52 in client.ts
if (result.error) {
  throw new RPlumberError(`R analysis error: ${String(result.error)}`);
}
```

The `executeAnalysis()` function in `analysis-runner.ts` catches all errors and writes them to the database:

```typescript
// Lines 259-265 in analysis-runner.ts
await supabase.from("analyses").update({
  status: "failed",
  results_json: { error: errorMessage },
}).eq("id", analysisId);
```

The analysis wizard UI (`analysis-wizard.tsx`) polls for status changes every 3 seconds and displays failed/completed states with appropriate icons and toast notifications. **Error messages from R do surface to the user** through this chain.

Additional safety mechanisms:
- R Plumber sets `setTimeLimit()` per endpoint (15s descriptive, 30s chi-square/t-test/correlation/kruskal, 45s survival/roc/logistic, 60s meta-analysis)
- Client-side `AbortController` timeout enforced per analysis type (matching values in `ANALYSIS_TIMEOUTS`)
- RPlumberError wraps HTTP errors, R errors, timeout errors, and connection failures with distinct messages

---

## FIGURE PIPELINE

### Where Figures Are Stored

Figures live in **two places**:

1. **Database (`figures` table)**: Metadata record with `file_url`, `caption`, `label`, `format`, `dpi`, `source_code` (R script), `source_tool` ("ggplot2"), `figure_type` (analysis type name).

2. **Local filesystem (tmpdir)**: Binary PDF files written to `os.tmpdir()/apollo-figures/{project_id}/{analysis_id}/{filename}`. This is defined by `FIGURES_BASE_DIR` in `/Users/devs/Downloads/Apollo/apps/web/lib/r-plumber/analysis-runner.ts` line 15.

**R2 is NOT yet wired up for figures.** The comment on line 14 says "dev: tmpdir, prod: R2" but only the tmpdir path is implemented. The `file_url` stored in the DB (e.g., `figures/{project_id}/{analysis_id}/chi_square_plot.pdf`) is a relative path, not a signed R2 URL.

### How Figures Get From R to Storage to LaTeX

The complete flow:

1. **R generates base64**: `save_plot_base64()` in `plumber.R` saves ggplot to temp PDF at 300 DPI, base64-encodes it, returns `{ filename, base64 }`.

2. **Node decodes and writes to disk**: `runAnalysis()` in `analysis-runner.ts` (lines 142-161) decodes each base64 figure, writes to `FIGURES_BASE_DIR/{project_id}/{analysis_id}/{filename}`.

3. **Figure record inserted into DB**: Lines 164-175 insert into the `figures` table with all metadata.

4. **Phase 6 generation**: When generating the Results section (`sections/[phase]/generate/route.ts` lines 204-238), the route fetches all completed analyses and all figures, then appends to the AI prompt:
   - Analysis summaries and `table_latex` content (told to include VERBATIM)
   - Figure references: `\label{fig:...} -- caption (\includegraphics{figures/...})`

5. **LaTeX compile**: The compile route (`compile/route.ts` lines 123-137) fetches all figures, resolves each `file_url` to a disk path via `FIGURES_BASE_DIR`, checks the file exists with `stat()`, and builds a `figureFiles` map. This map is passed to the compile function.

6. **File copy into workdir**: `compile.ts` (lines 155-166) copies each resolved figure file into the Docker compile working directory at the matching relative path, so `\includegraphics{figures/...}` resolves correctly during pdflatex execution.

### Can Users Download Individual Figures?

**Not directly.** The figure gallery (`figure-gallery.tsx`) shows thumbnails and a lightbox, but:
- For PNG/SVG figures, it renders an `<img>` tag using `fig.file_url` which is a relative path like `figures/{id}/...` -- this would need a serving endpoint or R2 signed URL to actually work in production.
- For PDF figures (which is what R produces), it shows a BarChart3 icon placeholder -- there is no PDF preview or download link.
- The lightbox shows the source code (R script) but not a download button.

**This is a gap** -- PDF figures from R analyses cannot be previewed or downloaded by users in the current UI.

### Minimum Figure/Table Requirement

**Not enforced anywhere in the code.** There is no validation gate that checks for a minimum number of figures or tables before allowing thesis compilation or phase progression.

### Does Descriptive Analysis Produce a Summary Table (Table 1)?

**Yes.** The `/descriptive` endpoint uses `gtsummary::tbl_summary()` which is specifically designed for Table 1 in medical papers. It produces:
- Continuous variables: mean (SD)
- Categorical variables: n (%)
- Optional grouping with `add_p()` (adds p-values) and `add_overall()` (adds overall column)
- LaTeX table output via `to_latex_table()`

However, it produces **no figures** -- just the table and summary JSON.

### How Are Figures Referenced in LaTeX?

Via `\includegraphics{figures/{project_id}/{analysis_id}/{filename}}`. The path is the `file_url` from the database. During Phase 6 generation, the AI is instructed (in `RESULTS_SYSTEM_PROMPT`) to "Place `\includegraphics{}` for each figure with the exact label provided." The figures context is appended to the prompt with the exact paths.

### Subfigure Support

**Not implemented.** There is no subfigure infrastructure anywhere in the codebase. The `graphicx` package is loaded (in `generate-tex.ts` line 65) but `subcaption` or `subfig` packages are not. Each figure is stored as a standalone entity. The meta-analysis endpoint produces two separate figures (forest + funnel) as two distinct PDF files with separate figure records, not as subfigures.

---

## INTEGRATION

### Analysis Wizard to Results Section (Phase 6b)

The connection is **indirect through the database**:

1. User runs analyses via the `AnalysisWizard` UI component, which calls `POST /api/projects/{id}/analyses`.
2. Analyses complete and store results in the `analyses` table (status: "completed", results_json, figures_urls).
3. Figure records are inserted into the `figures` table.
4. When the user triggers Phase 6 (Results) generation via `POST /api/projects/{id}/sections/6/generate`, the route (lines 204-238):
   - Fetches all completed analyses with their `results_json` and `r_script`
   - Fetches all project figures with their `label`, `caption`, and `file_url`
   - Appends this context to the AI prompt under "--- COMPLETED ANALYSES ---" and "--- FIGURES ---" headers
   - The AI is told to include LaTeX tables VERBATIM and reference figures using `\includegraphics{}`

5. After all analyses complete, the wizard shows a toast: "All analyses complete -- generate Results section" with a "Generate Results" action button (lines 126-138 of `analysis-wizard.tsx`).

### Are Results Automatically Incorporated?

**No.** The user must explicitly trigger Phase 6 generation. The Results section is AI-generated using the analysis data as context, but it is not auto-generated when analyses finish. The toast notification prompts the user to take action.

### Inngest Flow

The full flow is:

1. `POST /api/projects/{id}/analyses` creates analysis record with status "pending"
2. Semaphore `tryAcquire("analysis", projectId, userId)` is called
3. If Inngest is configured (`INNGEST_EVENT_KEY` env var exists):
   - Dispatches event `analysis/run.requested` with `{ analysisId, projectId, jobId }`
   - Inngest function `analysis-runner` (in `/Users/devs/Downloads/Apollo/apps/web/lib/inngest/functions/analysis-runner.ts`) handles it:
     - Calls `executeAnalysis(analysisId)` inside a step
     - On completion: returns `{ status: "completed" }`
     - On failure: returns `{ status: "failed", error }`
     - **Always releases semaphore** in `finally` block via `release(jobId)`
4. If Inngest is NOT configured:
   - Falls back to `runAnalysisInline()` -- fire-and-forget async execution
   - Also releases semaphore in `finally` block

5. `executeAnalysis()` in `analysis-runner.ts`:
   - Updates status to "running"
   - Fetches analysis record and dataset (including `rows_json`)
   - Calls `runAnalysis()` which dispatches to the correct R Plumber endpoint
   - Processes base64 figures (decode, write to disk, insert DB records)
   - Updates analysis with status "completed", results_json, figures_urls, r_script
   - On failure: updates status to "failed" with error message

6. The API returns `202 Accepted` immediately with the analysis record (status "pending"), and the UI polls every 3 seconds via `GET /api/projects/{id}/analyses/{analysisId}`.

### Semaphore Details

The semaphore (`/Users/devs/Downloads/Apollo/apps/web/lib/compute/semaphore.ts`) is an **in-memory** admission controller with these properties:

- **Total capacity**: 3 units
- **Cost**: compile = 2 units, analysis = 1 unit
- **Max concurrent analyses**: 2 (hard limit matching R Plumber container capacity)
- **Max per user**: 2 concurrent slots
- **Queue depth**: 5 per job type
- **Estimated wait**: 30 seconds per queue position

When all slots are full:
1. If queue has room (<5 entries): request is queued, returns `{ acquired: false, position, estimatedWaitMs }`
2. If queue is also full: returns `{ acquired: false }` with no position
3. The API route (`analyses/route.ts` line 127) returns `queueFull()` error response (HTTP 429 with estimated wait time)
4. The UI shows the error to the user via toast

When a job finishes (`release(jobId)`):
1. Job is removed from active set
2. Both queues (compile and analysis) are checked for promotable entries
3. Per-user limits are respected during promotion (via `findNextEligibleInQueue`)
4. If the head-of-queue user is at their limit, the next eligible user in the queue is promoted instead (round-robin fairness)

**Important limitation**: The semaphore is in-memory, so it resets on server restart. In a multi-instance deployment, each instance would have its own semaphore, potentially overcommitting resources. The comment mentions this is for the single-VPS Hetzner deployment.

---

## GAPS AND ISSUES IDENTIFIED

1. **R2 storage not wired for figures**: Figures are written to `os.tmpdir()` which is ephemeral. A server restart or container redeploy loses all figure files. The `file_url` in the DB becomes a dangling reference.

2. **PDF figure preview impossible in UI**: The figure gallery cannot display PDF figures. It shows a placeholder icon. Users cannot preview R-generated analysis figures.

3. **No figure download endpoint**: There is no API route that serves figure binary data. The `file_url` is a relative path, not a URL the browser can fetch.

4. **Descriptive analysis has no figure**: This is arguably correct (Table 1 is a table, not a figure), but a bar chart of demographics or a histogram is often included alongside Table 1 in medical theses.

5. **No minimum figure/table enforcement**: The PLAN likely specifies minimum requirements but no validation gate exists.

6. **Subfigure support absent**: Meta-analysis produces two separate figures (forest + funnel) but there is no mechanism to combine them into a single LaTeX subfigure environment.

7. **In-memory semaphore**: Not durable across restarts. The `resolve` callbacks on queued entries are no-ops (`() => {}`) when using the synchronous `tryAcquire` path, meaning queued jobs never actually get promoted -- they just get rejected. This is a bug: the queue entries are created but never consumed since there is no async waiting mechanism.

8. **Colour scheme and chart_type**: The R code supports `chart_type` and `colour_scheme` parameters, and the TypeScript `figurePreferencesSchema` defines them, but the analysis wizard UI does not expose these options to the user -- they always use defaults.</result>
<usage>total_tokens: 82186
tool_uses: 29
duration_ms: 151088</usage>
</task-notification>
Full transcript available at: /private/tmp/claude-501/-Users-devs-Downloads-Apollo/tasks/a5afa5e.output

---

<task-notification>
<task-id>a54e776</task-id>
<status>completed</status>
<summary>Agent "Audit LaTeX pipeline end-to-end" completed</summary>
<result>Now I have all the data I need for a comprehensive analysis. Here is the complete report.

---

# Complete LaTeX Processing Pipeline Analysis

## 1. FILE CONTENTS SUMMARY (all 14 files read in full)

All 14 files have been read completely. Below is the architecture analysis.

---

## 2. FULL DATA FLOW: End-to-End Transformation Chain

### Step 1: AI Generates LaTeX

The AI (Claude Sonnet/Opus) generates raw LaTeX for each thesis phase. The output format is:

```
\section{Introduction}
Body text with \cite{author2024} references...

---BIBTEX---
@article{author2024,
  title = {Some Article},
  ...
}
```

This is stored in the `sections` table with three columns:
- **`ai_generated_latex`**  Original AI output (preserved as-is, never user-edited)
- **`latex_content`**  Working copy (may be identical to AI output, or edited by user)
- **`rich_content_json`**  Tiptap JSON AST representation (populated when the user opens the editor)

### Step 2: LaTeX to Tiptap (for the rich-text editor)

File: `/Users/devs/Downloads/Apollo/apps/web/lib/latex/latex-to-tiptap.ts`

When a section is opened in the editor, `latexToTiptap()` converts the raw LaTeX to a Tiptap JSON document:

1. **Preprocessing** (`preprocess()`):
   - Strips `---BIBTEX---` trailer and everything after
   - Removes `\label{}`, `\needspace{}`, `\usepackage{}`
   - Removes full-line comments (`%...`)
   - Removes markdown horizontal separators
   - Converts markdown headings (`# Title` to `\section{Title}`)

2. **Block tokenisation** (`tokeniseBlocks()`):
   - Splits into heading / paragraph / bulletList / orderedList / blockquote / codeBlock blocks
   - Complex environments (longtable, table, figure, etc.) become `codeBlock` nodes (raw LaTeX pass-through)

3. **Inline parsing** (`parseInline()`):
   - Handles `\textbf{}`, `\textit{}`, `\emph{}`, `\texttt{}`, `\underline{}`
   - Handles `\cite{}` commands (stored as code-marked text nodes)
   - Unescapes LaTeX special characters (`\&` to `&`, `\%` to `%`, etc.)

### Step 3: User Edits in Tiptap Editor

The user works with the Tiptap rich-text representation. Their edits update `rich_content_json` in the database.

### Step 4: Tiptap to LaTeX (for compilation)

File: `/Users/devs/Downloads/Apollo/apps/web/lib/latex/tiptap-to-latex.ts`

When compiling, `tiptapToLatex()` converts the Tiptap JSON back to LaTeX:

1. Walks the JSON tree recursively via `serializeNode()`
2. **Text nodes**: Escaped via `escapeLatex()` (which first calls `normaliseUnicode()`)
3. **Citation nodes**: Code-marked text matching `\cite{...}` passes through raw (no escaping)
4. **CodeBlock nodes**: Raw LaTeX pass-through, but `normaliseUnicode()` applied (for smart quotes/em-dashes)
5. **Marks**: `bold` to `\textbf{}`, `italic` to `\textit{}`, etc.
6. Extracts citation keys from the output

### Step 5: Assembly

File: `/Users/devs/Downloads/Apollo/apps/web/lib/latex/assemble.ts`

`assembleThesisContent()` builds the complete thesis:

1. **Metadata**: `generateTex()` fills template placeholders with project metadata
2. **Front matter**: `injectFrontMatter()` populates acknowledgements and abstract from Phase 1
3. **Chapters (Phases 2-8, 10)**: For each phase:
   - **Primary path**: `tiptapToLatex(section.rich_content_json)`  if user has edited in the rich editor
   - **Fallback path**: `splitBibtex(section.latex_content).body` then `latexToTiptap()` then `tiptapToLatex()`  full round-trip to sanitise
   - Post-processing: `stripTierDCitations()`, `escapeBareAmpersands()`, `sanitiseChapterLatex()`
4. **BibTeX**: Collected from `ai_generated_latex` (preferred, preserves trailer) or `latex_content`, plus all citations from the citations table. Deduplication, Unicode normalisation, ampersand escaping, DOI underscore escaping.
5. **Output**: `{ tex, bib, chapterFiles, warnings }`

### Step 6: Validation

File: `/Users/devs/Downloads/Apollo/apps/web/lib/latex/validate.ts`

- **Pre-flight** (`preflightChapter()`): Deterministic, fast, BLOCKS on errors
  - Unescaped `#`, bare `&` outside tabular, markdown headings, bare URLs, unbalanced braces, unbalanced environments
- **AI validation** (`aiValidateChapters()`): Claude Haiku, NON-BLOCKING warnings only

### Step 7: Compilation

File: `/Users/devs/Downloads/Apollo/apps/web/lib/latex/compile.ts`

Three modes: `docker`, `local`, `mock`.

- **Docker mode**: Writes all files to a temp directory, runs `docker run --rm --network=none --read-only --memory=1g` with the `apollo-latex` image
- **Local mode**: Same flow but runs `pdflatex` and `bibtex` directly
- **Both**: 4-pass cycle: `pdflatex -> bibtex -> pdflatex -> pdflatex`
- PDF persisted to `$TMPDIR/apollo-pdfs/{projectId}.pdf`

### Step 8: Docker Compilation Script

File: `/Users/devs/Downloads/Apollo/docker/compile.sh`

- Copies files from `/thesis` to `/tmp` (read-only filesystem compatibility)
- Runs the same 4-pass cycle
- Applies watermark for sandbox projects via Ghostscript (`watermark.sh`)
- Copies output to `/thesis/output/`

### Step 9: PDF Serving

File: `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/preview.pdf/route.ts`

- Reads from `compilations.pdf_url` (a local disk path)
- Falls back to deterministic path `$TMPDIR/apollo-pdfs/{id}.pdf`
- Serves as `application/pdf` with `Cache-Control: private, max-age=60`

---

## 3. ROUND-TRIP ANALYSIS: Is LaTeX to Tiptap to LaTeX LOSSY?

**YES, the round-trip is lossy.** Here is what gets lost or corrupted:

### Definitively Lost

| Element | What Happens |
|---------|-------------|
| `\label{...}` | Stripped in preprocessing. Never restored. |
| `\needspace{...}` | Stripped in preprocessing. Never restored. |
| `\usepackage{...}` | Stripped in preprocessing. Never restored. |
| Full-line comments (`%...`) | Stripped in preprocessing. Never restored. |
| `---BIBTEX---` trailer | Stripped in preprocessing. Never restored in body. (BibTeX is sourced from `ai_generated_latex` separately.) |
| Paragraph spacing/layout | Multiple blank lines collapsed to single `\n\n` |
| Specific whitespace/indentation | All normalised |

### Potentially Corrupted

| Element | What Happens |
|---------|-------------|
| **Unrecognised LaTeX commands** (e.g. `\url{}`, `\href{}`, `\textsc{}`, `\footnote{}`) | The inline parser does not recognise these. A `\url{...}` will be consumed as: backslash consumed as plain text `\`, then `u`, `r`, `l`, `{`, `}` each separately (some may be escaped). The result is garbled. |
| **`\textsuperscript{}` / `\textsubscript{}`** | NOT in `FORMAT_COMMANDS`. Same garbling as above. |
| **`\footnote{}`** | Not handled. Content lost/garbled. |
| **Nested environments inside paragraphs** | A `\begin{center}...\end{center}` that starts mid-paragraph won't be properly detected as a block boundary since the block tokeniser only checks at line start. |
| **Multi-line headings** | The heading regex requires the entire `\section{...}` on a single line. If the AI wraps it across lines, it won't match. |
| **`\section*{}` with content after on same line** | The heading regex uses `$` anchor, so `\section{Title} Some text` would fail. |
| **`\vspace{}`, `\hspace{}`, `\noindent`** | Not handled by the parser. The backslash gets consumed as unknown and emitted as-is or garbled. |
| **Unicode characters that were originally LaTeX commands** | `normaliseUnicode()` converts e.g. micro sign `u` to `u`, but if the original was `$\mu$`, the round-trip converts `\mu` (inside a math environment) to... well, if it's inside a `codeBlock` it survives, but if in a paragraph, the `$` gets escaped to `\$`. |

### What Survives Cleanly

- Section headings (`\section{}`, `\subsection{}`, `\subsubsection{}`)
- Bold, italic, code, underline formatting
- `\cite{}` commands (special-cased with code marks)
- Bullet and numbered lists
- Blockquotes
- Complex environments as codeBlocks (tables, figures, longtable)
- Basic paragraph text

### Critical Analysis of the Fallback Path

When `rich_content_json` is null (user never opened the editor), the fallback does a FULL round-trip: `latexToTiptap() -> tiptapToLatex()`. This means **every lossy transformation applies** to AI-generated content that was never edited. The purpose is sanitisation (stripping markdown artifacts, escaping special chars), but the cost is loss of `\label{}`, `\footnote{}`, `\url{}`, and other non-basic commands.

---

## 4. SIMPLER ALTERNATIVES TO THE ROUND-TRIP

Several alternatives could avoid data loss:

### Option A: Store Canonical LaTeX, Edit LaTeX Directly
Use CodeMirror (LaTeX-mode) as the primary editor. No round-trip needed. Users see what they get. Downside: medical students may find raw LaTeX intimidating.

### Option B: Selective Sanitisation Without Round-Trip
Instead of round-tripping through Tiptap, apply targeted regex transformations directly on the LaTeX:
1. Convert markdown headings to `\section{}`
2. Escape bare `#`, `&` outside tabular
3. Strip `\usepackage{}` from chapter bodies
4. Repair brace/environment balance

This preserves `\label{}`, `\footnote{}`, `\url{}`, and every other LaTeX command. The `sanitiseChapterLatex()` function already does steps 2-4; it could be extended to handle step 1.

### Option C: Only Round-Trip for Display, Keep AI LaTeX Canonical
The Tiptap editor already stores `rich_content_json` separately from `latex_content`. For compilation, always use `latex_content` (or `ai_generated_latex`) directly, applying only the targeted sanitisation from Option B. Only use the round-trip for display purposes.

### Option D: Expand the Parser
Add all missing LaTeX commands to `latex-to-tiptap.ts`. This is an arms race against AI output variety, but would reduce lossiness.

**Recommendation**: Option B or C. The current round-trip is the most fragile path in the system and destroys LaTeX semantics that may be important for a thesis.

---

## 5. HOW assemble.ts BUILDS THE FINAL DOCUMENT

### Phase Coverage

The `PHASE_CHAPTER_MAP` maps phases to chapter files:

| Phase | Chapter File | Content |
|-------|-------------|---------|
| 1 | (no chapter file  injected into template) | Acknowledgements + Abstract |
| 2 | `chapters/introduction.tex` | Introduction |
| 3 | `chapters/aims.tex` | Aims and Objectives |
| 4 | `chapters/literature.tex` | Review of Literature |
| 5 | `chapters/methodology.tex` | Materials and Methods |
| 6 | `chapters/results.tex` | Results |
| 7 | `chapters/discussion.tex` | Discussion |
| 8 | `chapters/conclusion.tex` | Conclusion |
| 9 | (no chapter file) | References (handled by `\bibliography{references}` in template) |
| 10 | `chapters/appendices.tex` | Appendices |
| 11 | (no chapter file) | Final QC (no content generation) |

**Missing from PHASE_CHAPTER_MAP**:
- **Phase 0 (Orientation)**: No content generation phase.
- **Phase 6a/6b**: The GOLD Standard splits Phase 6 into 6a (Dataset) and 6b (Results). The assembly only uses phase number `6` mapped to `chapters/results.tex`. If 6a generates separate section rows with `phase_number=6`, they would be combined. If 6a has a different phase number, its content would be missed.
- **Phase 9 (References)**: Handled via BibTeX, not a chapter file. Correct.
- **Phase 11 (Final QC)**: QC phase, no content. Correct.

### Section Selection Strategy

For each phase, sections are sorted by status priority (`approved` > `review` > anything else), and only the first (best) is used. This means:
- If a phase has both approved and review sections, approved wins
- If a phase has only draft sections, they are ranked lower (priority `2`) but still selected

**Issue**: The section sort puts `approved: 0, review: 1`, and anything else gets `2`. So a `draft` section WOULD be used if no approved/review section exists, which contradicts the Supabase query in the compile route that filters `.in("status", ["approved", "review"])`.

### BibTeX Assembly

1. From each section's `ai_generated_latex` (preserving the `---BIBTEX---` trailer even after user edits) or `latex_content` fallback
2. From the `citations` table (excluding Tier D)
3. Deduplication by cite key (last-write-wins, so citations table entries override AI-generated ones)
4. Unicode normalisation, ampersand escaping, DOI underscore escaping

---

## 6. TEMPLATE AND \input{} USAGE

### main.tex Structure

The template at `/Users/devs/Downloads/Apollo/templates/main.tex` properly uses `\input{}`:

```latex
\input{chapters/introduction}
\input{chapters/aims}
\input{chapters/literature}
\input{chapters/methodology}
\input{chapters/results}
\input{chapters/discussion}
\input{chapters/conclusion}
```

Note: `\input{chapters/introduction}` (no `.tex` extension) is standard LaTeX  TeX auto-appends `.tex`.

### Chapter File Generation

Chapter files are generated by `assembleThesisContent()` as the `chapterFiles` dictionary:

```typescript
chapterFiles["chapters/introduction.tex"] = "..."
```

In `compile.ts`, these are written to disk:

```typescript
for (const [filename, content] of Object.entries(options.chapterFiles)) {
  await writeFile(path.join(workDir, filename), content);
}
```

### Template \input vs Assembly Output Mismatch

The template uses `\input{chapters/introduction}` (no `.tex`), but the assembly produces keys like `"chapters/introduction.tex"`. In `compile.ts`, the file is written as `path.join(workDir, "chapters/introduction.tex")`. Since LaTeX's `\input` auto-appends `.tex`, this works correctly.

**However**: There is NO `\input{chapters/appendices}` in the template. Phase 10 generates `chapters/appendices.tex` but the template has inline placeholder annexures with `\annexurechapter{}` commands. The appendices chapter file is written but never `\input`-ed. This is a **content loss bug** for Phase 10.

---

## 7. PACKAGE ANALYSIS: Template vs Docker Image

### CLS File Required Packages (sskm-thesis.cls)

| Package | In scheme-small? | In Dockerfile extras? | Status |
|---------|-----------------|----------------------|--------|
| geometry | Yes | - | OK |
| mathptmx | Yes (fonts) | - | OK |
| fontenc (T1) | Yes | - | OK |
| inputenc | Yes | - | OK |
| setspace | Yes | - | OK |
| tocloft | No | Yes | OK |
| graphicx | Yes | - | OK |
| float | Yes | - | OK |
| subfig | Yes | - | OK |
| booktabs | Yes | - | OK |
| longtable | Yes | - | OK |
| array | Yes | - | OK |
| multirow | No | Yes | OK |
| tabularx | Yes | - | OK |
| natbib | No | Yes | OK |
| hyperref | Yes | - | OK |
| caption | Yes | - | OK |
| fancyhdr | Yes | - | OK |
| titlesec | No | Yes | OK |
| hyphenat | No | Yes | OK |
| emptypage | No | Yes | OK |
| afterpage | Yes | - | OK |
| enumitem | No | Yes | OK |
| amsmath | Yes | - | OK |
| amssymb | No | Yes (in Dockerfile) | OK |
| babel-english | No | Yes | OK |
| datetime | No | Yes | OK |
| pdfpages | Yes | - | OK |
| xcolor | Yes | - | OK |
| etoolbox | Yes | - | OK |
| nomencl | No | Yes | OK |
| pdflscape | Yes | - | OK |
| lettrine | No | Yes | OK |
| threeparttable | No | Yes | OK |
| ragged2e | Yes | - | OK |
| needspace | No | Yes | OK |
| draftwatermark | No | Yes | OK |
| xfp | Yes | - | OK |

### Packages Added by generate-tex.ts

```typescript
const extraPackages = [
  "\\usepackage{mathrsfs}   % \\mathscr{} -- formal script math font",
  "\\usepackage{amssymb}    % Extended math symbols",
  "\\usepackage{graphicx}   % \\includegraphics for figures",
];
```

**Issue**: `mathrsfs` is NOT in the Dockerfile's `tlmgr install` list and is NOT part of scheme-small. If AI-generated content uses `\mathscr{}`, compilation will fail with `! LaTeX Error: File 'mathrsfs.sty' not found.`

**Issue**: `amssymb` is already loaded by both CLS files. The duplicate `\usepackage{amssymb}` in `generate-tex.ts` is harmless (LaTeX ignores duplicate loads), but indicates a lack of coordination.

**Issue**: `graphicx` is already loaded by both CLS files. Same as above  harmless but redundant.

---

## 8. FONT HANDLING

### Primary Font: mathptmx (Times)

Both CLS files use `\RequirePackage{mathptmx}`, which provides:
- Times Roman for text
- Times-compatible math fonts

This is part of `scheme-small` (specifically `collection-fontsrecommended`). It is a pdfLaTeX-only font setup using Type 1 fonts.

### T1 Font Encoding

`\RequirePackage[T1]{fontenc}`  available via `cm-super` fonts in scheme-small. If `cm-super` is missing, TeX falls back to bitmap CM fonts (lower quality but compiles).

### Potential Issue

The Docker image uses `texlive/texlive:latest-minimal` as base, then installs `scheme-small`. The `scheme-small` scheme includes `collection-fontsrecommended` which should have `mathptmx` and `cm-super`. This should work.

### No XeLaTeX/LuaLaTeX Dependency

The template uses pdfLaTeX (confirmed by `compile.sh` calling `pdflatex`). No system fonts (Arial, etc.) are needed. This is a good choice for Docker containerisation.

---

## 9. MATH NOTATION SUPPORT

### Available Math Packages

From the CLS files:
- `amsmath`  core math environments (`equation`, `align`, `gather`, etc.)
- `amssymb`  extended math symbols (`\mathbb`, `\mathfrak`, etc.)

From `generate-tex.ts`:
- `mathrsfs`  formal script math font (`\mathscr{}`) **BUT NOT INSTALLED IN DOCKER**

### What Students Can Use

- Standard math mode: `$...$`, `$$...$$`, `\[...\]`
- All AMS environments: `equation`, `align`, `gather`, `multline`, etc.
- Greek letters, operators, relations, arrows
- Matrices via `amsmath` (`pmatrix`, `bmatrix`, etc.)

### Round-Trip Impact on Math

**Critical concern**: The `escapeLatex()` function in `tiptap-to-latex.ts` escapes `$`, `\`, `{`, `}`, `^`, `_`, `~`, `#`, `%`, `&`. If math notation appears in a paragraph (text node), it will be destroyed:
- `$p < 0.05$` becomes `\$p < 0.05\$`  literal dollar signs, not math mode
- `\alpha` becomes `\textbackslash{}alpha`  literal text

**However**, if math content is inside a `codeBlock` node (complex environments), it passes through via `normaliseUnicode()` only (no escaping). So:
- Tables with math: Preserved (codeBlock)
- Inline math in paragraphs: **DESTROYED by the round-trip**

This is a significant limitation for medical statistics (p-values, confidence intervals, chi-squared, etc.).

---

## 10. TABLE HANDLING

### Available Packages

- `booktabs`  professional `\toprule`, `\midrule`, `\bottomrule`
- `longtable`  multi-page tables
- `tabularx`  auto-width columns
- `array`  extended column specifiers
- `multirow`  spanning rows
- `threeparttable`  table notes
- `caption`  formatting

### How Tables Survive the Round-Trip

In `latex-to-tiptap.ts`, any `\begin{...}...\end{...}` that isn't `itemize`, `enumerate`, or `quote` becomes a `codeBlock`. This means:
- `\begin{longtable}`  `codeBlock` (raw LaTeX preserved)
- `\begin{table}`  `codeBlock` (raw LaTeX preserved)
- `\begin{threeparttable}`  `codeBlock` (raw LaTeX preserved)

In `tiptap-to-latex.ts`, `codeBlock` content goes through `normaliseUnicode()` only  NO escaping. So tables survive the round-trip cleanly.

**Potential Issue**: If a user edits a table in the Tiptap editor, the codeBlock is opaque  they see raw LaTeX. There's no visual table editor. The editing experience for tables is poor, but correctness is maintained.

---

## 11. WATERMARK FOR SANDBOX PROJECTS

### Two-Layer Watermark System

**Layer 1: CLS-Level (LaTeX)**

Both CLS files include `draftwatermark` package with preset commands:
- `\draftwatermark`  "DRAFT" at 45 degrees
- `\reviewwatermark`  "FOR REVIEW ONLY"
- `\setupwatermark{text}{opacity}`  custom

But the template does NOT activate any watermark. The watermark text is set to empty: `\SetWatermarkText{}`.

**Layer 2: Ghostscript Post-Processing (Docker)**

In `compile.sh`:
```sh
if [ "$WATERMARK" = true ] && [ -f /usr/local/bin/watermark.sh ]; then
  /usr/local/bin/watermark.sh /tmp/main.pdf /tmp/main-watermarked.pdf
```

`watermark.sh` uses Ghostscript to overlay "DRAFT - SANDBOX" in gray at 45 degrees on every page.

**In the compile route**:
```typescript
const isWatermark = typedProject.status === "sandbox";
```
This is passed to `compileTex()` which passes `--watermark` to the Docker container.

**Issue in compile.ts Docker flow**: The `--watermark` flag is appended AFTER the container name in the args array:
```typescript
const args = [..., containerName];
if (options.watermark) {
  args.push("--watermark");
}
```
Since the entrypoint is `compile.sh`, this flag is passed as an argument to the script, which correctly parses it. This works.

**Issue in compile.ts Local flow**: The local compile mode does NOT apply any watermark. The `options.watermark` parameter is accepted but never used. Sandbox projects compiled locally will have no watermark.

---

## 12. COMPILE ERROR BUDGET ENFORCEMENT

### How Errors Are Counted

In `parse-log.ts`:
- Lines starting with `! ` are checked against `FATAL_ERROR_PATTERNS` and `NON_FATAL_ERROR_PATTERNS`
- Fatal errors  counted in `errorCount`
- Non-fatal errors (missing fonts, missing figures)  demoted to warnings
- Standard LaTeX warnings (overfull boxes, font shapes)  `warningCount`

### Success Criteria

In `compile.ts`:
```typescript
success: log.errorCount === 0 && pdfPath !== null
```

Zero blocking errors required. Warnings are tolerated.

### Warning Budget

Per `CLAUDE.md`: "Compile warnings budget: <=20 tolerated". However, this budget is NOT enforced anywhere in code. The compile route reports all warnings but never fails based on warning count. The 20-warning budget appears to be a policy guideline, not a programmatic enforcement.

### Pre-flight Blocking

`preflightChapter()` errors (unescaped `#`, unbalanced braces, markdown headings) block compilation entirely with a 422 response. This is the first line of defense.

---

## 13. HOW validate.ts CATCHES ISSUES BEFORE COMPILE

### Pre-flight Checks (Deterministic, Blocking)

| Check | Severity | Catches |
|-------|----------|---------|
| Unescaped `#` | Error | Direct LaTeX crash |
| Bare `&` outside tabular | Warning | "Misplaced alignment tab" |
| Markdown headings (`# Title`) | Error | Not valid LaTeX |
| Markdown separators (`---`) | Warning | Harmless but ugly |
| Bare URLs | Warning | Underscores break LaTeX |
| Unbalanced braces | Error | Cascading LaTeX errors |
| Unbalanced environments | Error | "Missing \end{...}" |

### What It Does NOT Catch

- Unescaped `$` (enters math mode unexpectedly)
- Unescaped `_` outside math/tabular
- Invalid LaTeX commands (e.g., `\textsc{}` if fontenc doesn't support it)
- Missing `\end{document}` (template-level, not chapter-level)
- BibTeX issues (bad cite keys, malformed entries)
- Circular citations
- File references to non-existent figures

### AI Validation (Non-Blocking, 15s Timeout)

Uses Claude Haiku with a 2000-char truncation per chapter. Returns warnings only. On failure or timeout, returns empty array. This is a best-effort supplementary check.

---

## 14. HARDCODED PATHS, UNIVERSITY-SPECIFIC ASSUMPTIONS, AND TEMPLATE MIXING

### Hardcoded Paths

| Location | Path | Issue |
|----------|------|-------|
| `compile.ts` line 111, 270 | `path.resolve(process.cwd(), "../../templates")` | Assumes Next.js app is at `apps/web/` relative to monorepo root. Fragile  breaks if app is moved or if `cwd()` changes. |
| `compile.ts` line 102, 263 | `path.join(os.tmpdir(), \`apollo-compile-${projectId}\`)` | OK for ephemeral work dirs |
| `compile.ts` line 72, 197, 329 | `path.join(os.tmpdir(), "apollo-pdfs")` | Stable PDF storage  but `os.tmpdir()` is wiped on reboot. PDFs are ephemeral. |
| `compile.sh` line 13 | `/thesis/output` | Docker-internal, correct |
| `compile.sh` lines 24-27 | `/thesis/*` copied to `/tmp/` | Docker-internal, correct |
| `route.ts` (compile) line 22 | `FIGURES_BASE_DIR = path.join(os.tmpdir(), "apollo-figures")` | Ephemeral  figures lost on reboot |

### University-Specific Assumptions

1. **Logo paths in generate-tex.ts**:
   ```typescript
   sskm: { university: "logo/wbuhs-logo", institute: "logo/sskm-logo" },
   ssuhs: { university: "logo/ssuhs-logo", institute: "logo/ssuhs-logo" },
   ```
   These paths have NO file extensions. The CLS files use `\includegraphics` which auto-detects `.pdf`, `.png`, `.jpg`. If the logo files don't exist at these paths, compilation warns but continues.

2. **Document class switching in generate-tex.ts**:
   ```typescript
   tex = tex
     .replace(/^\\documentclass\{sskm-thesis\}/m, "%\\documentclass{sskm-thesis}")
     .replace(/^%\\documentclass\{ssuhs-thesis\}/m, "\\documentclass{ssuhs-thesis}");
   ```
   This relies on the exact comment format `%\documentclass{ssuhs-thesis}` in the template. If the template format changes (e.g., extra space), the regex fails and the wrong CLS is used. The `sskm` path (default) requires no changes.

3. **Both CLS files are always copied to the work directory** (line 112 in `compile.ts`). Only the one referenced in `\documentclass` is used, but having both present is harmless.

### Template Mixing Issues

1. **`generate-tex.ts` adds `\usepackage{mathrsfs}` before `\begin{document}`**. If the CLS files ever add this package, it would be loaded twice (harmless, but messy).

2. **Front matter injection** relies on regex matching `\begin{acknowledgements}...\end{acknowledgements}` and `\begin{thesis_abstract}...\end{thesis_abstract}`. If the template formatting changes (e.g., extra whitespace inside these environments), the regex may fail, leaving placeholder text in the PDF.

3. **Phase 10 (Appendices) content is assembled into `chapters/appendices.tex` but never `\input`-ed by the template.** The template has inline `\annexurechapter{}` commands with placeholder text. This is a structural disconnect.

### `vancouver.bst` Dependency

The template specifies `\bibliographystyle{vancouver}`. The file `vancouver.bst` must be present in the work directory. Both `compile.ts` modes copy it from the templates directory. If the file is missing, BibTeX silently fails and references appear as `[?]`.

---

## 15. ADDITIONAL CRITICAL FINDINGS

### A. Abbreviations Are Never Injected

File `/Users/devs/Downloads/Apollo/apps/web/lib/latex/abbreviations.ts` generates LaTeX for abbreviations, but `assemble.ts` NEVER calls `generateAbbreviationsLatex()`. The template has `\begin{abbreviations}...\end{abbreviations}` with a placeholder comment. This environment is never populated during assembly.

### B. front-matter.ts Is Never Used for Compilation

`generateFrontMatterLatex()` and `generateAcknowledgements()` in `front-matter.ts` are standalone generators. The actual compilation uses `injectFrontMatter()` inside `assemble.ts` which takes a different approach (extracting from Phase 1 section content). The `front-matter.ts` file appears to be dead code for the compile pipeline.

### C. PDF Storage Is Ephemeral

The preview route reads PDFs from `os.tmpdir()`. On a production VPS, `/tmp` is cleaned on reboot. The `compilations.pdf_url` column stores the absolute path (e.g., `/tmp/apollo-pdfs/uuid.pdf`). After reboot, PDFs are gone, and the preview route returns 404. The plan mentions Cloudflare R2 for storage, but R2 integration is not implemented.

### D. Concurrent Compilation Race Condition

The compile route checks for `status: "running"` compilations, but there's a TOCTOU gap between the check and the insert. Two simultaneous compile requests could both pass the check and start compiling. The semaphore (`tryAcquire("compile", ...)`) provides admission control, but its enforcement depends on the in-memory semaphore state, which is not shared across Next.js instances.

### E. `\input{chapters/introduction}` vs `\input{chapters/introduction.tex}`

The template uses `\input{chapters/introduction}` (no extension), and the assembly creates files as `chapters/introduction.tex`. This works because TeX's `\input` auto-appends `.tex`. However, if a file were named `chapters/introduction` (no extension), TeX would try that first. This is not an issue in practice, but worth noting.

### F. The Brace-Checking Logic Has a Subtle Bug

In both `sanitiseChapterLatex()` and `preflightChapter()`, escaped braces are detected by checking `result[i - 1] !== "\\"`. This fails for `\\{` (double backslash followed by brace)  the `{` is actually unescaped because `\\` is an escaped backslash, not an escape prefix for `{`. In practice, `\\{` in LaTeX means "line break followed by brace", so the brace IS unescaped. The current logic would incorrectly count it as escaped.

### G. The `\cite{}` Passthrough in tiptapToLatex Has a Strict Regex

```typescript
/^\\cite\{[^}]+\}$/.test(raw)
```

This requires the ENTIRE text to be exactly `\cite{...}`. If a user types `\cite{a} text` in a code-marked node, it won't match and will be escaped, destroying the citation. Multi-citation nodes like `\cite{a}\cite{b}` will also fail.

### H. compile.ts Docker Mode Passes CLS Files from Host

```typescript
const templatesDir = path.resolve(process.cwd(), "../../templates");
```

In production, the Docker image should have the CLS/BST files baked in. But `compile.ts` copies them from the host's `templates/` directory into the work directory, then mounts that as `/thesis`. The Docker `compile.sh` then copies from `/thesis` to `/tmp`. This double-copy is correct but means the Docker image's built-in templates (if any) are never used  the host always provides them.

---

## SUMMARY OF CRITICAL ISSUES (Ranked by Severity)

1. **Inline math destroyed by round-trip**  `$p < 0.05$` in paragraphs becomes `\$p < 0.05\$`. Medical theses are full of p-values and statistical notation. This is a blocking usability issue.

2. **`mathrsfs` package not installed in Docker**  If AI uses `\mathscr{}`, compilation fails.

3. **Phase 10 (Appendices) content never rendered**  Assembly generates the file but template never `\input`s it.

4. **Abbreviations never injected**  The abbreviations generator exists but is never called during assembly.

5. **`\footnote{}`, `\url{}`, `\textsuperscript{}` destroyed by round-trip**  These are common in academic writing.

6. **PDF storage ephemeral**  PDFs stored in `/tmp` are lost on reboot. No R2 integration yet.

7. **Local compile mode ignores watermark**  Sandbox projects compiled locally have no watermark.

8. **Warning budget not enforced**  The 20-warning limit from PLAN.md is documentation only.

9. **Brace-checking logic incorrect for `\\{`**  Edge case but could cause silent corruption.

10. **`front-matter.ts` is dead code**  `generateFrontMatterLatex()` and `generateAcknowledgements()` are never called in the compile pipeline.</result>
<usage>total_tokens: 75391
tool_uses: 30
duration_ms: 236164</usage>
</task-notification>
Full transcript available at: /private/tmp/claude-501/-Users-devs-Downloads-Apollo/tasks/a54e776.output

---

<task-notification>
<task-id>a77af11</task-id>
<status>completed</status>
<summary>Agent "Audit phase transitions and generation routes" completed</summary>
<result>Now I have a comprehensive picture of the entire pipeline. Here is the full analysis.

---

## Complete Phase-to-Phase Pipeline Analysis

### Phase Definitions (constants.ts)

**File**: `/Users/devs/Downloads/Apollo/apps/web/lib/phases/constants.ts`

12 phases (0-11), with Phase 0-1 available without a licence and Phases 2-11 requiring one:

| Phase | Name | Label | Licence? |
|-------|------|-------|----------|
| 0 | orientation | Orientation | No |
| 1 | front_matter | Front Matter | No |
| 2 | introduction | Introduction | Yes |
| 3 | aims | Aims & Objectives | Yes |
| 4 | review_of_literature | Review of Literature | Yes |
| 5 | materials_methods | Materials & Methods | Yes |
| 6 | results | Results | Yes |
| 7 | discussion | Discussion | Yes |
| 8 | conclusion | Conclusion | Yes |
| 9 | references | References | Yes |
| 10 | appendices | Appendices | Yes |
| 11 | final_qc | Final QC | Yes |

**CRITICAL GAP -- Phase 6a/6b Split is Missing**: The PLAN.md calls for Phase 6a (Dataset) and Phase 6b (Results) as separate phases. The actual constants collapse them into a single Phase 6 "Results". There is no formal Phase 6a. The UI shows a "Results Checklist" in the workspace at Phase 6, but nothing structurally enforces dataset upload before generation. The `AI_GENERATABLE_PHASES` set includes `6`, meaning the user can click "Generate with AI" without uploading a dataset. The generate route does gather analysis context for Phase 6 if analyses exist, but it is **not a precondition** -- generation proceeds even with zero datasets and zero analyses.

### Word Count Targets (word-count-targets.ts)

**File**: `/Users/devs/Downloads/Apollo/apps/web/lib/phases/word-count-targets.ts`

Targets exist for Phases 2-8 only (no targets for 0, 1, 9, 10, 11):

| Phase | Min | Max |
|-------|-----|-----|
| 2 (Introduction) | 750 | 1,200 |
| 3 (Aims) | 200 | 500 |
| 4 (ROL) | 3,500 | 4,500 |
| 5 (M&M) | 1,500 | 3,000 |
| 6 (Results) | 1,500 | 3,000 |
| 7 (Discussion) | 2,000 | 3,500 |
| 8 (Conclusion) | 400 | 800 |

**INTEGRATION GAP -- Inconsistent Word Count Targets**: `final-qc.ts` has its **own** hardcoded `WORD_COUNT_TARGETS` at lines 62-70 that **disagree** with `word-count-targets.ts`:

| Phase | word-count-targets.ts | final-qc.ts |
|-------|----------------------|-------------|
| 2 | 750-1,200 | 500-750 |
| 3 | 200-500 | 150-200 |
| 4 | 3,500-4,500 | 2,500-3,500 |
| 5 | 1,500-3,000 | 1,500-2,500 |
| 6 | 1,500-3,000 | 1,500-2,500 |
| 7 | 2,000-3,500 | 2,000-2,500 |
| 8 | 400-800 | 500-750 |

The QC ranges are generally tighter/different. A section could pass the review check but fail the QC check, or vice versa. This is confusing for users.

---

### Phase Transition Logic (transitions.ts)

**File**: `/Users/devs/Downloads/Apollo/apps/web/lib/phases/transitions.ts`

`canAdvancePhase(project, currentSectionStatus)`:
1. Blocks if `current_phase > 11` (MAX_PHASE)
2. Blocks if current section status is not `"approved"` -- but the approve route **passes `"approved"` as a hardcoded literal** (line 95), not the actual section status. This means the transition check's section-status guard is effectively **bypassed**.
3. If `current_phase === 11`, allows completion (no licence check needed for the final phase itself)
4. For all other phases: looks at the next phase's `requiresLicence` flag. If true, requires project status to be `"licensed"` or `"completed"`, unless `DEV_LICENCE_BYPASS=true`.

**BUG -- canAdvancePhase section status check is bypassed**: In the approve route at line 95:
```typescript
const transitionCheck = canAdvancePhase(typedProject, "approved");
```
The second argument is always the string literal `"approved"`, not the section's actual status. The function checks if `currentSectionStatus !== "approved"`, which will always pass since the literal `"approved"` is passed. The real status check happens earlier in the approve route (lines 73-88), but the `canAdvancePhase` guard is architecturally dead code for the status check.

---

### Generation Route (generate/route.ts)

**File**: `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/sections/[phase]/generate/route.ts`

The complete flow:

1. **Auth check** -- authenticated user required
2. **Phase validation** -- `isValidPhase(phaseNumber)`
3. **Rate limit** -- `checkRateLimit(userId)`
4. **Project ownership** -- fetches project by id + user_id
5. **Phase 0 branch** -- synopsis parsing (special)
6. **Phases 1-8** (general section generation):
   - Checks system prompt availability
   - Requires `project.synopsis_text`
   - **Stale generation detection**: resets sections stuck in "generating" for > 2 minutes
   - **Token budget check**: hard-stop if phase (100K) or thesis (1.2M) budget exhausted
   - Gathers context from previously **approved** sections
   - Redacts PII from synopsis
   - Phase 6 special: gathers analysis results and figures
   - Citation-heavy phases (2, 4, 5, 7): pre-seeds real PubMed references
   - Sets section status to `"generating"` via upsert
   - Streams AI response via SSE
   - On completion: converts LaTeX to Tiptap JSON, counts words, updates section to `"review"` status
   - **3-tier DB fallback**: tries full update, then without `ai_generated_latex`, then core-only
   - Citation resolution with 15-second timeout (non-blocking)
   - On error: resets status to `"draft"`
   - On client disconnect: resets status to `"draft"` (if stream didn't complete)

**CRITICAL GAPS in Generate Route**:

1. **No licence gate on generation**: The generate route does NOT check project licence status. A sandbox project can generate Phase 2+ content freely. The licence gate only blocks **approval/advancement** (in the approve route via `canAdvancePhase`). This means users can generate all content for free and are only blocked when trying to approve. This may be intentional (try-before-you-buy model) but is worth noting.

2. **Phase 9, 10, 11 not handled by generate**: The generate route supports Phases 0-8 via `getPhaseSystemPrompt()` (returns null for 9+). Phase 9 is auto-created by the approve route when Phase 8 is approved. Phase 10 is listed in `AI_GENERATABLE_PHASES` in the workspace, but `getPhaseSystemPrompt(10)` likely returns null, causing a `badRequest`. Phase 11 is auto-created when Phase 10 is approved.

3. **No phase sequence enforcement**: The generate route does NOT check that `phaseNumber === project.current_phase`. A user could theoretically generate content for any phase, regardless of which phase the project is currently at. Only **approval** enforces phase sequence.

4. **Model routing TODO**: Lines 284-286 show both branches use `claude-sonnet-4-5-20250929` -- the TODO to switch Introduction/Discussion to Opus is unfulfilled.

**Phase 0 (Synopsis Parsing)**:
- Uses dedicated `SYNOPSIS_PARSE_SYSTEM_PROMPT`
- Extracts title, department, study_type from synopsis
- Updates project metadata
- Sets section to `"review"`
- No rich text conversion (outputs structured JSON, not LaTeX)

---

### Approval Route (approve/route.ts)

**File**: `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/sections/[phase]/approve/route.ts`

The complete approval flow:

1. **Auth + phase validation**
2. **Phase sequence enforcement**: `typedProject.current_phase !== phaseNumber` returns 409 Conflict
3. **Section status checks**:
   - "generating" -> blocked (409)
   - "approved" -> blocked (409, already approved)
   - "draft" -> auto-promoted to "review" if it has content, then proceeds
4. **Transition check**: `canAdvancePhase(typedProject, "approved")` -- as discussed, the section status argument is always "approved"
5. **Licence gate**: if transition check returns `LICENCE_REQUIRED`, returns 402
6. **Atomic update**: simultaneously approves section and advances `current_phase` to `phaseNumber + 1`
7. **Phase-specific auto-creation**:
   - **Phase 0 approved** -> auto-creates Phase 1 (Front Matter) with generated front matter LaTeX, status "review"
   - **Phase 8 approved** -> auto-creates Phase 9 (References) with citation audit results, status "review"
   - **Phase 10 approved** -> auto-creates Phase 11 (Final QC) with placeholder text, status "review"
   - **Phase 11 approved** -> sets project status to "completed"
8. **Inngest event emission**: `thesis/phase.approved` (non-blocking, skipped if `INNGEST_EVENT_KEY` not configured)

**IMPORTANT GAPS in Approve Route**:

1. **No QC pass verification before Phase 11 approval**: Phase 11 approval (lines 237-245) sets the project to "completed" WITHOUT checking whether the Final QC actually passed. A user can approve Phase 11 even if there are blocking QC failures (Tier D citations, NBEMS violations, etc.). The `overallPass` flag from `finalQC()` is never checked during approval.

2. **Phase 1->2 identity binding NOT implemented**: The PLAN.md mentions identity binding at Phase 1->2 transition (locking the project to the licence holder). The approve route does nothing special at Phase 1 approval beyond the standard licence check. There is no code that binds the project's user identity to the licence.

3. **Phase 6a->6b dataset requirement NOT enforced**: As noted, Phase 6 is a single phase. The approve route does not check that a dataset was uploaded or that analyses were run before approving Phase 6. The UI shows a checklist, but it is purely informational.

4. **Inngest creates duplicate sections**: The Inngest workflow (thesis-workflow.ts) also creates the next section as "draft" on approval. But the approve route already creates some sections (Phase 1, 9, 11) with status "review" and content. Both use `upsert` with `onConflict`, so the Inngest version would overwrite the approve route's richer content if Inngest runs after the approve route creates the section. However, because the approve route creates with status "review" and content, and Inngest creates with status "draft" and empty content, the Inngest upsert would **blank out** the auto-generated content. This is a race condition.

   Looking more carefully: the upsert uses `onConflict: "project_id,phase_number"`, and since the approve route runs synchronously before emitting the Inngest event, the section should already exist when Inngest runs. The Inngest upsert would then overwrite it with empty content and "draft" status. **This is a data loss bug** for Phases 1, 9, and 11.

   Mitigating factor: Inngest is only triggered if `INNGEST_EVENT_KEY` is configured, and the workflow creates the section for `nextPhase = phaseNumber + 1`. For Phase 0 approval (nextPhase=1), Phase 8 approval (nextPhase=9), and Phase 10 approval (nextPhase=11), the Inngest workflow would indeed try to create sections 1, 9, and 11 respectively -- overwriting the auto-generated content.

5. **`phases_completed` array can have duplicates**: The code at line 106-108 appends `phaseNumber` to `phases_completed` without checking if it already exists. If approve is called twice for the same phase (possible via a race condition), the array could contain duplicates.

---

### Review Route (review/route.ts)

**File**: `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/sections/[phase]/review/route.ts`

A **synchronous, local-only** review (no AI API call). Calls `reviewSection()` which performs:

1. **Citation diff**: compares current LaTeX cite keys against `ai_generated_latex` -- flags removed/added citations
2. **Word count check**: against `word-count-targets.ts` ranges
3. **Structure checks** (phase-specific):
   - Phase 4 (ROL): requires `\begin{longtable}`
   - Phase 5 (M&M): requires >= 8 section headings
   - Phase 7 (Discussion): requires "strength" and "limitation" text
   - Phase 8 (Conclusion): requires "conclusion" and "recommendation" text
4. **British English spot-check**: flags American spellings
5. **Citation quality** (for citation-heavy phases): flags Tier D > 50%, missing keys

Returns `{ issues, passedReview }`. `passedReview` is true only if no errors or warnings.

**KEY POINT**: The review is **advisory only**. The workspace's `handleApprove` function calls review first; if issues are found, a `ReviewDialog` opens letting the user see issues but they can click "Approve Anyway" which calls `doApprove()` directly, bypassing all review warnings.

---

### Refine Route (refine/route.ts)

**File**: `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/sections/[phase]/refine/route.ts`

Flow:
1. Auth + phase validation
2. Requires `instructions` string in request body
3. Verifies project ownership
4. Fetches current section; uses `ai_generated_latex` (fallback `latex_content`)
5. **Does NOT change section status to "generating"** -- intentionally, to avoid broken UI on page refresh during streaming
6. Sends current content + student instructions to Claude Sonnet with `REFINE_SYSTEM_PROMPT`
7. On completion: updates section with new content, Tiptap JSON, word count, citations, status `"review"`
8. Citation resolution with 10-second timeout (non-blocking)
9. No cancel handler needed (status was never changed)

**Refine Analysis**:
- **No limit on refine calls**: There is no rate limit or iteration counter. A user can refine indefinitely, consuming tokens from the phase budget (but the refine route **does not check token budget** -- only the generate route does). This is a **budget bypass** -- a user could exhaust arbitrary tokens via refine without any budget check.
- **Citations are preserved**: The refine prompt receives the full current LaTeX (including BibTeX trailer), and the new response replaces everything. Citation keys are re-extracted from the new response. If the AI preserves the BibTeX trailer, citations are preserved. But the AI could also drop or modify citations.
- **Refine replaces everything**: The refine route overwrites `latex_content`, `rich_content_json`, `ai_generated_latex`, `word_count`, and `citation_keys`. It is a full replacement, not a patch.
- **No phase restriction**: Refine does not check that `phaseNumber === project.current_phase`. You can refine any phase's content at any time, even approved sections (the status is set to "review" after refine, which would effectively un-approve it in the DB, but the project's `current_phase` would not regress).

**BUG -- Refine can un-approve sections**: If you refine an already-approved section, the status is changed from "approved" to "review". But the project's `phases_completed` array and `current_phase` are not rolled back. This creates an inconsistent state where the project says phase N is completed but the section says it is in "review".

---

### Sections List Route (sections/route.ts)

**File**: `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/sections/route.ts`

Simple GET -- fetches all sections for a project, ordered by `phase_number`.

---

### Section CRUD Route (sections/[phase]/route.ts)

**File**: `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/sections/[phase]/route.ts`

- **GET**: fetches a single section by project_id + phase_number
- **PUT**: saves section content with two modes:
  - **Rich text mode**: converts Tiptap JSON -> LaTeX via `tiptapToLatex()`
  - **Source mode**: saves raw LaTeX, nullifies `rich_content_json`
  - Auto-promotes "draft" -> "review" when saving non-empty content
  - Preserves existing citation_keys if no new content provided
  - Validates against `sectionUpdateSchema` (Zod)

---

### Inngest Workflow (thesis-workflow.ts)

**File**: `/Users/devs/Downloads/Apollo/apps/web/lib/inngest/functions/thesis-workflow.ts`

Triggered by `thesis/phase.approved` event:
1. Looks up next phase definition
2. If no next phase: returns `{ status: "completed" }`
3. Creates next section as "draft" with empty content (upsert)
4. Waits for next approval event (90-day timeout, matched by `data.projectId`)

**CRITICAL BUG**: As discussed above, this overwrites the auto-generated content from the approve route for Phases 1, 9, and 11. The upsert with empty content + "draft" status would replace the front matter, citation audit, and QC placeholder content.

**Architecture Note**: The Inngest workflow is a simple linear chain. It creates the next section and then waits. It does NOT orchestrate generation, compilation, or any other step. It is effectively redundant because the approve route already advances `current_phase` and the UI reacts to that.

---

### Inngest Events (events.ts)

**File**: `/Users/devs/Downloads/Apollo/apps/web/lib/inngest/events.ts`

Three event types defined:
1. `thesis/phase.approved` -- used by thesis-workflow
2. `thesis/compile.requested` -- defined but **not consumed by any function** (no compile workflow exists)
3. `analysis/run.requested` -- defined but **not consumed by any function** (no analysis workflow exists)

---

### Licence Gate (licence-gate.ts)

**File**: `/Users/devs/Downloads/Apollo/apps/web/lib/api/licence-gate.ts`

Used for **export** operations only (PDF download, etc.), not for generation or approval:
- Checks project exists and belongs to user
- Returns 402 if project status is not `"licensed"` or `"completed"`
- Returns `{ status }` if authorised

**Not used in the phase pipeline at all**. The phase pipeline's licence check is in `canAdvancePhase()` (transitions.ts), called from the approve route.

---

### Final QC (final-qc.ts)

**File**: `/Users/devs/Downloads/Apollo/apps/web/lib/qc/final-qc.ts`

Runs 5 checks:

1. **Citation Provenance**: Runs `auditCitations()`. **Blocking** if any Tier D citations exist. Fix action: `re-resolve-citations`.
2. **Section Completeness**: Checks Phases 2-8 word counts against its own (different!) targets. **Non-blocking** (warning only). Fix action: `expand-section`.
3. **British English**: Checks for American spellings in Phases 2-8 prose. **Non-blocking**. Fix action: `auto-fix-spelling`.
4. **NBEMS Compliance**: Three sub-checks:
   - 80-page limit (250 words/page estimate) -- **blocking**
   - 300-word abstract limit (Phase 1) -- not blocking
   - M&M >= 12 section headings -- **blocking**
5. **Undefined References**: Parses compile log for LaTeX warnings about undefined refs/cites. **Blocking**.

Returns `QCReport { checks, overallPass, blockingCount, warningCount }`.

**KEY ISSUE**: `overallPass` is `blockingCount === 0`. But as noted, the approve route for Phase 11 does NOT check `overallPass`. The QC report is stored in the Phase 11 section's `latex_content` as JSON, but no code reads it during approval.

**ANOTHER ISSUE**: Check 5 (Undefined References) returns `"pass"` with message "No compile log available -- compile first" when `compileLog` is null. This means if the user never compiled, the check passes by default. The `blocking: true` flag is misleading because the status is "pass" -- the `blockingCount` calculation only counts `blocking && status === "fail"`, so a "pass" with `blocking: true` is fine. But semantically, "no compile log" should probably be a "fail" or "warn", not "pass".

---

### QC Route (qc/route.ts)

**File**: `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/qc/route.ts`

- **POST**: Runs `finalQC()` with all sections, citations, and latest compile log. Stores the JSON report in Phase 11 section's `latex_content`. Returns the report.
- **GET**: Retrieves the stored QC report from Phase 11's `latex_content` (parses JSON). Returns null if not found.

**GAP**: The QC route stores the report as JSON in `latex_content`, which is normally LaTeX. This overloads the column's semantic meaning. If the user views Phase 11 in the editor, they would see raw JSON, not rendered LaTeX.

---

### QC Fix Route (qc/fix/route.ts)

**File**: `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/qc/fix/route.ts`

Three fix actions:

1. **`re-resolve-citations`**: Fetches all Tier D citations, attempts re-resolution:
   - First tries `resolveAllEntries()` on existing BibTeX
   - Falls back to CrossRef search by cite key pattern (author+year)
   - Updates resolved citations to Tier B with DOI evidence
   - Returns `{ resolved, failed, total }`

2. **`auto-fix-spelling`**: Replaces American -> British spellings in all "review" or "draft" sections. Only modifies `latex_content`, **does not update `rich_content_json`** -- this creates a mismatch where the rich text editor shows old American spellings but the source view shows corrected British spellings.

3. **`expand-section`**: **Placeholder only** -- returns a JSON message directing the user to the refine endpoint. Not actually implemented.

**BUG -- auto-fix-spelling duplicated regex list**: The `AMERICAN_TO_BRITISH` list is duplicated between `final-qc.ts`, `review-section.ts`, and `qc/fix/route.ts`. If one is updated, the others may not be. This violates DRY.

**BUG -- spelling fix doesn't update rich_content_json**: After fixing American spellings in `latex_content`, the `rich_content_json` still contains the old text. When the user opens the rich text editor, they see the unfixed version. The fix is invisible in rich text mode.

---

### AI Generate Button (ai-generate-button.tsx)

**File**: `/Users/devs/Downloads/Apollo/apps/web/components/project/ai-generate-button.tsx`

- Shows "Generate with AI" button that triggers SSE stream to `/api/projects/{id}/sections/{phase}/generate`
- Shows "Refine" button (after hydration, only when `hasContent` is true and `onRefine` callback provided)
- Shows streaming preview during generation
- Shows citation summary after completion (verified vs unverified counts)
- Shows "Stop" button during streaming
- Shows error messages

**Note**: The button does not disable itself based on licence status -- it relies on the generate route to return errors. But as noted, the generate route does NOT check licence status.

---

### Compile Button (compile-button.tsx)

**File**: `/Users/devs/Downloads/Apollo/apps/web/components/project/compile-button.tsx`

- Posts to `/api/projects/{id}/compile`
- Handles three response scenarios:
  - **202/429 (Queued)**: polls every 5 seconds for queue position
  - **200 + completed**: shows success with compile time and warning count
  - **validation_failed**: shows validation issues
  - **failed**: shows compile errors
- Shows queue position badge with estimated wait time
- `disabled` prop comes from workspace (disabled when no sections are in "approved" or "review" status)
- Calls `onCompileSuccess` callback which refreshes PDF viewer

**DESIGN NOTE**: Compile is available at any phase, not gated by pipeline state. The workspace only disables it when there are no approvable sections. This is fine -- users should be able to preview-compile at any point.

---

### Thesis Completion (thesis-completion.tsx)

**File**: `/Users/devs/Downloads/Apollo/apps/web/components/project/thesis-completion.tsx`

Rendered when `project.status === "completed"`. Shows:
- Success header with title and completion date
- Download cards (PDF and dataset CSV)
- Statistics grid (word count, pages, phases, Tier A citations, dataset rows)
- Important notices/disclaimers
- Actions footer (Back to Dashboard, Export menu)

Uses cursor-tracking sage glow cards. Well-structured celebration page.

**Note**: Hardcodes "12/12 Phases completed" regardless of actual phases_completed array contents.

---

### Project Workspace (project-workspace.tsx)

**File**: `/Users/devs/Downloads/Apollo/apps/web/app/(dashboard)/projects/[id]/project-workspace.tsx`

The central orchestration component. Key behaviors:

1. **State Management**:
   - `viewingPhase`: which phase the user is looking at (defaults to `project.current_phase`)
   - `editorMode`: "richtext" or "source" (auto-selects based on content availability)
   - `mobileTab`: "edit" or "preview" for mobile responsive layout
   - `workspaceTab`: "editor", "data", "compliance", "figures", "progress"
   - Various dialog states (refine, review, citation search, mermaid editor)

2. **Phase Navigation**: Users can click phases in `PipelineTimeline` to view any phase, but can only generate/approve the current phase.

3. **AI Generation**:
   - `AI_GENERATABLE_PHASES = {0, 1, 2, 3, 4, 5, 6, 7, 8, 10}` -- Phase 9 and 11 are excluded (auto-created)
   - Generate button shown only when `isCurrentPhase && AI_GENERATABLE_PHASES.has(viewingPhase)`
   - On generate complete: calls `router.refresh()` + auto-compiles

4. **Approval Flow**:
   - "Approve & Advance" button shown when `isCurrentPhase && section.status in ("review", "draft") && section has content`
   - Calls review route first; if issues found, opens ReviewDialog
   - ReviewDialog has "Approve Anyway" option
   - On approve: `router.refresh()` + auto-compile

5. **Refine Flow**:
   - "Refine" button in AIGenerateButton opens refine dialog in workspace
   - User enters instructions in textarea
   - Submits to refine route, consumes SSE stream to completion
   - On complete: `router.refresh()` + auto-compile

6. **Editor Rendering**:
   - Rich text: `SectionEditor` (dynamic import, Novel-based)
   - Source: `LaTeXSourceView` (dynamic import, CodeMirror-based)
   - Read-only: `SectionViewer` (for approved/generating sections)
   - Toggle between modes via pill buttons

7. **Phase 6 Results Checklist**: Shows 3-step checklist (dataset, analyses, generate) but is purely informational.

8. **Workspace Tabs**: data & analysis, compliance, figures, progress -- additional views beyond the main editor.

**ISSUES**:

1. **Refine SSE stream is consumed silently**: The workspace reads the entire SSE stream just to wait for completion (lines 657-664), but does not display streaming progress to the user. The user sees "Refining..." on the button but no preview of changes.

2. **Auto-compile on every action**: `handleGenerateComplete` and `handleSaveSuccess` both call `compileAndRefreshPdf()`. This means every save or generation triggers a compile. With a 1-concurrent-compile limit, this could queue compiles unnecessarily.

3. **citationSearchOpen onInsert ignores citeKey**: Line 701 -- the `onInsert` callback receives `citeKey` but only closes the dialog and refreshes; it doesn't insert the cite key into the editor.

4. **Phase 10 (Appendices) in AI_GENERATABLE_PHASES but likely fails**: The generate route requires a non-null system prompt from `getPhaseSystemPrompt(10)`. If this returns null, the generate route returns 400. The UI shows the generate button but clicking it would fail.

---

### Complete Phase Lifecycle Walkthrough

**Phase 0 (Orientation)**:
1. User uploads synopsis to project
2. Clicks "Generate with AI" -> generate route parses synopsis via Claude
3. Extracts title, department, study_type -> updates project metadata
4. Section created with status "review"
5. User reviews extracted metadata, clicks "Approve & Advance"
6. Review route checks (no meaningful checks for Phase 0)
7. Approve route: advances to Phase 1, auto-creates Phase 1 section with front matter LaTeX in "review" status
8. **Risk**: Inngest workflow could overwrite Phase 1 content with empty draft

**Phase 1 (Front Matter)**:
1. Phase 1 section already exists (auto-created by Phase 0 approval) with generated front matter
2. User can edit names, titles, certificates
3. Clicks "Approve & Advance"
4. **Licence check**: `canAdvancePhase` checks if Phase 2 requires licence -> YES
5. If project is sandbox -> blocked with `LICENCE_REQUIRED`
6. If licensed -> advances to Phase 2
7. **No identity binding** -- PLAN.md says bind licence to user here, but code doesn't

**Phases 2-8 (Content Phases)**:
1. User clicks "Generate with AI"
2. Generate route: gathers previous approved sections as context, redacts PII, pre-seeds citations (phases 2,4,5,7)
3. Phase 6 special: gathers analysis results and figures for context
4. Streams LaTeX response, converts to Tiptap, stores with "review" status
5. User can edit in rich text or source mode
6. User can "Refine" with instructions (unlimited, no token budget check)
7. User can save edits (PUT endpoint)
8. User clicks "Approve & Advance"
9. Review route runs local checks (word count, structure, citations, British English)
10. If issues: ReviewDialog shown, user can "Approve Anyway"
11. Approve route: verifies phase sequence, licence status, advances phase
12. Phase 8 special: auto-creates Phase 9 with citation audit

**Phase 9 (References)**:
1. Auto-created by Phase 8 approval with citation audit summary
2. **Not in AI_GENERATABLE_PHASES** in the workspace... actually checking: `AI_GENERATABLE_PHASES = new Set([0, 1, 2, 3, 4, 5, 6, 7, 8, 10])` -- Phase 9 is excluded. User cannot generate it with AI.
3. User reviews citation audit, can edit, then approves
4. No special handling on Phase 9 approval

**Phase 10 (Appendices)**:
1. Inngest workflow creates empty draft section (if configured)
2. Phase 10 IS in `AI_GENERATABLE_PHASES`, but `getPhaseSystemPrompt(10)` likely returns null -> badRequest
3. User must manually write appendices or approve an empty/minimal section
4. On approval: auto-creates Phase 11 placeholder

**Phase 11 (Final QC)**:
1. Auto-created by Phase 10 approval with placeholder text "Run Final QC to generate the quality report"
2. **Not in AI_GENERATABLE_PHASES** (Phase 11 excluded)
3. User must manually trigger QC via the `/api/projects/{id}/qc` POST endpoint
4. **BUT there is no QC trigger button in the workspace UI!** The workspace does not render a "Run QC" button for Phase 11. The compliance dashboard tab exists but is separate.
5. QC report is stored as JSON in Phase 11's `latex_content`
6. User clicks "Approve & Advance" for Phase 11
7. **No QC pass check** -- approval proceeds regardless of QC results
8. Project status set to "completed"
9. UI switches to ThesisCompletion celebration view

---

### Summary of Critical Issues

**Severity: High**

1. **Inngest overwrites auto-generated content**: The Inngest workflow creates empty draft sections for phases 1, 9, and 11, potentially overwriting the auto-generated front matter, citation audit, and QC placeholder created by the approve route. This is a **data loss bug**.

2. **Phase 11 approval skips QC verification**: Users can approve Phase 11 and complete the thesis even with blocking QC failures (Tier D citations, NBEMS violations, undefined references).

3. **No QC trigger in workspace UI**: There is no button in the workspace to run Final QC for Phase 11. The QC route exists but is not wired to the UI.

4. **Refine route bypasses token budget**: Refine calls consume tokens without any budget check, allowing unlimited token usage.

5. **Word count targets mismatch**: `word-count-targets.ts` and `final-qc.ts` have different ranges for the same phases.

**Severity: Medium**

6. **No dataset/analysis requirement for Phase 6**: The 6a/6b split from PLAN.md is not implemented. Users can generate and approve Results without any dataset.

7. **No Phase 1->2 identity binding**: Licence-to-user binding at Phase 1->2 transition is not implemented.

8. **Refine can un-approve sections**: Refining an approved section changes its status to "review" without rolling back the project's phase tracking.

9. **Spelling fix doesn't update rich_content_json**: The QC fix for British English only updates `latex_content`, leaving `rich_content_json` inconsistent.

10. **Generate route lacks phase sequence enforcement**: Content can be generated for any phase, not just the current one.

11. **canAdvancePhase section status check is dead code**: The approve route always passes `"approved"` literal, never the actual section status.

**Severity: Low**

12. **Duplicated AMERICAN_TO_BRITISH dictionary**: Three copies across `final-qc.ts`, `review-section.ts`, and `qc/fix/route.ts`.

13. **Phase 10 generate button shows but fails**: Listed in `AI_GENERATABLE_PHASES` but `getPhaseSystemPrompt(10)` likely returns null.

14. **Compile triggered on every save**: Auto-compile on save could create unnecessary queue pressure.

15. **`phases_completed` can have duplicates**: No deduplication check.

16. **Undefined references check passes when no compile log exists**: Should warn, not pass.

17. **ThesisCompletion hardcodes "12/12"**: Does not check actual `phases_completed`.</result>
<usage>total_tokens: 83376
tool_uses: 28
duration_ms: 244065</usage>
</task-notification>
Full transcript available at: /private/tmp/claude-501/-Users-devs-Downloads-Apollo/tasks/a77af11.output

---

Now do a 3rd pass to check frontend code, frontend backend linkage, unwired stuff, anything missing as per previous PLAN, andy suggestions from your end? This pass is purely for frontend backend linkage and wiring. Create part III of the review report. [one question from part II... what is the optimum solution to the latex round trip problem? can we do a Modified option C? ie Latex is canonical, and shown to user, no need for rich text, but the latex syntax, codes etc are in a diff font or color which remains uneditable to the user?]

---

<task-notification>
<task-id>a990a75</task-id>
<status>completed</status>
<summary>Agent "Audit API routes vs frontend calls" completed</summary>
<result>Perfect. Now I have comprehensive information about all the API routes. Let me compile the final report:

## API Routes and Frontend Callers - Comprehensive Analysis

### COMPLETE API ROUTE INVENTORY (47 routes)

#### **Project Management** (5 routes)
1. **GET /api/projects** - List all projects (user's own) | POST /api/projects - Create new project
   - Callers: `app/(dashboard)/projects/new/page.tsx` (POST create), likely dashboard pages
   - Methods: GET, POST
   - Auth: Required (user owns projects)

2. **GET /api/projects/[id]** - Get single project | PATCH /api/projects/[id] - Update project | DELETE /api/projects/[id] - Archive project
   - Callers: project-workspace, dashboard pages
   - Methods: GET, PATCH, DELETE
   - Auth: Required (user owns project)

#### **Sections & Content** (7 routes)
3. **GET /api/projects/[id]/sections** - List all sections for project
   - Callers: project-workspace (fetches all sections)
   - Methods: GET
   - Auth: Required

4. **GET /api/projects/[id]/sections/[phase]** - Get single section | PUT /api/projects/[id]/sections/[phase] - Update section (rich editor or source save)
   - Callers: project-workspace (editor saves)
   - Methods: GET, PUT
   - Auth: Required
   - Mismatch: PUT expects rich_content_json OR latex_content (editor save mode)

5. **POST /api/projects/[id]/sections/[phase]/generate** - Stream AI-generated section via SSE
   - Callers: ai-generate-button.tsx (via EventSource)
   - Methods: POST
   - Returns: Server-Sent Events stream
   - Auth: Required
   - Note: Streams delta JSON, complete event, [DONE]

6. **POST /api/projects/[id]/sections/[phase]/review** - AI validation (non-blocking warnings)
   - Callers: None found in frontend (likely internal/unused)
   - Methods: POST
   - Returns: { data: ReviewIssue[] }
   - Auth: Required

7. **POST /api/projects/[id]/sections/[phase]/approve** - Approve section & advance phase
   - Callers: project-workspace (via button click)
   - Methods: POST
   - Returns: { data: { section, project, advanced_to_phase } }
   - Auth: Required
   - Gate: Licence required for Phase 2+

8. **POST /api/projects/[id]/sections/[phase]/refine** - Stream AI refinement (student instructions)
   - Callers: project-workspace (via refine dialog)
   - Methods: POST
   - Returns: Server-Sent Events stream
   - Auth: Required
   - Body: { instructions: string }

#### **Citations** (6 routes)
9. **GET /api/projects/[id]/citations** - List all citations
   - Callers: project-workspace
   - Methods: GET
   - Auth: Required

10. **POST /api/projects/[id]/citations** - Add/resolve citation (DOI, PMID, or raw BibTeX)
    - Callers: citation-search-dialog.tsx (POST with doi/pmid)
    - Methods: POST
    - Body: { doi?: string, pmid?: string, bibtex_entry?: string, cite_key?: string }
    - Returns: { data: Citation }
    - Auth: Required

11. **PUT /api/projects/[id]/citations/[citationId]** - Update citation | DELETE /api/projects/[id]/citations/[citationId]** - Delete citation
    - Callers: citation-list-panel.tsx (PUT to attest, DELETE)
    - Methods: PUT, DELETE
    - Auth: Required

12. **POST /api/projects/[id]/citations/[citationId]/re-resolve** - Auto-resolve Tier D citation
    - Callers: citation-list-panel.tsx (POST)
    - Methods: POST
    - Auth: Required

13. **POST /api/projects/[id]/citations/audit** - Run integrity audit
    - Callers: citation-list-panel.tsx (POST)
    - Methods: POST
    - Returns: { data: AuditResult }
    - Auth: Required

14. **GET /api/citations/search** - Search PubMed/CrossRef
    - Callers: citation-search-dialog.tsx (GET with query params)
    - Methods: GET
    - Query: ?q=...&source=pubmed|crossref&limit=10
    - Auth: Required

#### **Analyses & Datasets** (8 routes)
15. **GET /api/projects/[id]/analyses** - List analyses | POST /api/projects/[id]/analyses** - Run analysis
    - Callers: analysis-wizard.tsx (GET to list, POST to run)
    - Methods: GET, POST
    - Body: { dataset_id, analysis_type, parameters: {...} }
    - Auth: Required

16. **POST /api/projects/[id]/analyses/auto-detect** - AI recommend analyses from dataset
    - Callers: analysis-wizard.tsx (POST)
    - Methods: POST
    - Body: { dataset_id }
    - Returns: { data: AnalysisRecommendation[] }
    - Auth: Required

17. **GET /api/projects/[id]/analyses/[analysisId]** - Get analysis result
    - Callers: analysis-wizard.tsx (poll for completion)
    - Methods: GET
    - Auth: Required

18. **GET /api/projects/[id]/datasets** - List datasets | POST /api/projects/[id]/datasets** - Upload dataset
    - Callers: dataset-upload.tsx (GET to list, POST with FormData)
    - Methods: GET, POST
    - Auth: Required

19. **GET /api/projects/[id]/datasets/[datasetId]** - Get dataset | DELETE /api/projects/[id]/datasets/[datasetId]** - Delete dataset
    - Callers: dataset-upload.tsx (DELETE)
    - Methods: GET, DELETE
    - Auth: Required

20. **POST /api/projects/[id]/datasets/generate** - AI-generate synthetic dataset
    - Callers: dataset-upload.tsx (POST)
    - Methods: POST
    - Body: { sample_size, context }
    - Auth: Required

21. **GET /api/projects/[id]/datasets/[datasetId]/download** - Download dataset as CSV
    - Callers: None found (likely unused or behind download button)
    - Methods: GET
    - Auth: Required

#### **Figures & Diagrams** (4 routes)
22. **GET /api/projects/[id]/figures** - List figures | POST /api/projects/[id]/figures** - Upload figure
    - Callers: figure-gallery.tsx (GET, POST with FormData)
    - Methods: GET, POST
    - Auth: Required

23. **GET /api/projects/[id]/figures/[figureId]** - Get figure | DELETE /api/projects/[id]/figures/[figureId]** - Delete figure
    - Callers: figure-gallery.tsx (DELETE)
    - Methods: GET, DELETE
    - Auth: Required

24. **POST /api/projects/[id]/figures/mermaid** - Save Mermaid diagram
    - Callers: mermaid-editor.tsx (POST)
    - Methods: POST
    - Body: { source_code, caption, label, figure_type }
    - Auth: Required

#### **Compilation & QC** (6 routes)
25. **POST /api/projects/[id]/compile** - Compile thesis to PDF
    - Callers: compile-button.tsx (POST, polling)
    - Methods: POST
    - Returns: { data: { compilation_id, status, warnings, errors } }
    - Auth: Required
    - Gate: Admission control (1 concurrent), semaphore queue

26. **GET /api/projects/[id]/preview.pdf** - Stream compiled PDF
    - Callers: pdf-viewer.tsx, project-workspace
    - Methods: GET
    - Query: ?download=1 (sets disposition)
    - Auth: Required
    - Returns: PDF binary with Content-Type: application/pdf

27. **GET /api/projects/[id]/compilations** - List compilation history
    - Callers: None found (likely unused dashboard)
    - Methods: GET
    - Auth: Required

28. **POST /api/projects/[id]/qc** - Run Final QC check
    - Callers: None found (likely phase 11 auto-trigger)
    - Methods: POST, GET
    - Returns: { data: QCReport }
    - Auth: Required

29. **POST /api/projects/[id]/qc/fix** - Re-resolve citations or fix spelling
    - Callers: None found (quality panel, if exists)
    - Methods: POST
    - Body: { action: "re-resolve-citations"|"auto-fix-spelling"|"expand-section", phaseNumber? }
    - Auth: Required

#### **Compliance & Quality** (2 routes)
30. **GET /api/projects/[id]/compliance** - Get compliance checks | POST /api/projects/[id]/compliance** - Run compliance check
    - Callers: compliance-dashboard.tsx (GET on load, POST to run)
    - Methods: GET, POST
    - Body: { guideline_type: "NBEMS"|"PRISMA"|... }
    - Auth: Required

#### **Abbreviations** (2 routes)
31. **GET /api/projects/[id]/abbreviations** - List | POST /api/projects/[id]/abbreviations** - Add abbreviation
    - Callers: abbreviation-manager.tsx (GET, POST)
    - Methods: GET, POST
    - Body: { short_form, long_form }
    - Auth: Required

32. **PUT /api/projects/[id]/abbreviations/[abbrevId]** - Update | DELETE /api/projects/[id]/abbreviations/[abbrevId]** - Delete
    - Callers: abbreviation-manager.tsx (PUT, DELETE)
    - Methods: PUT, DELETE
    - Auth: Required

#### **Review & Sharing** (3 routes)
33. **POST /api/projects/[id]/share** - Generate review token | GET /api/projects/[id]/share** - List review tokens
    - Callers: share-dialog.tsx (POST to generate)
    - Methods: POST, GET
    - Returns: { data: { token, share_url, expires_at } }
    - Auth: Required (owner only)

34. **GET /api/review/[token]** - Validate review link (public)
    - Callers: app/review/[token]/page.tsx (GET)
    - Methods: GET
    - Returns: { data: { project, sections, pdf_url, token_id } }
    - Auth: None (token-based, public but time-limited)

35. **GET /api/review/[token]/comments** - List review comments | POST /api/review/[token]/comments** - Add comment
    - Callers: app/review/[token]/page.tsx (GET to list, POST to add)
    - Methods: GET, POST
    - Body: { reviewer_name, phase_number, comment_text }
    - Auth: None (token-based)

#### **Exports** (4 routes)
36. **GET /api/projects/[id]/export/pdf** - Export to PDF
    - Callers: None found (likely export menu)
    - Methods: GET
    - Auth: Required, Licence-gated

37. **GET /api/projects/[id]/export/docx** - Export to DOCX
    - Callers: None found
    - Methods: GET
    - Auth: Required, Licence-gated

38. **GET /api/projects/[id]/export/source** - Export LaTeX source
    - Callers: None found
    - Methods: GET
    - Returns: { data: { "main.tex": ..., "refs.bib": ..., chapters..., .cls } }
    - Auth: Required, Licence-gated

39. **GET /api/projects/[id]/export/stats** - Export analysis stats
    - Callers: None found
    - Methods: GET
    - Returns: { data: { analyses, datasets } }
    - Auth: Required, Licence-gated

#### **Licenses & Payment** (3 routes)
40. **GET /api/licenses** - List user's licences
    - Callers: Not found in frontend (likely used during checkout flow)
    - Methods: GET
    - Auth: Required

41. **POST /api/licenses/[lid]/attach/[pid]** - Attach licence to project
    - Callers: attach-dialog.tsx (likely, POST)
    - Methods: POST
    - Auth: Required

42. **POST /api/licenses/[lid]/transfer** - Transfer licence (cooldown trigger)
    - Callers: None found (likely licence management UI)
    - Methods: POST
    - Auth: Required

43. **POST /api/checkout** - Initiate payment (Razorpay/Stripe)
    - Callers: app/(dashboard)/checkout/page.tsx (POST)
    - Methods: POST
    - Body: { plan_type, currency: "INR"|"USD", project_id? }
    - Returns: { data: { provider, order_id|redirect_url, ... } }
    - Auth: Required

#### **Utilities** (3 routes)
44. **POST /api/upload/signed-url** - Generate R2 upload URL
    - Callers: file-uploader.tsx (likely POST)
    - Methods: POST
    - Body: { fileName, contentType, projectId }
    - Returns: { data: { url, fields } }
    - Auth: Required

45. **POST /api/synopsis/parse** - AI parse synopsis to metadata
    - Callers: setup-wizard.tsx (likely POST)
    - Methods: POST
    - Body: { synopsis_text }
    - Returns: { data: { title, aims, objectives, study_type, ... } }
    - Auth: Required

#### **Webhooks & Inngest** (3 routes)
46. **POST /api/inngest** - Inngest workflow dispatcher (GET, POST, PUT)
    - Callers: Internal (Inngest only)
    - Methods: GET, POST, PUT
    - Auth: None (Inngest signing)

47. **POST /api/webhooks/clerk** - Clerk user sync webhook
    - Callers: External (Clerk)
    - Methods: POST
    - Auth: Clerk signature verification

48. **POST /api/webhooks/razorpay** - Razorpay payment webhook
    - Callers: External (Razorpay)
    - Methods: POST
    - Auth: Webhook signature verification

49. **POST /api/webhooks/stripe** - Stripe payment webhook
    - Callers: External (Stripe)
    - Methods: POST
    - Auth: Webhook signature verification

---

### KEY FINDINGS

#### **Unwired/Dead Routes** (Never called from frontend):
- `/api/projects/[id]/sections/[phase]/review` (POST) - AI review endpoint exists but not exposed to UI
- `/api/projects/[id]/compilations` (GET) - Compilation history not displayed
- `/api/projects/[id]/qc` (POST) - QC check exists but may be auto-triggered
- `/api/projects/[id]/export/pdf`, `/docx`, `/source`, `/stats` (all GET) - Export menu not implemented in UI
- `/api/licenses` (GET) - Not found in checkout flow
- `/api/licenses/[lid]/transfer` (POST) - Licence transfer UI missing
- `/api/projects/[id]/qc/fix` (POST) - Quality fixes UI missing
- `/api/projects/[id]/datasets/[datasetId]/download` (GET) - Download button not found
- `/api/citations/search` (GET) - IMPLEMENTED AND CALLED by citation-search-dialog.tsx

#### **Streaming/SSE Connections** (3 routes):
1. `/api/projects/[id]/sections/[phase]/generate` - Consumed by EventSource listener
2. `/api/projects/[id]/sections/[phase]/refine` - Consumed by EventSource listener

#### **Request/Response Mismatches**:
- **No major mismatches found** - All callers match API expectations
- Routes use POST for state-changing operations (approve, generate, compile)
- Routes use GET for read operations
- Section PUT expects either rich_content_json (editor mode) or latex_content (source mode)

#### **Middleware Protection** (`middleware.ts`):
- Protected routes via Clerk: `/dashboard`, `/projects`, `/licences`, `/checkout`, `/api/projects`, `/api/licenses`, `/api/upload`
- Public routes: Landing page, review page (via token)
- **Gap**: Webhooks (Clerk, Razorpay, Stripe) bypass Clerk middleware (correct - they use signature verification instead)

#### **Admission Control & Gating**:
- `/api/projects/[id]/compile` - Semaphore with queue (1 concurrent)
- `/api/projects/[id]/sections/[phase]/generate` - Rate limit check + token budget check
- `/api/projects/[id]/analyses` - Semaphore (2 concurrent)
- Licence gate on exports: `checkLicenceGate()` for PDF, DOCX, Source, Stats exports

#### **Authentication Methods**:
- **User routes**: Clerk auth via `getAuthenticatedUser()` (checks session)
- **Public routes**: None (all require auth except webhooks/review tokens)
- **Token-based**: `/api/review/[token]/*` (time-limited, no user login required)
- **Webhook routes**: HMAC signature verification (Clerk, Razorpay, Stripe)

---

This completes a comprehensive map of all 49 API routes and their frontend integration status.</result>
<usage>total_tokens: 112681
tool_uses: 58
duration_ms: 81991</usage>
</task-notification>
Full transcript available at: /private/tmp/claude-501/-Users-devs-Downloads-Apollo/tasks/a990a75.output

---

This session is being continued from a previous conversation that ran out of context. The summary below covers the earlier portion of the conversation.

Analysis:
Let me chronologically analyze the entire conversation:

1. **Context from previous session**: The conversation is a continuation from a previous session that ran out of context. The previous session covered:
   - Part I: Infrastructure-level gap analysis (completed and delivered)
   - Part II: Deep-dive business logic audit using 5 parallel agents (data gathered, synthesis pending)

2. **Start of current session**: I retrieved outputs from all 5 completed agents (a3d46a3, a8dc46a, a54e776, a5afa5e, a77af11) and synthesized the Part II report.

3. **Part II Report Delivered**: Comprehensive report with 47 issues across 6 domains:
   - AI Integration Pipeline (10 issues)
   - Citation Pipeline (5 issues)
   - LaTeX Pipeline (9 issues)
   - R Analysis & Figure Pipeline (8 issues)
   - Phase Transitions & Pipeline Flow (13 issues)
   - Cross-Cutting Issues (5 issues)
   - Prioritized: 12 P0, 18 P1, 17 P2

4. **Multiple agent completion notifications**: Several delayed notifications came in (a8dc46a, a3d46a3, a5afa5e, a54e776, a77af11) - all already incorporated into the report.

5. **User's third request**: "Now do a 3rd pass to check frontend code, frontend backend linkage, unwired stuff, anything missing as per previous PLAN, any suggestions from your end? This pass is purely for frontend backend linkage and wiring. Create part III of the review report. [one question from part II... what is the optimum solution to the latex round trip problem? can we do a Modified option C? ie Latex is canonical, and shown to user, no need for rich text, but the latex syntax, codes etc are in a diff font or color which remains uneditable to the user?]"

6. **My response to LaTeX question**: I endorsed Modified Option C as the optimal solution - using CodeMirror 6 as the primary editor with:
   - Syntax-highlighted LaTeX commands in different font/color
   - Atomic ranges/transaction filters to protect structural commands
   - Toolbar for WYSIWYG-like shortcuts (Bold  \textbf{}, etc.)
   - \cite{} rendered as inline chip/badge decorations
   - Complex environments get fold markers
   - Eliminates entire round-trip, no Tiptap dependency
   - Only targeted sanitisation needed (sanitiseChapterLatex, escapeBareAmpersands, normaliseUnicode)

7. **Launched 4 parallel agents for Part III**:
   - Agent a230c7b: Audit frontend components and wiring (still running)
   - Agent a990a75: Audit API routes vs frontend calls (completed)
   - Agent a0d4277: Audit PLAN.md frontend requirements (still running)
   - Agent a2ae992: Audit workspace component wiring (still running)

8. **Agent a990a75 completed** with comprehensive findings:
   - 49 API routes mapped
   - Unwired/dead routes identified: review, compilations, QC, export/pdf, export/docx, export/source, export/stats, licenses GET, licenses transfer, QC fix, datasets download
   - SSE connections mapped (generate, refine)
   - Middleware protection analysis
   - No major request/response mismatches found

9. **Checked other agents**: a230c7b, a0d4277, a2ae992 still running. Read partial outputs showing they are deep into analysis.

10. **No code changes made** in this session - purely research/analysis.

Key files referenced in findings:
- All API routes in apps/web/app/api/
- All components in apps/web/components/
- hooks/use-sse.ts - SSE streaming hook
- Various workspace components
- Template gallery, tour overlay, attach dialog, share dialog, export menu, licence banner, word count bar

The user's explicit requests were:
1. Continue from where left off (synthesize Part II) - DONE
2. Part III frontend-backend linkage audit - IN PROGRESS (agents running)
3. Answer about Modified Option C for LaTeX round-trip - DONE

No code has been written or modified in this session.

Summary:
1. Primary Request and Intent:
   The user has been conducting a comprehensive multi-part gap analysis of the Apollo thesis generation platform. The conversation spans three review passes:
   
   **Part I (completed in prior session)**: Infrastructure-level gap analysis comparing codebase against `/docs/PLAN.md`. Found CI failure, 51 uncommitted files, sprint completion gaps, schema discrepancies (Clerk vs Supabase Auth was intentional), RLS recursion bugs, duplicate migrations.
   
   **Part II (synthesized and delivered this session)**: Deep-dive audit of ALL business logic pipelines. User specifically requested: "Check the actual business code, the thesis generation pipeline, from beginning to end. Focus hard on the AI integration lacunae, AI system prompts which I feel are just bare minimum, the citation pipeline and its integration to the main thesis pipeline, the Refine, Re-verify citations, etc pipelines and their integration to the main pipeline, the Data Analysis pipeline in detail and depth, its weaknesses, failure points, and its integration to the main pipeline. The figure generation pipeline (not just single plots per analysis and none for descriptive), the figure storage and downloadability lacunae. There should be a minimum number of figures and tables requirement per thesis."
   
   **Part III (currently in progress)**: User requested: "Now do a 3rd pass to check frontend code, frontend backend linkage, unwired stuff, anything missing as per previous PLAN, any suggestions from your end? This pass is purely for frontend backend linkage and wiring. Create part III of the review report."
   
   **LaTeX Round-Trip Question**: User asked: "what is the optimum solution to the latex round trip problem? can we do a Modified option C? ie Latex is canonical, and shown to user, no need for rich text, but the latex syntax, codes etc are in a diff font or color which remains uneditable to the user?"  I endorsed this approach with a detailed architectural specification using CodeMirror 6.

2. Key Technical Concepts:
   - **GOLD Standard 12-Phase Methodology**: Phases 0-11 for thesis generation with human-in-the-loop approval gates
   - **LaTeX Round-Trip Problem**: AI generates LaTeX  `latexToTiptap()` for rich editor  `tiptapToLatex()` for compile. This is LOSSY  destroys inline math ($p < 0.05$), \footnote{}, \url{}, \textsuperscript{}, \label{}
   - **Modified Option C (Recommended Solution)**: LaTeX is canonical, CodeMirror 6 as primary editor with syntax-highlighted decorations, atomic ranges for structural commands, toolbar for WYSIWYG shortcuts, eliminates entire round-trip
   - **3-Tier DB Fallback**: `rich_content_json` (primary)  `latex_content` with round-trip sanitization (fallback)  empty (skip)
   - **Citation Provenance Tiers**: A (DOI/PMID auto-verified), B (ISBN/URL student-confirmed), C (manual attestation), D (unresolvable  blocks Phase 11)
   - **BibTeX `---BIBTEX---` Separator**: AI outputs separator after chapter content; split for assembly
   - **SSE Streaming**: Used for AI generation and refinement via `useSSE()` hook
   - **Semaphore Admission Control**: In-memory, 3 units max (compile=2, analysis=1), queue promotion bug
   - **Docker Isolation**: LaTeX (`network_mode: none`, read-only, 1GB limit) and R Plumber (port 8787, 512MB limit)
   - **University Template System**: `sskm-thesis.cls` (WBUHS) and `ssuhs-thesis.cls` (SSUHS) with harmonized 50+ command API
   - **Inngest Workflows**: `thesis/phase.approved` events, but workflow creates empty drafts that overwrite auto-generated content (data loss bug)

3. Files and Code Sections:

   **Part II Report  Key files referenced (no modifications made):**
   
   - `apps/web/lib/ai/prompts.ts`  System prompts for all 12 phases. Issues: Phase 9 missing, Phase 6a/6b conflated, previous section context truncated to 3000 chars, no Unicode warning in COMMON_RULES, word count targets disagree with other files.
   
   - `apps/web/lib/ai/token-budget.ts`  Token tracking. Issues: refine/dataset/synopsis bypass budget, input+output tokens conflated, messages_json always empty.
   
   - `apps/web/lib/ai/review-section.ts`  Purely rule-based review (no AI). Issues: M&M check requires 8 sections (prompt says 12, QC says 12), word count targets disagree.
   
   - `apps/web/lib/citations/auto-resolve.ts`  Post-generation citation resolver. Critical bug: orphan cite keys without DB records bypass Tier D stripping in compile.
   
   - `apps/web/lib/latex/latex-to-tiptap.ts`  LaTeX to Tiptap conversion (lossy). Destroys inline math, \footnote{}, \url{}, \textsuperscript{}.
   
   - `apps/web/lib/latex/tiptap-to-latex.ts`  Tiptap to LaTeX conversion. `escapeLatex()` destroys `Analysis:
Let me chronologically analyze the entire conversation:

1. **Context from previous session**: The conversation is a continuation from a previous session that ran out of context. The previous session covered:
   - Part I: Infrastructure-level gap analysis (completed and delivered)
   - Part II: Deep-dive business logic audit using 5 parallel agents (data gathered, synthesis pending)

2. **Start of current session**: I retrieved outputs from all 5 completed agents (a3d46a3, a8dc46a, a54e776, a5afa5e, a77af11) and synthesized the Part II report.

3. **Part II Report Delivered**: Comprehensive report with 47 issues across 6 domains:
   - AI Integration Pipeline (10 issues)
   - Citation Pipeline (5 issues)
   - LaTeX Pipeline (9 issues)
   - R Analysis & Figure Pipeline (8 issues)
   - Phase Transitions & Pipeline Flow (13 issues)
   - Cross-Cutting Issues (5 issues)
   - Prioritized: 12 P0, 18 P1, 17 P2

4. **Multiple agent completion notifications**: Several delayed notifications came in (a8dc46a, a3d46a3, a5afa5e, a54e776, a77af11) - all already incorporated into the report.

5. **User's third request**: "Now do a 3rd pass to check frontend code, frontend backend linkage, unwired stuff, anything missing as per previous PLAN, any suggestions from your end? This pass is purely for frontend backend linkage and wiring. Create part III of the review report. [one question from part II... what is the optimum solution to the latex round trip problem? can we do a Modified option C? ie Latex is canonical, and shown to user, no need for rich text, but the latex syntax, codes etc are in a diff font or color which remains uneditable to the user?]"

6. **My response to LaTeX question**: I endorsed Modified Option C as the optimal solution - using CodeMirror 6 as the primary editor with:
   - Syntax-highlighted LaTeX commands in different font/color
   - Atomic ranges/transaction filters to protect structural commands
   - Toolbar for WYSIWYG-like shortcuts (Bold  \textbf{}, etc.)
   - \cite{} rendered as inline chip/badge decorations
   - Complex environments get fold markers
   - Eliminates entire round-trip, no Tiptap dependency
   - Only targeted sanitisation needed (sanitiseChapterLatex, escapeBareAmpersands, normaliseUnicode)

7. **Launched 4 parallel agents for Part III**:
   - Agent a230c7b: Audit frontend components and wiring (still running)
   - Agent a990a75: Audit API routes vs frontend calls (completed)
   - Agent a0d4277: Audit PLAN.md frontend requirements (still running)
   - Agent a2ae992: Audit workspace component wiring (still running)

8. **Agent a990a75 completed** with comprehensive findings:
   - 49 API routes mapped
   - Unwired/dead routes identified: review, compilations, QC, export/pdf, export/docx, export/source, export/stats, licenses GET, licenses transfer, QC fix, datasets download
   - SSE connections mapped (generate, refine)
   - Middleware protection analysis
   - No major request/response mismatches found

9. **Checked other agents**: a230c7b, a0d4277, a2ae992 still running. Read partial outputs showing they are deep into analysis.

10. **No code changes made** in this session - purely research/analysis.

Key files referenced in findings:
- All API routes in apps/web/app/api/
- All components in apps/web/components/
- hooks/use-sse.ts - SSE streaming hook
- Various workspace components
- Template gallery, tour overlay, attach dialog, share dialog, export menu, licence banner, word count bar

The user's explicit requests were:
1. Continue from where left off (synthesize Part II) - DONE
2. Part III frontend-backend linkage audit - IN PROGRESS (agents running)
3. Answer about Modified Option C for LaTeX round-trip - DONE

No code has been written or modified in this session.

 signs making inline math literal text.
   
   - `apps/web/lib/latex/assemble.ts`  Thesis assembly. Phase 10 appendices generated but template never \input's them. Abbreviations never injected.
   
   - `apps/web/lib/latex/compile.ts`  Docker/local/mock compilation. PDF storage ephemeral (os.tmpdir). Local mode ignores watermark.
   
   - `apps/web/lib/latex/generate-tex.ts`  Template filling. Adds `\usepackage{mathrsfs}` but NOT installed in Docker.
   
   - `apps/web/lib/r-plumber/analysis-runner.ts`  R analysis execution. Figures stored in tmpdir (R2 not wired). No figure download endpoint.
   
   - `docker/plumber.R`  9 R analysis endpoints. Descriptive produces NO figures (only Table 1).
   
   - `apps/web/lib/compute/semaphore.ts`  In-memory admission control. Queue promotion bug: resolve callbacks are no-ops.
   
   - `apps/web/lib/inngest/functions/thesis-workflow.ts`  Overwrites auto-generated content for Phases 1, 9, 11 with empty drafts. DATA LOSS BUG.
   
   - `apps/web/app/api/projects/[id]/sections/[phase]/approve/route.ts`  Phase 11 approval skips QC verification. canAdvancePhase section status check is dead code.
   
   - `apps/web/app/api/projects/[id]/sections/[phase]/refine/route.ts`  No token budget check. Can un-approve already-approved sections.
   
   - `apps/web/lib/qc/final-qc.ts`  5 checks, word count targets disagree with word-count-targets.ts. Undefined references check passes when no compile log exists.
   
   - `templates/main.tex`  Missing `\input{chapters/appendices}`.
   
   **Part III Agent Findings (partial  agents still running):**
   
   - Agent a990a75 (completed): Mapped 49 API routes. Found 11+ unwired/dead routes:
     - `/api/projects/[id]/sections/[phase]/review`  POST exists but no frontend caller
     - `/api/projects/[id]/compilations`  GET compilation history never displayed
     - `/api/projects/[id]/qc`  POST QC check not triggered from workspace UI
     - `/api/projects/[id]/qc/fix`  POST quality fixes UI missing
     - `/api/projects/[id]/export/pdf`, `/docx`, `/source`, `/stats`  Export menu component EXISTS but not rendered in workspace
     - `/api/licenses`  GET not found in checkout flow
     - `/api/licenses/[lid]/transfer`  Licence transfer UI missing
     - `/api/projects/[id]/datasets/[datasetId]/download`  Download button not found
   
   - `apps/web/hooks/use-sse.ts`  SSE streaming hook. Well-implemented with fetch-based reader, delta/complete/error handling, AbortController support.
   
   - `apps/web/components/project/export-menu.tsx`  Export menu component EXISTS and calls all 4 export routes, but is not rendered in the workspace (only in thesis-completion.tsx).
   
   - `apps/web/components/project/share-dialog.tsx`  Share functionality implemented, calls POST `/api/projects/{id}/share`.
   
   - `apps/web/components/project/licence-banner.tsx`  Licence required banner with link to checkout.
   
   - `apps/web/components/editor/word-count-bar.tsx`  Word count progress bar using word-count-targets.ts.
   
   - `apps/web/components/onboarding/tour-overlay.tsx`  Onboarding tour with 4 steps, localStorage persistence.
   
   - `apps/web/components/project/template-gallery.tsx`  6 study templates (RCT, cohort, cross-sectional, case-control, case-report, systematic-review) + 2 university templates.
   
   - `apps/web/components/licences/attach-dialog.tsx`  Licence attachment to sandbox projects, calls POST `/api/licenses/{lid}/attach/{pid}`.
   
   - `apps/web/components/project/whatsapp-share-button.tsx`  WhatsApp share link generator.

4. Errors and fixes:
   - No code errors encountered in this session  this was purely a research/audit session
   - No code changes were made
   - Agent a990a75 completed successfully with comprehensive API route mapping
   - Agents a230c7b, a0d4277, a2ae992 were still running at session end

5. Problem Solving:
   - Successfully synthesized Part II report from 5 completed deep-dive agents covering AI prompts, citations, LaTeX pipeline, R analysis, and phase transitions
   - Identified 47 total issues (12 P0, 18 P1, 17 P2) across all pipelines
   - Answered user's question about Modified Option C for LaTeX round-trip  endorsed CodeMirror 6 approach as optimal
   - Launched Part III frontend-backend audit with 4 parallel agents
   - 1 of 4 Part III agents completed (API routes mapping), 3 still running

6. All user messages:
   - **Message 1** (continuation): System provided summary of previous session context. No explicit user message  continuation prompt said "Please continue the conversation from where we left off without asking the user any further questions. Continue with the last task that you were asked to work on."
   - **Message 2-6**: Multiple `<task-notification>` messages for agents a8dc46a, a3d46a3, a5afa5e, a54e776, a77af11 completing. No user text  just system notifications. I responded that these were already incorporated.
   - **Message 7**: User's actual request: "Now do a 3rd pass to check frontend code, frontend backend linkage, unwired stuff, anything missing as per previous PLAN, any suggestions from your end? This pass is purely for frontend backend linkage and wiring. Create part III of the review report. [one question from part II... what is the optimum solution to the latex round trip problem? can we do a Modified option C? ie Latex is canonical, and shown to user, no need for rich text, but the latex syntax, codes etc are in a diff font or color which remains uneditable to the user?]"
   - **Message 8**: System progress notifications for all 4 Part III agents running. No user text.
   - **Message 9**: Task notification for agent a990a75 (API routes audit) completing. No user text.
   - **Message 10**: System progress notifications + more agent progress. No user text.

7. Pending Tasks:
   - **Part III Report Synthesis**: 3 of 4 agents still running (a230c7b: frontend components audit, a0d4277: PLAN.md requirements check, a2ae992: workspace wiring audit). Need to wait for completion, then synthesize Part III report.
   - **Fix P0 items**: User has been offered but not yet approved fixing. The suggested order was: (1) Inline math preservation, (2) Inngest content overwrite, (3) Phase 11 QC enforcement + UI button, (4) Token budget enforcement, (5) Orphan cite key fix, (6) Template fixes.
   - **Modified Option C Implementation**: User endorsed approach but hasn't explicitly asked to implement yet.

8. Current Work:
   I am waiting for 3 remaining Part III agents to complete:
   - Agent a230c7b: Auditing ALL frontend components  inventory of every component, imports, API calls, TODOs, dynamic imports, state management, empty handlers
   - Agent a0d4277: Checking PLAN.md frontend requirements against implementation  every UI screen, component, feature mentioned in the plan
   - Agent a2ae992: Deep audit of project-workspace.tsx and all child components  editor wiring, tab wiring, dialog wiring, phase 11 QC UI, mobile responsiveness
   
   Agent a990a75 has completed with the API routes inventory (49 routes mapped, 11+ unwired routes identified).
   
   Once all agents complete, I will synthesize the Part III report covering frontend-backend linkage gaps, unwired routes, missing UI per PLAN, and the Modified Option C architectural specification.

9. Optional Next Step:
   Wait for agents a230c7b, a0d4277, and a2ae992 to complete, then synthesize the Part III report as requested by the user: "Create part III of the review report" focused on "frontend backend linkage and wiring." The report should include the Modified Option C architectural specification for the LaTeX editor, the unwired API routes inventory, missing UI features per PLAN.md, and workspace wiring issues.

If you need specific details from before compaction (like exact code snippets, error messages, or content you generated), read the full transcript at: /Users/devs/.REDACTED.jsonl
Please continue the conversation from where we left off without asking the user any further questions. Continue with the last task that you were asked to work on.

---

<task-notification>
<task-id>a0d4277</task-id>
<status>completed</status>
<summary>Agent "Audit PLAN.md frontend requirements" completed</summary>
<result>Perfect. Now I have enough information to create a comprehensive report. Let me compile the findings:

## COMPREHENSIVE UI REQUIREMENT VERIFICATION REPORT

Based on a thorough read of `/Users/devs/Downloads/Apollo/docs/PLAN.md` and analysis of the codebase, here is the complete status of frontend/UI implementation:

---

## SECTION 1: CORE UI SCREENS & PAGES

### 1.1 Landing Page  IMPLEMENTED
**Plan requirement**: Landing page with hero, sponsors, features, pricing, testimonials, FAQ, CTA sections
**Status**: COMPLETE
**Files**:
- `/Users/devs/Downloads/Apollo/apps/web/app/page.tsx`  Root landing page
- `/Users/devs/Downloads/Apollo/apps/web/components/landing/hero-section.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/landing/sponsors-section.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/landing/features-section.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/landing/how-it-works-section.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/landing/pricing-section.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/landing/testimonials-section.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/landing/faq-section.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/landing/cta-section.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/landing/footer-section.tsx`

### 1.2 Authentication Pages  IMPLEMENTED
**Plan requirement**: Sign-in, sign-up pages
**Status**: COMPLETE
**Files**:
- `/Users/devs/Downloads/Apollo/apps/web/app/(auth)/sign-in/[[...sign-in]]/page.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/app/(auth)/sign-up/[[...sign-up]]/page.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/app/(auth)/layout.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/auth/auth-3d-scene-loader.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/auth/auth-3d-scene.tsx`

### 1.3 Dashboard  IMPLEMENTED
**Plan requirement**: User dashboard with project count, licence count, recent projects
**Status**: COMPLETE
**Files**:
- `/Users/devs/Downloads/Apollo/apps/web/app/(dashboard)/dashboard/page.tsx`  Main dashboard with stats and recent projects

### 1.4 Projects List Page  IMPLEMENTED
**Plan requirement**: View all projects with filtering/sorting
**Status**: COMPLETE
**Files**:
- `/Users/devs/Downloads/Apollo/apps/web/app/(dashboard)/projects/page.tsx`  Projects list with ProjectCard components
- `/Users/devs/Downloads/Apollo/apps/web/app/(dashboard)/projects/project-card.tsx`  Individual project card

### 1.5 Project Detail Page  IMPLEMENTED
**Plan requirement**: View project metadata, current phase, status
**Status**: COMPLETE
**Files**:
- `/Users/devs/Downloads/Apollo/apps/web/app/(dashboard)/projects/[id]/page.tsx`  Project detail page with metadata panel

### 1.6 Project Workspace (Editor)  IMPLEMENTED
**Plan requirement**: Multi-panel editor with phase selection, section editing, PDF preview
**Status**: COMPLETE
**Files**:
- `/Users/devs/Downloads/Apollo/apps/web/app/(dashboard)/projects/[id]/project-workspace.tsx`  Main workspace with resizable panels for editor, PDF viewer, data, compliance

### 1.7 Checkout/Payment Page  IMPLEMENTED
**Plan requirement**: Payment plans display (Student Monthly, Professional Monthly, One-Time)
**Status**: COMPLETE
**Files**:
- `/Users/devs/Downloads/Apollo/apps/web/app/(dashboard)/checkout/page.tsx`  Checkout with plan cards, Razorpay/Stripe integration, currency toggle

### 1.8 Licences Management Page  IMPLEMENTED
**Plan requirement**: View purchased licences, status, attachments
**Status**: COMPLETE
**Files**:
- `/Users/devs/Downloads/Apollo/apps/web/app/(dashboard)/licences/page.tsx`  Licences list with status badges

### 1.9 Supervisor Review Page  IMPLEMENTED
**Plan requirement**: Read-only review interface for supervisors without accounts
**Status**: COMPLETE
**Files**:
- `/Users/devs/Downloads/Apollo/apps/web/app/review/[token]/page.tsx`  Anonymous review page with PDF viewer and comment form

### 1.10 New Project Wizard  IMPLEMENTED
**Plan requirement**: 5-step setup wizard
**Status**: COMPLETE
**Files**:
- `/Users/devs/Downloads/Apollo/apps/web/app/(dashboard)/projects/new/page.tsx`  Entry point for new project
- `/Users/devs/Downloads/Apollo/apps/web/app/(dashboard)/projects/[id]/setup/page.tsx`  Setup wizard page

---

## SECTION 2: SETUP WIZARD (5-Step)  IMPLEMENTED

**Plan requirement**: University  Synopsis Upload  AI Parsing Review  Metadata Form  Title Page Preview

**Status**: COMPLETE

**Files**:
- `/Users/devs/Downloads/Apollo/apps/web/components/wizard/setup-wizard.tsx`  Wizard orchestrator with step navigation
- `/Users/devs/Downloads/Apollo/apps/web/components/wizard/steps/university-step.tsx`  Step 1: Select WBUHS/SSUHS/Generic
- `/Users/devs/Downloads/Apollo/apps/web/components/wizard/steps/synopsis-upload-step.tsx`  Step 2: Upload PDF/text synopsis
- `/Users/devs/Downloads/Apollo/apps/web/components/wizard/steps/parsed-data-review-step.tsx`  Step 3: Review AI-parsed PICO, study design, methods
- `/Users/devs/Downloads/Apollo/apps/web/components/wizard/steps/metadata-form-step.tsx`  Step 4: Fill candidate name, guide, HOD, registration
- `/Users/devs/Downloads/Apollo/apps/web/components/wizard/steps/title-page-preview-step.tsx`  Step 5: Title page PDF preview

---

## SECTION 3: EDITOR FEATURES

### 3.1 Rich Text Editor (Novel)  IMPLEMENTED
**Plan requirement**: Form-based section editor with Novel editor; Add Citation, Add Table, Add Figure buttons; inline formatting
**Status**: COMPLETE
**Files**:
- `/Users/devs/Downloads/Apollo/apps/web/components/editor/section-editor.tsx`  Novel-based editor with formatting toolbar, citation search integration

### 3.2 LaTeX Source View  IMPLEMENTED
**Plan requirement**: CodeMirror LaTeX editor for advanced users (optional toggle)
**Status**: COMPLETE
**Files**:
- `/Users/devs/Downloads/Apollo/apps/web/components/editor/latex-source-view.tsx`  CodeMirror with LaTeX syntax highlighting

### 3.3 Word Count Tracking  IMPLEMENTED
**Plan requirement**: Real-time word count per chapter with target ranges
**Status**: COMPLETE
**Files**:
- `/Users/devs/Downloads/Apollo/apps/web/components/editor/word-count-bar.tsx`  Word count display bar

### 3.4 Phase Stepper  IMPLEMENTED
**Plan requirement**: 12-phase stepper showing progress and quality gate status
**Status**: COMPLETE
**Files**:
- `/Users/devs/Downloads/Apollo/apps/web/components/project/phase-stepper.tsx`  Phase navigation stepper

### 3.5 Live PDF Preview  IMPLEMENTED
**Plan requirement**: react-pdf split-pane viewer with zoom, page navigation
**Status**: COMPLETE
**Files**:
- `/Users/devs/Downloads/Apollo/apps/web/components/viewer/pdf-viewer.tsx`  PDF viewer with page controls, zoom, pan, sidebar toggle

### 3.6 Section Viewer (Read-Only)  IMPLEMENTED
**Plan requirement**: View compiled sections as rich text (for supervisors)
**Status**: COMPLETE
**Files**:
- `/Users/devs/Downloads/Apollo/apps/web/components/project/section-viewer.tsx`  Read-only section display

---

## SECTION 4: AI GENERATION

### 4.1 AI Generate Button  IMPLEMENTED
**Plan requirement**: "Generate Draft" per phase with streaming via SSE
**Status**: COMPLETE
**Files**:
- `/Users/devs/Downloads/Apollo/apps/web/components/project/ai-generate-button.tsx`  Generation trigger with SSE streaming, models dropdown

### 4.2 Review & Refine Dialog  IMPLEMENTED
**Plan requirement**: Review generated content; "Regenerate", "Expand", "Condense", "Add Citations" actions
**Status**: COMPLETE
**Files**:
- `/Users/devs/Downloads/Apollo/apps/web/components/project/review-dialog.tsx`  Review dialog with action buttons

---

## SECTION 5: CITATION MANAGEMENT

### 5.1 Citation Search Dialog  IMPLEMENTED
**Plan requirement**: PubMed/CrossRef search UI; insert directly with auto Tier A
**Status**: COMPLETE
**Files**:
- `/Users/devs/Downloads/Apollo/apps/web/components/project/citation-search-dialog.tsx`  Citation search with provider integration

### 5.2 Citation List Panel  IMPLEMENTED
**Plan requirement**: View all citations with provenance tier badges (A/B/C/D); bidirectional integrity check; "Add Citation" button
**Status**: COMPLETE
**Files**:
- `/Users/devs/Downloads/Apollo/apps/web/components/project/citation-list-panel.tsx`  Citation list with tier classification badges, add/edit/delete actions

### 5.3 Provenance Tier Badges  IMPLEMENTED
**Plan requirement**: Green (A), amber (B/C), red (D) badges in editor
**Status**: COMPLETE
**Implementation**: Tier badge colors embedded in citation-list-panel.tsx and inline within editor

---

## SECTION 6: STATISTICAL ANALYSIS

### 6.1 Dataset Upload  IMPLEMENTED
**Plan requirement**: CSV/Excel upload with column type auto-detection
**Status**: COMPLETE
**Files**:
- `/Users/devs/Downloads/Apollo/apps/web/components/project/dataset-upload.tsx`  File uploader with CSV/XLSX support

### 6.2 Analysis Wizard  IMPLEMENTED
**Plan requirement**: Select variables, test type, significance level; full analysis set (descriptive, chi-square, t-test, correlation, survival, ROC, logistic, Kruskal-Wallis, meta-analysis)
**Status**: COMPLETE
**Files**:
- `/Users/devs/Downloads/Apollo/apps/web/components/project/analysis-wizard.tsx`  Multi-step wizard: dataset selection  method choice  auto-recommendations  column mapping  execution

### 6.3 Figure Gallery  IMPLEMENTED
**Plan requirement**: View generated figures (ggplot2, Mermaid, TikZ, manual upload)
**Status**: COMPLETE
**Files**:
- `/Users/devs/Downloads/Apollo/apps/web/components/project/figure-gallery.tsx`  Figure display with delete/preview

### 6.4 Mermaid Editor  IMPLEMENTED
**Plan requirement**: CONSORT flowchart generation from Mermaid syntax
**Status**: COMPLETE
**Files**:
- `/Users/devs/Downloads/Apollo/apps/web/components/project/mermaid-editor.tsx`  Mermaid diagram editor with preview

---

## SECTION 7: COMPLIANCE DASHBOARDS

### 7.1 Reporting Guideline Checklist  IMPLEMENTED
**Plan requirement**: CONSORT, STROBE, PRISMA, STARD, CARE checklists with green/yellow/red status; section mapping
**Status**: COMPLETE
**Files**:
- `/Users/devs/Downloads/Apollo/apps/web/components/project/compliance-dashboard.tsx`  Guideline selector with item-by-item checklist, NBEMS compliance checks

### 7.2 NBEMS Compliance  IMPLEMENTED
**Plan requirement**: 80-page limit (Introduction to Conclusion), 300-word abstract, PICO elements verification
**Status**: COMPLETE
**Implementation**: Embedded in compliance-dashboard.tsx with page count and abstract length validation

---

## SECTION 8: EXPORT & DOWNLOADS

### 8.1 Export Menu  IMPLEMENTED
**Plan requirement**: PDF, DOCX, source files (.tex, .bib, .cls, figures), R scripts + dataset
**Status**: COMPLETE
**Files**:
- `/Users/devs/Downloads/Apollo/apps/web/components/project/export-menu.tsx`  Export dropdown with all 4 export types, license gate, loading states

### 8.2 Compilation Button  IMPLEMENTED
**Plan requirement**: One-click compile; error/warning parser; success/failure UI
**Status**: COMPLETE
**Files**:
- `/Users/devs/Downloads/Apollo/apps/web/components/project/compile-button.tsx`  Compile trigger with status feedback, watermark for sandbox

---

## SECTION 9: ABBREVIATION MANAGEMENT

### 9.1 Abbreviations UI  IMPLEMENTED
**Plan requirement**: Add, edit, delete abbreviations; auto-generates LaTeX longtable
**Status**: COMPLETE
**Files**:
- `/Users/devs/Downloads/Apollo/apps/web/components/project/abbreviation-manager.tsx`  Abbreviation CRUD interface

---

## SECTION 10: SUPERVISOR COLLABORATION (MVP)

### 10.1 Supervisor Share Dialog  IMPLEMENTED
**Plan requirement**: Generate read-only share link; requires Professional Monthly/One-Time/Institutional license
**Status**: COMPLETE
**Files**:
- `/Users/devs/Downloads/Apollo/apps/web/components/project/share-dialog.tsx`  Link generation with copy-to-clipboard

### 10.2 Supervisor Review Page  IMPLEMENTED
**Plan requirement**: Read-only dashboard, PDF preview, phase-scoped comments
**Status**: COMPLETE
**Files**:
- `/Users/devs/Downloads/Apollo/apps/web/app/review/[token]/page.tsx`  Anonymous supervisor review interface
- `/Users/devs/Downloads/Apollo/apps/web/components/project/review-comments.tsx`  Comment form and display

### 10.3 Phase Approval  IMPLEMENTED
**Plan requirement**: Supervisor click "Approve" to advance phase (for professional licenses)
**Status**: COMPLETE
**API**: `/api/projects/[id]/sections/[phase]/approve`  Checks license tier before allowing approval

---

## SECTION 11: LICENSE & PAYMENT SYSTEM

### 11.1 License Attachment Dialog  IMPLEMENTED
**Plan requirement**: Attach license to project (binds identity)
**Status**: COMPLETE
**Files**:
- `/Users/devs/Downloads/Apollo/apps/web/components/licences/attach-dialog.tsx`  License picker and attachment flow

### 11.2 License Banner  IMPLEMENTED
**Plan requirement**: Show license status in project workspace
**Status**: COMPLETE
**Files**:
- `/Users/devs/Downloads/Apollo/apps/web/components/project/licence-banner.tsx`  License status indicator with upgrade prompt

### 11.3 Payment Integration  IMPLEMENTED
**Plan requirement**: Razorpay (INR) + Stripe (USD) integration
**Status**: COMPLETE
**Files**:
- `/Users/devs/Downloads/Apollo/apps/web/app/(dashboard)/checkout/page.tsx`  Checkout page with Razorpay modal + Stripe redirect
- `/Users/devs/Downloads/Apollo/apps/web/app/api/checkout/route.ts`  Checkout initiation
- `/Users/devs/Downloads/Apollo/apps/web/app/api/webhooks/razorpay/route.ts`  Razorpay webhook handler
- `/Users/devs/Downloads/Apollo/apps/web/app/api/webhooks/stripe/route.ts`  Stripe webhook handler

---

## SECTION 12: DASHBOARD & PROGRESS TRACKING

### 12.1 Progress Dashboard  IMPLEMENTED
**Plan requirement**: 12-phase progress stepper; word counts; quality gate status
**Status**: COMPLETE
**Files**:
- `/Users/devs/Downloads/Apollo/apps/web/components/project/progress-dashboard.tsx`  Detailed progress view with phase metrics
- `/Users/devs/Downloads/Apollo/apps/web/components/project/pipeline-timeline.tsx`  Visual phase timeline

### 12.2 Template Gallery  IMPLEMENTED
**Plan requirement**: 6 study type templates
**Status**: COMPLETE
**Files**:
- `/Users/devs/Downloads/Apollo/apps/web/components/project/template-gallery.tsx`  Template selector for new projects

---

## SECTION 13: MOBILE & PWA

### 13.1 PWA Manifest  IMPLEMENTED
**Plan requirement**: PWA manifest with manifest.json, service worker, add-to-home-screen
**Status**: COMPLETE
**Files**:
- `/Users/devs/Downloads/Apollo/apps/web/public/manifest.json`  PWA manifest with icons, colors, display mode
- PWA Provider component (service worker registration)

### 13.2 Responsive Layout  IMPLEMENTED
**Plan requirement**: Mobile-optimised dashboard, editor, PDF preview with bottom nav
**Status**: COMPLETE
**Implementation**: Tailwind responsive classes throughout; glass sidebar collapses on mobile

---

## SECTION 14: ADDITIONAL UI FEATURES

### 14.1 WhatsApp Share Button  IMPLEMENTED
**Plan requirement**: Share thesis PDF via WhatsApp
**Status**: COMPLETE
**Files**:
- `/Users/devs/Downloads/Apollo/apps/web/components/project/whatsapp-share-button.tsx`  WhatsApp share integration

### 14.2 Thesis Completion Modal  IMPLEMENTED
**Plan requirement**: Confirmation/celebration UI when thesis completed
**Status**: COMPLETE
**Files**:
- `/Users/devs/Downloads/Apollo/apps/web/components/project/thesis-completion.tsx`  Completion celebration UI

### 14.3 Delete Project Button  IMPLEMENTED
**Plan requirement**: Soft-delete with confirmation
**Status**: COMPLETE
**Files**:
- `/Users/devs/Downloads/Apollo/apps/web/components/project/delete-project-button.tsx`  Delete confirmation dialog

---

## SECTION 15: API ENDPOINTS

All 49 planned API endpoints exist:

**Project Management**: 
- `POST /api/projects`
- `GET /api/projects`
- `GET /api/projects/:id`
- `PATCH /api/projects/:id`

**Sections**: 
- `GET /api/projects/:id/sections`
- `GET /api/projects/:id/sections/:phase`
- `PUT /api/projects/:id/sections/:phase`
- `POST /api/projects/:id/sections/:phase/generate` (SSE streaming)
- `POST /api/projects/:id/sections/:phase/approve`
- `POST /api/projects/:id/sections/:phase/review`
- `POST /api/projects/:id/sections/:phase/refine`

**Licenses**: 
- `GET /api/licenses`
- `POST /api/licenses/:lid/attach/:pid`
- `POST /api/licenses/:lid/transfer`

**Compilation**: 
- `POST /api/projects/:id/compile`
- `GET /api/projects/:id/compilations`
- `GET /api/projects/:id/preview.pdf`

**Citations**: 
- `GET /api/projects/:id/citations`
- `POST /api/projects/:id/citations`
- `POST /api/projects/:id/citations/:citationId`
- `POST /api/projects/:id/citations/:citationId/re-resolve`
- `POST /api/projects/:id/citations/audit`
- `GET /api/citations/search`

**Datasets & Analysis**: 
- `POST /api/projects/:id/datasets`
- `GET /api/projects/:id/datasets`
- `POST /api/projects/:id/datasets/:datasetId`
- `GET /api/projects/:id/datasets/:datasetId/download`
- `POST /api/projects/:id/analyses`
- `GET /api/projects/:id/analyses/:analysisId`
- `POST /api/projects/:id/analyses/auto-detect`
- `POST /api/projects/:id/datasets/generate`

**Figures**: 
- `POST /api/projects/:id/figures`
- `GET /api/projects/:id/figures`
- `DELETE /api/projects/:id/figures/:figureId`
- `POST /api/projects/:id/figures/mermaid`

**Compliance**: 
- `GET /api/projects/:id/compliance`
- `POST /api/projects/:id/compliance`

**Export**: 
- `GET /api/projects/:id/export/pdf`
- `GET /api/projects/:id/export/docx`
- `GET /api/projects/:id/export/source`
- `GET /api/projects/:id/export/stats`

**Supervisor Sharing**: 
- `POST /api/projects/:id/share`
- `GET /api/review/:token`
- `POST /api/review/:token/comments`

**Abbreviations**: 
- `GET /api/projects/:id/abbreviations`
- `POST /api/projects/:id/abbreviations`
- `DELETE /api/projects/:id/abbreviations/:abbrevId`

**Payment**: 
- `POST /api/checkout`
- `POST /api/webhooks/razorpay`
- `POST /api/webhooks/stripe`

**QC**: 
- `GET /api/projects/:id/qc`
- `POST /api/projects/:id/qc/fix`

---

## SECTION 16: DESIGN PATTERNS & STYLING

### 16.1 Design System  IMPLEMENTED
**Plan requirement**: Tailwind CSS + shadcn/ui; responsive PWA; mobile-first
**Status**: COMPLETE
- Tailwind CSS configuration
- shadcn/ui components (Button, Dialog, Sidebar, etc.)
- Custom CSS for landing-dot-grid, landing-card, landing-card-elevated

### 16.2 Glass Sidebar  IMPLEMENTED
**Plan requirement**: Frosted glass floating sidebar; collapses on mobile
**Status**: COMPLETE
**Files**:
- `/Users/devs/Downloads/Apollo/apps/web/components/layout/glass-sidebar.tsx`
- `/Users/devs/Downloads/Apollo/apps/web/components/layout/glass-sidebar-provider.tsx`

### 16.3 Dashboard Header  IMPLEMENTED
**Status**: COMPLETE
**Files**:
- `/Users/devs/Downloads/Apollo/apps/web/components/layout/dashboard-header.tsx`

---

## IMPLEMENTATION COMPLETENESS SUMMARY

| Feature Category | Status | % Complete |
|---|---|---|
| **Landing Page** |  Complete | 100% |
| **Auth Pages** |  Complete | 100% |
| **Dashboard** |  Complete | 100% |
| **Setup Wizard (5-step)** |  Complete | 100% |
| **Project Editor** |  Complete | 100% |
| **Rich Text Editor (Novel)** |  Complete | 100% |
| **LaTeX Source View** |  Complete | 100% |
| **PDF Viewer** |  Complete | 100% |
| **AI Generation (SSE)** |  Complete | 100% |
| **Citation Management** |  Complete | 100% |
| **Statistical Analysis** |  Complete | 100% |
| **Compliance Dashboards** |  Complete | 100% |
| **Figure Gallery** |  Complete | 100% |
| **Abbreviation Manager** |  Complete | 100% |
| **Export Menu** |  Complete | 100% |
| **Compilation UI** |  Complete | 100% |
| **Supervisor Collaboration** |  Complete | 100% |
| **License Management** |  Complete | 100% |
| **Payment System** |  Complete | 100% |
| **Progress Dashboard** |  Complete | 100% |
| **Template Gallery** |  Complete | 100% |
| **PWA/Mobile** |  Complete | 100% |
| **WhatsApp Share** |  Complete | 100% |
| **Notification System** |  Minimal | 50% |
| **Settings/Profile Pages** |  Not Found | 0% |

---

## CRITICAL GAPS & MISSING FEATURES

### 1. **User Settings/Profile Pages**  NOT FOUND
**Plan mentions**: User profile, preference management
**Status**: No dedicated settings page found
**Files that might address this**: None found
**Impact**: Minor  functionality can be added later without breaking core flow

### 2. **Notification System**  MINIMAL
**Plan mentions**: Email notifications for phase approvals, payment confirmation
**Implementation found**: Only `sonner` toast notifications in frontend; no persistent notification UI
**Missing**: 
- Notification bell/center in header
- Web Push API integration (mentioned in PWA section but not implemented)
- Email notification preferences UI
**Impact**: Medium  core features work; notifications are present but not persistent

### 3. **Error Display & Handling**  PARTIAL
**Plan mentions**: Standard error response schema
**Status**: API error schema implemented (`code`, `message`, `action`, `details`); frontend uses sonner toasts
**Missing**: Comprehensive error page/panel for API errors
**Impact**: Low  sonner toasts are adequate for MVP

### 4. **Loading States & Skeletons**  IMPLEMENTED
**Status**: Skeletons found in project-workspace.tsx, checkout page Suspense boundaries
**Impact**: Good UX

### 5. **Onboarding Tour Overlay**  STUB FOUND
**Files**: `/Users/devs/Downloads/Apollo/apps/web/components/onboarding/tour-overlay.tsx`
**Status**: File exists but likely not integrated into main flow
**Impact**: Low priority

---

## FEATURE COMPLETENESS ASSESSMENT BY SPRINT

**Sprint 0** (Governance, Rules, CI) 
- Governance docs framework exists

**Sprint 1-2** (Foundation + Setup Wizard + Licenses) 
- Setup wizard fully implemented
- License system fully implemented
- Auth fully implemented

**Sprint 3-4** (Compute Services + Editor) 
- Rich text editor fully implemented
- LaTeX source view fully implemented
- Phase navigation fully implemented
- PDF preview fully implemented

**Sprint 5-6** (AI Integration + Citations) 
- AI generation with SSE fully implemented
- Citation provenance pipeline fully implemented
- Citation search fully implemented

**Sprint 7** (Dashboard + Compliance + Analysis) 
- Compliance dashboards fully implemented
- Analysis wizard fully implemented
- Progress dashboard fully implemented

**Sprint 8** (Advanced Analysis + Observability) 
- All analysis types supported in wizard UI
- Sentry integration configured

**Sprint 9-10** (Export + Payments + Collaboration + Launch) 
- Export menu fully implemented
- Payment system fully implemented
- Supervisor collaboration fully implemented
- Landing page fully implemented

---

## RESPONSIVE DESIGN & MOBILE CONSIDERATIONS

**Checked**: 
- Responsive Tailwind classes throughout
- Mobile-friendly navigation
- Resizable panels in workspace (using react-resizable-panels)
- PWA manifest configured
- Service worker provider configured
- Bottom nav bar patterns ready for PWA optimization
- Glass sidebar collapses on mobile

**Status**: COMPLETE

---

## FINAL VERDICT

**Overall Implementation Status: 95%+ COMPLETE**

All **23 major UI feature categories** from the PLAN are implemented. All **49 API endpoints** exist. The only notable gaps are:
1. User Settings/Profile page (not in PLAN as critical)
2. Persistent notification center (sonner toasts are functional substitute)
3. Onboarding tour (stub component exists, not integrated)

The frontend is **production-ready** and aligns with the PLAN specification. The implementation is thorough, well-organised, and follows the stated design patterns (Tailwind + shadcn/ui, responsive, mobile-first PWA).</result>
<usage>total_tokens: 77129
tool_uses: 36
duration_ms: 88850</usage>
</task-notification>
Full transcript available at: /private/tmp/claude-501/-Users-devs-Downloads-Apollo/tasks/a0d4277.output

---

<task-notification>
<task-id>a2ae992</task-id>
<status>completed</status>
<summary>Agent "Audit workspace component wiring" completed</summary>
<result>Now let me generate the comprehensive audit report:

## COMPREHENSIVE PROJECT WORKSPACE AUDIT

I have completed an exhaustive audit of the Apollo project workspace component and all its child components. Here are my findings:

---

## 1. PROJECT WORKSPACE STATE & HANDLERS

### State Variables (All Present & Wired Correctly)
- **`viewingPhase`**  Currently viewed phase (initialized from `project.current_phase`)
- **`editorMode`**  Toggle between "richtext" and "source" (auto-selects richtext when JSON available)
- **`mobileTab`**  Mobile editor/preview tab toggle
- **`pdfUrl`**  Current PDF preview URL (refreshed on compile)
- **`pdfKey`**  React key for force-reloading PDF viewer
- **`reviewIssues`**  Issues from section review check
- **`reviewDialogOpen`**  Show/hide review dialog
- **`citationSearchOpen`**  Show/hide citation search dialog
- **`workspaceTab`**  Workspace tab selection (editor, data, compliance, figures, progress)
- **`mermaidEditorOpen`**  Show/hide mermaid diagram editor
- **`isApproving`**  Approval button state
- **`refineDialogOpen`**  Show/hide refine dialog
- **`refineInstructions`**  Refine prompt textarea value
- **`isRefining`**  Refine submission state

**Status**: All state variables properly initialized, dependencies correctly specified in `useEffect` and `useCallback` hooks.

---

## 2. CHILD COMPONENTS AUDIT

### 2.1 Editor Components

#### **SectionEditor** (Tiptap/Novel Rich Text Editor)
- **Location**: `/Users/devs/Downloads/Apollo/apps/web/components/editor/section-editor.tsx`
- **Props received**:
  - `projectId`  Used in save fetch
  - `phaseNumber`  Used in save fetch
  - `initialContent`  Properly converted to Tiptap JSON
  - `onSaveSuccess`  Called after successful save
- **Callbacks wired**: 
  - `handleUpdate()`  tracks `contentRef` + schedules auto-save (30s debounce)
  - `saveContent()`  PUT `/api/projects/{id}/sections/{phase}` with `rich_content_json`
  - Citation insert via `CitationSearchDialog`  appends `\cite{key}` as code-marked text
- **Auto-save**: Yes, 30-second debounce, cleaned up on unmount
- **Issues found**: None

#### **LaTeXSourceView** (CodeMirror)
- **Location**: `/Users/devs/Downloads/Apollo/apps/web/components/editor/latex-source-view.tsx`
- **Props received**:
  - `projectId`  Used in save fetch
  - `phaseNumber`  Used in save fetch
  - `initialContent`  Passed to CodeMirror
  - `onSaveSuccess`  Called after save
- **Callbacks wired**: 
  - `handleChange()`  updates `contentRef` + sets `isDirty`
  - `saveContent()`  PUT `/api/projects/{id}/sections/{phase}` with `latex_content`
- **Issues found**: No auto-save (manual save only  acceptable for source editing)

#### **SectionViewer** (Read-only View)
- **Location**: `/Users/devs/Downloads/Apollo/apps/web/components/project/section-viewer.tsx`
- **Functionality**:
  - Renders null content state
  - Phase 0 special case: tries to parse `latex_content` as JSON for synopsis data
  - Fallback: renders LaTeX as preformatted text
- **Issues found**: None  handles all edge cases

#### **PdfViewer** (react-pdf)
- **Location**: `/Users/devs/Downloads/Apollo/apps/web/components/viewer/pdf-viewer.tsx`
- **Props received**:
  - `url`  Used as PDF source
  - `isSandbox`  Renders watermark
  - `projectId`  Used for download URL
- **Features wired correctly**:
  - Page navigation 
  - Zoom controls 
  - Thumbnail sidebar toggle 
  - Download button 
  - Sandbox watermark 
- **Refresh mechanism**: Via `pdfKey` + `pdfUrl` query param (timestamp)
- **Issues found**: None

---

### 2.2 Action Bar Components

#### **PipelineTimeline**
- **Location**: `/Users/devs/Downloads/Apollo/apps/web/components/project/pipeline-timeline.tsx`
- **Props received**:
  - `currentPhase` 
  - `phasesCompleted` 
  - `projectStatus` 
  - `devLicenceBypass` 
  - `onPhaseClick`  Properly wired (disabled when not accessible)
- **Behavior**:
  - Shows all 12 phases with compact labels (Orient., Front, Intro, etc.)
  - Current phase: large dot + ring + bold label
  - Completed: medium dot + sage colour
  - Future: small dot + grey
  - Locked (licence required): opacity 40%, cursor-not-allowed
  - Clicking only works on completed or current phase
- **Wiring**:  Correctly disables clicks on inaccessible phases

#### **AIGenerateButton**
- **Location**: `/Users/devs/Downloads/Apollo/apps/web/components/project/ai-generate-button.tsx`
- **Props received**:
  - `projectId` 
  - `phaseNumber` 
  - `disabled` 
  - `hasContent`  Controls Refine button visibility
  - `onComplete`  Called after generation finishes
  - `onRefine`  Wired to open refine dialog
- **Callbacks wired**:
  - `handleGenerate()`  POST `/api/projects/{id}/sections/{phase}/generate` (SSE stream)
  - Citation summary extracted from complete event
- **Issues found**: None

#### **CompileButton**
- **Location**: `/Users/devs/Downloads/Apollo/apps/web/components/project/compile-button.tsx`
- **Props received**:
  - `projectId` 
  - `disabled` 
  - `onCompileSuccess`  Called after successful compile
- **Callbacks wired**:
  - `handleCompile()`  POST `/api/projects/{id}/compile`
  - Queue position polling (5s intervals)
  - Status responses: 202/429 (queued), 200 (success), validation_failed, failed
- **Issues found**: None  comprehensive error handling

#### **CompileAndRefreshPdf**
- **Handler**: In workspace, called after AI generation and approval
- **Mechanism**: 
  - Fetches `/api/projects/{id}/compile`
  - Updates `pdfUrl` with timestamp query param
  - Increments `pdfKey` to force re-render
- **Wiring**:  Properly used in `handleGenerateComplete` and `handleSaveSuccess`

---

### 2.3 Dialog Components

#### **ReviewDialog**
- **Location**: `/Users/devs/Downloads/Apollo/apps/web/components/project/review-dialog.tsx`
- **Props received**:
  - `open` 
  - `issues`  (ReviewIssue[])
  - `onGoBack`  Wired
  - `onApproveAnyway`  Wired to `doApprove()`
- **Severity rendering**: Errors (red), Warnings (amber), Info (sage)
- **Wiring in workspace**:
  ```
  handleApprove()  POST /review  if issues  setReviewDialogOpen(true)
  onApproveAnyway  doApprove()
  ```
- **Issues found**: None

#### **CitationSearchDialog**
- **Location**: `/Users/devs/Downloads/Apollo/apps/web/components/project/citation-search-dialog.tsx`
- **Props received**:
  - `projectId` 
  - `open` 
  - `onOpenChange` 
  - `onInsert`  Called with cite_key after insertion
- **Callbacks wired**:
  - `doSearch()`  GET `/api/citations/search?q=...&source=pubmed|crossref`
  - `handleInsert()`  POST `/api/projects/{id}/citations` with DOI/PMID
- **Wiring in workspace**:  Opens/closes with button, inserted citations trigger router.refresh()
- **Issues found**: None

#### **RefineDialog**
- **Location**: Inline in workspace (lines 612-683)
- **Type**: Custom inline modal (not using AlertDialog primitive)
- **State**:
  - `refineDialogOpen`
  - `refineInstructions` textarea
  - `isRefining` button state
- **Callbacks wired**:
  - onClick "Refine"  POST `/api/projects/{id}/sections/{phase}/refine` with SSE
  - Consumes SSE stream to completion before refreshing
  - Calls `router.refresh()` + `compileAndRefreshPdf()`
- **Wiring**:  Properly wired to AIGenerateButton's `onRefine` callback
- **Issues found**: None

---

### 2.4 Workspace Tabs

#### **"editor" Tab** (Default)
Renders:
- **CitationListPanel**  (collapsible, auto-expands when Tier D exists)
- **Mobile tab toggle** (Edit/Preview)
- **Desktop panel layout** (resizable 50/50 split)
  - Left: `renderEditor()` output
  - Right: `PdfViewer`
- **Mobile layout** (tabbed)
  - Edit tab: `renderEditor()`
  - Preview tab: `PdfViewer`

**Citation List Panel wiring**:
- Props: `projectId`, `citations`, `onAddCitation`
- Callbacks wired:
  - `onAddCitation`  Opens citation search dialog
  - `handleRunAudit()`  POST `/api/projects/{id}/citations/audit`
  - `handleAttest()`  PUT `/api/projects/{id}/citations/{id}` with `attested: true`
  - `handleDelete()`  DELETE `/api/projects/{id}/citations/{id}`
  - `handleReResolve()`  POST `/api/projects/{id}/citations/{id}/re-resolve`
- Issues found: None

#### **"data" Tab**
Renders:
- **DatasetUpload** (file upload or AI generation)
- **AnalysisWizard** (3-step: select dataset  choose method  map columns)

**DatasetUpload wiring**:
- `handleFileUpload()`  POST `/api/projects/{id}/datasets` (multipart form data)
- `handleGenerate()`  POST `/api/projects/{id}/datasets/generate` with sample_size
- `handleDelete()`  DELETE `/api/projects/{id}/datasets/{id}`
- All properly refresh via `router.refresh()`
- Issues found: None

**AnalysisWizard wiring**:
- Step 1: Select dataset
- Step 1.5: Choose method (manual or auto-detect)
- Step 2a: Auto-recommendations  POST `/api/projects/{id}/analyses/auto-detect`
  - Batch selection with checkboxes
  - ELI15 explanations (collapsible)
  - Individual "Run This" or batch "Run Selected"
- Step 2b: Manual analysis type selection
- Step 3: Column mapping (outcome, predictor, group, time, event)
- Step 4: Running state + polling
- Polling: Every 3s, checks each analysis status
- Figure display: Shows generated figures with link to Figures tab
- Issues found: None

#### **"compliance" Tab**
Renders:
- **ComplianceDashboard** (CONSORT, STROBE, PRISMA, STARD, CARE)

**ComplianceDashboard wiring**:
- `handleRunCheck()`  POST `/api/projects/{id}/compliance` with guideline_type
- Displays overall score + checklist items
- NBEMS section for page count, abstract, PICO elements
- Issues found: None

#### **"figures" Tab**
Renders:
- **FigureGallery** (grouped by source: analysis vs uploaded)
- **MermaidEditor** dialog

**FigureGallery wiring**:
- `handleUpload()`  POST `/api/projects/{id}/figures` with file + metadata
- `handleDelete()`  DELETE `/api/projects/{id}/figures/{id}`
- Groups figures by source_tool (ggplot2 vs others)
- Lightbox preview for expanded view
- Issues found: None

**MermaidEditor wiring**:
- `handleSave()`  POST `/api/projects/{id}/figures/mermaid` with source_code + caption + label
- Live preview with debounce (500ms)
- Validation: label must match `fig:[lowercase-dashes]` format
- Issues found: None

#### **"progress" Tab**
Renders:
- **ProgressDashboard** (read-only overview)

**ProgressDashboard wiring**:
- No state mutations
- Displays word count progress per phase (minmax targets)
- Shows summary stats: total words, phases completed, citations, compliance score
- Issues found: None

#### **Phase 6 Special Handling**
- Lines 459-495: Results Checklist visible only at Phase 6
- Checks: dataset uploaded, analyses completed, results section generated
- Visual status indicators (checkmarks or empty circles)
- Issues found: None

---

## 3. EDITOR MODE SWITCHING

### How It Works

1. **Auto-selection on phase change** (useEffect line 162-168):
   ```
   if (richContentForEditor)  setEditorMode("richtext")
   else  setEditorMode("source")
   ```

2. **User toggle** (via buttons in action bar line 403-423):
   - Only shown when `hasViewableContent` is true
   - Clicking changes `editorMode`
   - `renderEditor()` re-renders with appropriate component

3. **renderEditor() Logic** (lines 247-328):
   - No section  `SectionViewer` with placeholder
   - Section but no content  `SectionViewer` with placeholder
   - Editable + richtext mode  `SectionEditor` (Novel)
   - Editable + source mode  `LaTeXSourceView` (CodeMirror)
   - Non-editable + source mode  Preformatted read-only LaTeX block
   - Non-editable + richtext mode  `SectionViewer` (read-only rendering)

**Issue found**: When in non-editable + source mode (lines 297-317), the toggle buttons are still visible if `hasViewableContent` is true. Clicking them will switch to richtext mode and show read-only viewer. This is acceptable but slightly confusing.

---

## 4. PDF REFRESH MECHANISM

### Workflow
1. After AI generation: `handleGenerateComplete()`  `compileAndRefreshPdf()`
2. After manual save: `handleSaveSuccess()`  `compileAndRefreshPdf()`
3. After approval: `doApprove()`  `compileAndRefreshPdf()`
4. After compile button success: `onCompileSuccess()` callback  `setPdfUrl()` + `setPdfKey()`

### Implementation
- Uses `pdfKey` (integer) to force component remount
- Uses timestamp query param `?t={Date.now()}` to bypass cache
- PdfViewer reset: `onDocumentLoadSuccess` sets page 1

**Issue found**: None  robust implementation

---

## 5. MOBILE RESPONSIVENESS

### Layout
- **Desktop** (md breakpoint): Resizable 50/50 panels with separator
- **Mobile**: Tabbed interface (Edit/Preview toggle)

**Wiring**:  Properly uses `mobileTab` state

**Issue found**: None

---

## 6. PHASE 11 (FINAL QC) HANDLING

### Current Implementation
- Phase 11 is in PHASES constant (requiresLicence: true)
- Workspace shows Phase 11 like any other phase
- Pipeline timeline includes it (3-tier dot hierarchy)
- **No special UI found for Phase 11 in workspace**

### Issues Found
1. **Missing: Final QC UI**  No dedicated component for Phase 11 QC workflow
2. **Missing: QC blocking logic**  Tier D citations should block Phase 11 approval
3. **Missing: Auto-completion**  No automatic transition from Phase 11 to completed status

**Recommendation**: Implement Phase 11 QC Dashboard that:
- Lists all Tier D citations (blocking)
- Runs final compliance check
- Shows final word count validation
- Allows approval to mark thesis as "completed"

---

## 7. DEAD CODE & UNREACHABLE BRANCHES

### Section Rendering
- **Lines 248-256**: Empty section case  reachable 
- **Lines 260-267**: No content case  reachable 
- **Lines 271-292**: Editable richtext case  reachable 
- **Lines 284-292**: Editable source case  reachable 
- **Lines 297-317**: Non-editable source case  reachable 
- **Lines 321-327**: Non-editable richtext case  reachable 

**Issue found**: None  all branches reachable

### Tab Content
- All 5 workspace tabs have conditional rendering
- All are reachable by clicking buttons
- Editor tab content inside `workspaceTab === "editor"` (line 545-609)

**Issue found**: None

---

## 8. CALLBACK WIRING VERIFICATION

### handleGenerateComplete
- Called by: `AIGenerateButton` via `onComplete` prop
- Actions:
  1. `router.refresh()`  Refreshes section data
  2. `compileAndRefreshPdf()`  Recompiles thesis
- Issues: None 

### handleSaveSuccess
- Called by: `SectionEditor` and `LaTeXSourceView` via `onSaveSuccess` prop
- Actions: Same as above
- Issues: None 

### handleApprove
- Triggered by: "Approve & Advance" button (line 379)
- Flow:
  1. POST `/sections/{phase}/review` to get issues
  2. If issues found  open ReviewDialog
  3. If no issues  call `doApprove()`
- Issues: None 

### doApprove
- Triggered by: `handleApprove()` or ReviewDialog's "Approve Anyway"
- Actions:
  1. POST `/sections/{phase}/approve`
  2. `router.refresh()`
  3. `compileAndRefreshPdf()`
- Handles: 409 conflict (already approved) gracefully
- Issues: None 

### compileAndRefreshPdf
- Silent failure on error (non-blocking)
- Properly updates PDF viewer
- Issues: None 

---

## 9. API ENDPOINTS STATUS

### Workspace References (Verified)
1.  `POST /api/projects/{id}/compile`  Compile button
2.  `POST /api/projects/{id}/sections/{phase}/generate`  AI Generate (SSE)
3.  `POST /api/projects/{id}/sections/{phase}/review`  Review check
4.  `POST /api/projects/{id}/sections/{phase}/approve`  Approve & advance
5.  `PUT /api/projects/{id}/sections/{phase}`  Save editor content
6.  `POST /api/projects/{id}/sections/{phase}/refine`  Refine section (SSE)
7.  `GET /api/projects/{id}/preview.pdf`  PDF preview/download
8.  `POST /api/projects/{id}/citations`  Add citation
9.  `PUT /api/projects/{id}/citations/{id}`  Attest citation
10.  `DELETE /api/projects/{id}/citations/{id}`  Delete citation
11.  `POST /api/projects/{id}/citations/{id}/re-resolve`  Re-resolve citation
12.  `POST /api/projects/{id}/citations/audit`  Citation audit
13.  `GET /api/citations/search`  Citation search (PubMed/CrossRef)
14.  `POST /api/projects/{id}/datasets`  Upload dataset
15.  `POST /api/projects/{id}/datasets/generate`  Generate dataset
16.  `DELETE /api/projects/{id}/datasets/{id}`  Delete dataset
17.  `GET /api/projects/{id}/datasets/{id}/download`  Download dataset
18.  `POST /api/projects/{id}/analyses`  Create analysis
19.  `GET /api/projects/{id}/analyses/{id}`  Poll analysis status
20.  `POST /api/projects/{id}/analyses/auto-detect`  Auto-detect recommendations
21.  `POST /api/projects/{id}/figures`  Upload figure
22.  `DELETE /api/projects/{id}/figures/{id}`  Delete figure
23.  `POST /api/projects/{id}/figures/mermaid`  Save Mermaid diagram
24.  `POST /api/projects/{id}/compliance`  Run compliance check
25.  `GET /api/projects/{id}/export/{type}`  Export (pdf, docx, source, stats)

**All referenced endpoints exist.** 

---

## 10. CRITICAL FINDINGS & ISSUES

### 1. **MISSING: Phase 11 (Final QC) Implementation**
- **Severity**: High
- **Description**: No dedicated QC workflow for Phase 11
- **Impact**: Students cannot run final validation before marking thesis complete
- **Location**: Project workspace doesn't differentiate Phase 11
- **Fix**: Add ComplianceQC or FinalQC component that blocks on Tier D citations

### 2. **DUPLICATE Citation Search Dialog Instances**
- **Severity**: Low (cosmetic)
- **Description**: CitationSearchDialog rendered in two places:
  - Editor tab (line 697-706)  via workspace state
  - SectionEditor component (line 230-258)  via component state
- **Impact**: Users may see two separate citation search UIs depending on where they click
- **Location**: `SectionEditor` vs workspace
- **Fix**: Remove one instance; use workspace state consistently

### 3. **Non-editable Mode Allows Mode Toggle**
- **Severity**: Low
- **Description**: When section is approved/generating, editor mode buttons still appear if content exists
- **Impact**: User can toggle to richtext, but editor is read-only; confusing UX
- **Location**: Line 402-423 (visibility logic)
- **Fix**: Hide toggle buttons if not editable: `{hasViewableContent && isEditable && (...buttons...)}`

### 4. **No Refine Without Content**
- **Severity**: Low (by design)
- **Description**: Refine button only shows if `hasContent && !isStreaming`
- **Impact**: Can't refine empty sections (users must generate first)
- **Status**: Acceptable  matches expected workflow

### 5. **SSE Stream Not Fully Consumed**
- **Severity**: Medium
- **Description**: Refine endpoint returns SSE, but workspace only reads until `done: true`
- **Location**: Line 655-665
- **Impact**: Stream properly consumed; no issue found
- **Status**:  Correctly implemented

### 6. **Mobile Tab State Not Remembered**
- **Severity**: Low
- **Description**: Mobile tab resets to "edit" on phase change
- **Location**: `setMobileTab` initialized to "edit", no persistence on `viewingPhase` change
- **Impact**: Mobile users flipped to Preview switch back to Edit when navigating
- **Fix**: Add useEffect to track preference or reset explicitly only on major navigation

---

## 11. COMPREHENSIVE STATE DEPENDENCY AUDIT

### useEffect Dependencies Audit

| Hook | Dependencies | Correct? | Issue |
|------|---|---|---|
| Line 129-133 (Sidebar collapse) | `[]` |  | Runs once on mount |
| Line 162-168 (Editor mode) | `[currentSection?.id]` |  | Re-runs when phase changes |
| Line 149-159 (Rich content memo) | `[currentSection?.id, rich_content_json, latex_content]` |  | Re-computes on content changes |

**Status**: All correct

---

## 12. PERFORMANCE CONSIDERATIONS

### Dynamic Imports
- `SectionEditor`, `LaTeXSourceView`, `PdfViewer`, `WordCountBar` all dynamically imported
- Loading skeletons shown during import
- **Status**: Good  prevents large bundle bloat

### Auto-save Debouncing
- SectionEditor: 30s debounce 
- LaTeXSourceView: Manual save only 
- MermaidEditor: 500ms debounce on preview 

### Polling Strategies
- Compile: 5s intervals 
- Analysis: 3s intervals 
- Stops polling when complete 
- Cleanup on unmount 

---

## 13. SECURITY CONSIDERATIONS

### No Direct User Input Injection
- All user inputs sanitized before API submission
- LaTeX content is trusted (student-authored)
- Mermaid source validated by Mermaid lib
- PDF download uses signed URL pattern

**Status**:  No XSS vectors found

---

## 14. SUMMARY TABLE

| Component | Status | Wired | Issues |
|-----------|--------|-------|--------|
| SectionEditor |  Complete |  | None |
| LaTeXSourceView |  Complete |  | None |
| SectionViewer |  Complete |  | None |
| PdfViewer |  Complete |  | None |
| PipelineTimeline |  Complete |  | None |
| AIGenerateButton |  Complete |  | None |
| CompileButton |  Complete |  | None |
| ReviewDialog |  Complete |  | None |
| CitationSearchDialog |  Complete |  | Duplication (minor) |
| CitationListPanel |  Complete |  | None |
| RefineDialog |  Complete |  | None |
| DatasetUpload |  Complete |  | None |
| AnalysisWizard |  Complete |  | None |
| ComplianceDashboard |  Complete |  | None |
| FigureGallery |  Complete |  | None |
| MermaidEditor |  Complete |  | None |
| ProgressDashboard |  Complete |  | None |
| WordCountBar |  Complete |  | None |
| **Phase 11 (Final QC)** |  **Missing** | N/A | **Blocking issue** |

---

## 15. RECOMMENDATIONS

### Priority 1 (Blocking)
1. **Implement Phase 11 Final QC workflow** with Tier D blocking + final compliance check

### Priority 2 (High Value)
2. Remove duplicate CitationSearchDialog instance in SectionEditor
3. Fix editor mode toggle visibility when non-editable
4. Add persistent mobile tab preference

### Priority 3 (Nice to Have)
5. Add "Generate Results" button directly in Phase 6 checklist
6. Pre-populate Refine dialog with section summary (what to refine?)
7. Show compile time breakdown in results

---

## CONCLUSION

**Overall Status**: 95% complete and fully functional

The workspace component is **exceptionally well-architected**. All 17 child components are correctly imported, properly wired, and functioning as designed. State management is clean, callback chains are well-established, and error handling is comprehensive.

**The only significant gap**: Phase 11 (Final QC) lacks a dedicated implementation. This is a must-have before students can mark theses as "completed."

All 25+ API endpoints are referenced and correctly used. The mobile/desktop responsive layout works seamlessly. The editor mode switching is smart and context-aware. The PDF refresh mechanism is robust.

This is production-ready code with minor UX polish needed.</result>
<usage>total_tokens: 91992
tool_uses: 25
duration_ms: 92773</usage>
</task-notification>
Full transcript available at: /private/tmp/claude-501/-Users-devs-Downloads-Apollo/tasks/a2ae992.output

---

<task-notification>
<task-id>a230c7b</task-id>
<status>completed</status>
<summary>Agent "Audit frontend components and wiring" completed</summary>
<result>Perfect! Now I have comprehensive information. Let me compile the final report:

## COMPREHENSIVE FRONTEND COMPONENT INVENTORY FOR APOLLO

### PART 1: COMPLETE COMPONENT LISTING

#### **UI Components** (`/apps/web/components/ui/`)
All components are imported and used throughout the app:
- `button.tsx` - Core button component (used extensively)
- `input.tsx` - Text input component (form fields)
- `alert-dialog.tsx` - Modal dialogs (review dialog, confirmations)
- `sheet.tsx` - Side panel component
- `accordion.tsx` - Collapsible sections
- `avatar.tsx` - User/author images
- `breadcrumb.tsx` - Navigation breadcrumbs
- `carousel.tsx` - Image/content carousel
- `navigation-menu.tsx` - Radix-based navigation
- `separator.tsx` - Divider lines
- `skeleton.tsx` - Loading placeholders
- `tooltip.tsx` - Hover info tooltips
- `animated-grid.tsx` - Animated background grid

#### **Layout Components** (`/apps/web/components/layout/`)
- `navbar.tsx` - Top navigation bar
- `glass-sidebar.tsx` - Main fixed sidebar (240px expanded, 80px collapsed)
- `glass-sidebar-provider.tsx` - Context provider for sidebar state with keyboard shortcut (Cmd/Ctrl+B), mobile detection, and cookie persistence
- `dashboard-header.tsx` - Dashboard page header with glass effect
- `app-sidebar.tsx` - App navigation sidebar

#### **Landing Page Components** (`/apps/web/components/landing/`)  ALL LOCKED
- `hero-section.tsx` - Hero with 3D scene loader
- `hero-3d-scene.tsx` - Three.js 3D canvas
- `features-section.tsx` - Feature cards with cursor-tracking sage glow
- `how-it-works-section.tsx` - Process steps
- `pricing-section.tsx` - Pricing cards with cursor-tracking amber glow
- `testimonials-section.tsx` - Customer testimonials with cursor-tracking #AF6FAB glow
- `cta-section.tsx` - Call-to-action with cursor-tracking #3077C9 glow
- `faq-section.tsx` - Frequently asked questions accordion
- `footer-section.tsx` - Footer with links
- `sponsors-section.tsx` - Partner marquee with fade effect

#### **Auth Components** (`/apps/web/components/auth/`)
- `auth-3d-scene-loader.tsx` - Dynamic loader for 3D auth scene
- `auth-3d-scene.tsx` - Three.js 3D canvas for sign-in/sign-up pages

#### **Editor Components** (`/apps/web/components/editor/`)
- `section-editor.tsx` - Rich text editor using Novel (Tiptap) with:
  - Auto-save timer (30s debounce)
  - Citation search dialog integration
  - LaTeX math support via extensions
  - Saves to `/api/projects/[id]/sections/[phase]` (PUT)
- `latex-source-view.tsx` - Raw LaTeX code editor with CodeMirror
- `word-count-bar.tsx` - Word count display and target tracking

#### **Viewer Components** (`/apps/web/components/viewer/`)
- `pdf-viewer.tsx` - PDF viewer using react-pdf with:
  - Page navigation (previous/next)
  - Zoom controls
  - Thumbnail panel toggle
  - Sandbox watermark overlay
  - Download button

#### **Project Workspace Components** (`/apps/web/components/project/`)  COMPREHENSIVE LIST

**Data Management:**
- `dataset-upload.tsx` - Upload CSV/Excel or generate datasets
  - Tab: Upload (drag-drop or file picker)
  - Tab: Generate (sample_size parameter)
  - API calls: POST `/api/projects/[id]/datasets`, DELETE `/api/projects/[id]/datasets/[datasetId]`
  
- `figure-gallery.tsx` - Manage figures/images (uploaded, Mermaid, R ggplot2)
  - Tabs: R Analysis figures, Mermaid diagrams, Uploaded images
  - API calls: POST `/api/projects/[id]/figures`, DELETE `/api/projects/[id]/figures/[figureId]`
  - Opens `mermaid-editor` via callback

- `mermaid-editor.tsx` - Diagram editor (flowcharts, etc.)
  - Real-time preview with 500ms debounce
  - Validates label format: `fig:lowercase-dashes`
  - API calls: POST `/api/projects/[id]/figures/mermaid`

- `analysis-wizard.tsx` - Statistical analysis configuration
  - 9 analysis types (descriptive, chi-square, t-test, correlation, survival, ROC, logistic, Kruskal-Wallis, meta-analysis)
  - Dataset and column mapping selection
  - Auto-recommendations via Haiku
  - Multi-poll for running analyses (5s interval)
  - API calls: POST `/api/projects/[id]/analyses`, POST `/api/projects/[id]/analyses/auto-detect`

**Content & Compilation:**
- `ai-generate-button.tsx` - Generate/refine section content via SSE streaming
  - Uses custom `useSSE` hook
  - Tracks citation summary (tierA, tierD counts)
  - Optional refine button (hydration-safe with `mounted` state)
  - API calls: POST `/api/projects/[id]/sections/[phase]/generate` (SSE)

- `compile-button.tsx` - PDF compilation with queue monitoring
  - Polls `/api/projects/[id]/compile` every 5s when queued
  - Shows queue position and estimated wait time
  - Displays compilation warnings (20 tolerated)
  - API calls: POST `/api/projects/[id]/compile`

- `section-viewer.tsx` - Read-only section display
  - Handles Phase 0 synopsis JSON parsing
  - Status badge (draft, generating, review, approved)
  - Renders as LaTeX or raw JSON view

**Citations & References:**
- `citation-list-panel.tsx` - Citation management panel
  - Auto-expands when Tier D citations exist
  - Tier summary badges (A/B/C/D counts)
  - Individual actions: Re-resolve (Tier D), Attest, Delete
  - Run Audit button  integrity score, missing/orphaned citations
  - Help text for Tier D handling
  - API calls: POST `/api/projects/[id]/citations/audit`, PUT/DELETE `/api/projects/[id]/citations/[citationId]`, POST `/api/projects/[id]/citations/[citationId]/re-resolve`

- `citation-search-dialog.tsx` - Search CrossRef/PubMed
  - Source toggle (PubMed default)
  - Debounced search (300ms)
  - Insert button adds citation to project
  - API calls: GET `/api/citations/search?q=...&source=...&limit=10`, POST `/api/projects/[id]/citations`

**Review & QC:**
- `review-dialog.tsx` - Pre-approval validation results
  - Groups issues: Errors, Warnings, Suggestions
  - Action buttons: Go Back & Edit, Approve Anyway
  - Severity styling (error/warning/info)
  - Category labels (citation, word-count, structure, spelling)

- `review-comments.tsx` - Display supervisor feedback
  - Fetches review tokens, then comments via latest token
  - Shows reviewer name, phase, comment text, date
  - Refresh button to reload
  - API calls: GET `/api/projects/[id]/share`, GET `/api/review/[token]/comments`

- `compliance-dashboard.tsx` - CONSORT/STROBE/PRISMA/STARD/CARE compliance
  - Guideline selector buttons
  - Auto-detects guideline based on study type
  - NBEMS result display (page count, abstract word count, PICO score)
  - Run Check button
  - API calls: POST `/api/projects/[id]/compliance`

**Metadata & Settings:**
- `abbreviation-manager.tsx` - Add/edit/delete abbreviations
  - Add form (short_form, long_form)
  - Edit inline with confirm/cancel
  - Auto-sort alphabetically
  - API calls: POST/PUT/DELETE `/api/projects/[id]/abbreviations/[abbrevId]`

- `licence-banner.tsx` - Licence requirement warning
  - Hidden if licensed, completed, or Phase < 2
  - Link to checkout with `attach=[projectId]`

- `share-dialog.tsx` - Generate read-only supervisor review link
  - Generates link on demand
  - Shows expiration date
  - Copy and Preview buttons
  - API calls: POST `/api/projects/[id]/share`

- `whatsapp-share-button.tsx` - Share via WhatsApp
  - Simple link generator to WhatsApp Web

**Utilities:**
- `delete-project-button.tsx` - Delete project with confirmation
  - Two-step confirmation (Delete? Yes/No)
  - API calls: DELETE `/api/projects/[id]`

- `export-menu.tsx` - Export dropdown menu
  - 4 export types: PDF, DOCX, LaTeX Source, Statistics
  - Only available if licensed or completed
  - Handles both JSON blob downloads and PDF redirects
  - API calls: GET `/api/projects/[id]/export/[type]`

- `thesis-completion.tsx` - Completion summary page
  - Stats: total words, approx pages, Tier A citations, dataset info
  - Cursor-tracking sage glow card
  - Download PDF button
  - Download citation CSV button
  - Uses `ExportMenu` component
  - API calls: GET `/api/projects/[id]/preview.pdf?download=1`

- `template-gallery.tsx` - Study type & university format templates
  - 6 study templates (RCT, cohort, cross-sectional, case-control, case report, systematic review)
  - 2 university templates (WBUHS, SSUHS)
  - No API calls, static data

- `phase-stepper.tsx` - DEPRECATED (marked with @deprecated comment)
  - Use `PipelineTimeline` instead
  - Shows phase access control based on licence

- `pipeline-timeline.tsx` - Active phase timeline
  - Compact 12-phase navigation (horizontal)
  - Short labels: "Orient.", "Front", "Intro", "Aims", "ROL", "M & M", "Results", "Discuss.", "Concl.", "Refs", "Append.", "Final QC"
  - 3-tier dot sizes: current (3.5px), completed (2.5px), future (2px)
  - Connecting lines (filled or light)
  - Licence gating

- `progress-dashboard.tsx` - Phase progress overview
  - Word count targets per phase
  - Citation integrity score (Tier A %)
  - Phase grid with status icons (completed/current/review/pending)

#### **Wizard Components** (`/apps/web/components/wizard/`)
- `setup-wizard.tsx` - 5-step project creation wizard
  - Step 1: University selection (WBUHS/SSUHS)
  - Step 2: Synopsis upload/paste
  - Step 3: Parsed data review
  - Step 4: Metadata form (candidate name, guide name, etc.)
  - Step 5: Title page preview
  - Stepper UI with progress indicators
  - API calls: PATCH `/api/projects/[id]` for each step

**Wizard Steps:**
- `synopsis-upload-step.tsx` - File upload or paste synopsis
  - Uses `FileUploader` component
  - Shows upload status message for PDFs
  - Live preview of pasted text
  - API calls: Delegates to FileUploader

- `parsed-data-review-step.tsx` - Review extracted synopsis data
  - Auto-attempts AI parsing via `/api/synopsis/parse`
  - Falls back to regex parser if AI fails
  - Editable fields for title, study_type, etc.
  - Shows "AI parsing unavailable" warning on fallback
  - API calls: POST `/api/synopsis/parse`

- `metadata-form-step.tsx` - Thesis metadata form
  - Candidate name, registration number
  - Guide name, department
  - University affiliation

- `title-page-preview-step.tsx` - HTML/LaTeX title page preview
  - Renders title page with metadata
  - Uses `generateTitlePageHtml` and `TitlePagePreview`

- `university-step.tsx` - University selection buttons
  - WBUHS (Director, REFERENCES, bottom-centre)
  - SSUHS (Principal, BIBLIOGRAPHY, bottom-right + dept footer)

#### **Providers** (`/apps/web/components/providers/`)
- `posthog-provider.tsx` - PostHog analytics
  - Initialises on mount, opt-out in dev
  - `trackEvent()` exported function (whitelist: project_created, phase_approved, compile_triggered, export_downloaded, analysis_started, compliance_checked, dataset_uploaded)
  - Sanitises PII fields (email, name, registration_no, candidate_name, guide_name, $ip)

- `pwa-provider.tsx` - Service worker registration
  - Registers `/sw.js` on mount
  - Renders children unchanged

#### **Preview Components** (`/apps/web/components/preview/`)
- `title-page-preview.tsx` - Renders HTML title page in iframe

#### **Upload Components** (`/apps/web/components/upload/`)
- `file-uploader.tsx` - Generic file uploader
  - Accepts prop configurable file types
  - Max size validation
  - Reads text from PDF/DOCX via file reader
  - Calls `onFileRead` callback with extracted text

#### **Onboarding** (`/apps/web/components/onboarding/`)
- `tour-overlay.tsx` - 4-step welcome tour
  - Targets data attributes: `[data-tour='sidebar']`, `[data-tour='new-project']`, `[data-tour='pipeline']`
  - Uses localStorage to prevent repeat: `apollo_onboarding_complete`
  - Uses motion.react for animations

#### **Licences** (`/apps/web/components/licences/`)
- `attach-dialog.tsx` - Attach thesis licence to sandbox project
  - Fetches sandbox projects on mount
  - Shows error if none available
  - API calls: GET `/api/projects`, POST `/api/licenses/[lid]/attach/[pid]`

#### **Theme**
- `theme-provider.tsx` - Next.js theme provider with shadcn/ui

---

### PART 2: APP ROUTES & PAGE STRUCTURE

#### **Public Routes**
- `/app/page.tsx` - Landing page (locked, do not modify)
- `/app/(auth)/sign-in/[[...sign-in]]/page.tsx` - Clerk sign-in with custom styling
- `/app/(auth)/sign-up/[[...sign-up]]/page.tsx` - Clerk sign-up
- `/review/[token]/page.tsx` - Public supervisor review page

#### **Dashboard Routes** (`/(dashboard)/`)
- `/dashboard/page.tsx` - Dashboard home (stats, recent projects)
- `/projects/page.tsx` - Projects list (uses ProjectCard + TemplateGallery)
- `/projects/new/page.tsx` - New project creation
- `/projects/[id]/page.tsx` - Project detail page (routes to setup or workspace)
- `/projects/[id]/setup/page.tsx` - Project setup wizard (SetupWizard component)
- `/projects/[id]/project-workspace.tsx` - Main editor workspace (client component)
  - Dynamic imports for heavy components:
    - `SectionEditor` (lazy loaded)
    - `LaTeXSourceView` (lazy loaded)
    - `PdfViewer` (lazy loaded)
    - `WordCountBar` (lazy loaded)
  - Renders: PipelineTimeline, SectionEditor/LaTeXSourceView toggle, PdfViewer, CitationListPanel, CitationSearchDialog, ReviewDialog, AnalysisWizard, DatasetUpload, MermaidEditor, ComplianceDashboard, ProgressDashboard, FigureGallery, ThesisCompletion
  - Tabs: editor, data, compliance, figures, progress
  - Mobile tabs: edit, preview

- `/checkout/page.tsx` - Stripe checkout page
- `/licences/page.tsx` - User's thesis licences page

---

### PART 3: API ROUTES CALLED FROM FRONTEND

#### **Project Management**
| Component | HTTP Method | API Route | Purpose |
|-----------|-------------|-----------|---------|
| SetupWizard | PATCH | `/api/projects/[id]` | Save project metadata |
| DeleteProjectButton | DELETE | `/api/projects/[id]` | Delete project |
| ReviewComments | GET | `/api/projects/[id]/share` | Fetch review tokens |

#### **Sections & Content**
| Component | HTTP Method | API Route | Purpose |
|-----------|-------------|-----------|---------|
| AIGenerateButton | POST | `/api/projects/[id]/sections/[phase]/generate` | Generate section (SSE streaming) |
| SectionEditor | PUT | `/api/projects/[id]/sections/[phase]` | Save editor content |
| CompileButton | POST | `/api/projects/[id]/compile` | Compile PDF (polls for status) |

#### **Citations**
| Component | HTTP Method | API Route | Purpose |
|-----------|-------------|-----------|---------|
| CitationSearchDialog | GET | `/api/citations/search?q=...&source=...&limit=...` | Search CrossRef/PubMed |
| CitationSearchDialog | POST | `/api/projects/[id]/citations` | Add citation to project |
| CitationListPanel | POST | `/api/projects/[id]/citations/audit` | Run citation audit |
| CitationListPanel | PUT | `/api/projects/[id]/citations/[citationId]` | Mark citation as attested |
| CitationListPanel | DELETE | `/api/projects/[id]/citations/[citationId]` | Delete citation |
| CitationListPanel | POST | `/api/projects/[id]/citations/[citationId]/re-resolve` | Retry citation resolution |

#### **Datasets & Analysis**
| Component | HTTP Method | API Route | Purpose |
|-----------|-------------|-----------|---------|
| DatasetUpload | POST | `/api/projects/[id]/datasets` | Upload CSV/Excel |
| DatasetUpload | DELETE | `/api/projects/[id]/datasets/[datasetId]` | Delete dataset |
| DatasetUpload | POST | `/api/projects/[id]/datasets/generate` | Generate synthetic dataset |
| AnalysisWizard | GET | `/api/projects/[id]/analyses/[analysisId]` | Poll for analysis status |
| AnalysisWizard | POST | `/api/projects/[id]/analyses/auto-detect` | Get auto-recommendations |
| AnalysisWizard | POST | `/api/projects/[id]/analyses` | Submit analysis job |

#### **Figures & Diagrams**
| Component | HTTP Method | API Route | Purpose |
|-----------|-------------|-----------|---------|
| FigureGallery | POST | `/api/projects/[id]/figures` | Upload figure image |
| FigureGallery | DELETE | `/api/projects/[id]/figures/[figureId]` | Delete figure |
| MermaidEditor | POST | `/api/projects/[id]/figures/mermaid` | Save Mermaid diagram |

#### **Abbreviations**
| Component | HTTP Method | API Route | Purpose |
|-----------|-------------|-----------|---------|
| AbbreviationManager | POST | `/api/projects/[id]/abbreviations` | Add abbreviation |
| AbbreviationManager | PUT | `/api/projects/[id]/abbreviations/[abbrevId]` | Update abbreviation |
| AbbreviationManager | DELETE | `/api/projects/[id]/abbreviations/[abbrevId]` | Delete abbreviation |

#### **Compliance & QC**
| Component | HTTP Method | API Route | Purpose |
|-----------|-------------|-----------|---------|
| ComplianceDashboard | POST | `/api/projects/[id]/compliance` | Run compliance check |
| ReviewComments | GET | `/api/review/[token]/comments` | Fetch supervisor comments |

#### **Exports & Sharing**
| Component | HTTP Method | API Route | Purpose |
|-----------|-------------|-----------|---------|
| ExportMenu | GET | `/api/projects/[id]/export/[type]` | Export (pdf/docx/source/stats) |
| ShareDialog | POST | `/api/projects/[id]/share` | Generate share link |
| ThesisCompletion | GET | `/api/projects/[id]/preview.pdf?download=1` | Download preview PDF |

#### **Licences**
| Component | HTTP Method | API Route | Purpose |
|-----------|-------------|-----------|---------|
| AttachDialog | GET | `/api/projects` | List all projects |
| AttachDialog | POST | `/api/licenses/[lid]/attach/[pid]` | Attach licence to project |

#### **Parsing**
| Component | HTTP Method | API Route | Purpose |
|-----------|-------------|-----------|---------|
| ParsedDataReviewStep | POST | `/api/synopsis/parse` | AI-parse synopsis text |

---

### PART 4: TODO/FIXME/HACK COMMENTS FOUND

**RESULT: NONE FOUND**  The codebase is clean. No TODO, FIXME, HACK, or XXX comments in components.

---

### PART 5: COMPONENTS WITH EMPTY OR PLACEHOLDER HANDLERS

**No critical issues found.** All event handlers have meaningful implementations:
- All buttons trigger actual API calls or state changes
- All callbacks have implementations (no `() => {}` stubs)
- Placeholder handlers are intentional (e.g., `handleExport` early returns for unlicensed users)

---

### PART 6: DYNAMIC IMPORTS

Found in **project-workspace.tsx**:
```tsx
const SectionEditor = dynamic(
  () => import("@/components/editor/section-editor").then(m => m.SectionEditor),
  { ssr: false, loading: () => <EditorSkeleton /> }
);

const LaTeXSourceView = dynamic(
  () => import("@/components/editor/latex-source-view").then(m => m.LaTeXSourceView),
  { ssr: false, loading: () => <EditorSkeleton /> }
);

const PdfViewer = dynamic(
  () => import("@/components/viewer/pdf-viewer").then(m => m.PdfViewer),
  { ssr: false, loading: () => <EditorSkeleton /> }
);

const WordCountBar = dynamic(
  () => import("@/components/editor/word-count-bar").then(m => m.WordCountBar),
  { ssr: false }
);
```

**All files exist and are correctly imported.** 

---

### PART 7: STATE MANAGEMENT PATTERNS

#### **Context Providers:**
1. **GlassSidebarProvider** (`/components/layout/glass-sidebar-provider.tsx`)
   - Context: `GlassSidebarContext`
   - Hook: `useGlassSidebar()`
   - State: `isExpanded`, `mobileOpen`, `isMobile`, `toggleSidebar()`
   - Features: Keyboard shortcut (Cmd/Ctrl+B), cookie persistence, mobile detection via `useIsMobile`

2. **ThemeProvider** (`/components/theme-provider.tsx`)
   - Next.js built-in theme provider

3. **ClerkProvider** (app/layout.tsx)
   - Authentication provider

4. **PostHogProvider** (`/components/providers/posthog-provider.tsx`)
   - Analytics initialization (event whitelist)

5. **PWAProvider** (`/components/providers/pwa-provider.tsx`)
   - Service worker registration

#### **Custom Hooks:**
1. **useSSE** (`/hooks/use-sse.ts`)
   - Manages Server-Sent Event streaming
   - Used in AIGenerateButton
   - Tracks: `isStreaming`, `streamedText`, `error`
   - Methods: `start(url, fetchOptions)`, `stop()`

2. **useIsMobile** (`/hooks/use-mobile.tsx`)
   - Mobile breakpoint detection
   - Used in sidebar provider and UI sidebar

#### **No Zustand stores found**  All state is component-local or via context.

---

### PART 8: CONDITIONALS THAT MIGHT NEVER TRIGGER

**Potential Dead Code Identified:**

1. **phase-stepper.tsx** (deprecated)
   - Marked `@deprecated`  Use PipelineTimeline instead
   - Not imported anywhere in the codebase
   - **Status:** Candidate for removal

2. **LicenceBanner early returns:**
   ```tsx
   if (projectStatus === "licensed" || projectStatus === "completed") return null;
   if (devLicenceBypass) return null;
   if (currentPhase < 1) return null;
   ```
   - These are correct guards (banner hides for licensed projects)
   - No dead code here

3. **ProgressDashboard word targets:**
   ```tsx
   6: { min: 0, max: 0 }, // Dataset  no word target
   ```
   - Intentional (Phase 6 is dataset upload, not writing)

4. **ComplianceDashboard export disable:**
   ```tsx
   if (!isLicensed) return; // in handleExport
   ```
   - Correct guard to prevent unlicensed exports

---

### PART 9: BUTTONAPI ROUTE MAPPING

| Button | Component | API Route | Method |
|--------|-----------|-----------|--------|
| Generate with AI | AIGenerateButton | `/api/projects/[id]/sections/[phase]/generate` | POST (SSE) |
| Refine | AIGenerateButton | (callback via `onRefine` prop) | N/A |
| Compile PDF | CompileButton | `/api/projects/[id]/compile` | POST |
| Add Citation | CitationListPanel | (callback via `onAddCitation` prop) | N/A |
| Run Audit | CitationListPanel | `/api/projects/[id]/citations/audit` | POST |
| Re-resolve (Tier D) | CitationListPanel | `/api/projects/[id]/citations/[citationId]/re-resolve` | POST |
| Attest (Tier D) | CitationListPanel | `/api/projects/[id]/citations/[citationId]` | PUT |
| Delete Citation | CitationListPanel | `/api/projects/[id]/citations/[citationId]` | DELETE |
| Upload File | FileUploader | (multipart, handled by parent) | POST |
| Generate Dataset | DatasetUpload | `/api/projects/[id]/datasets/generate` | POST |
| Delete Dataset | DatasetUpload | `/api/projects/[id]/datasets/[datasetId]` | DELETE |
| Save Abbreviation | AbbreviationManager | `/api/projects/[id]/abbreviations` | POST |
| Update Abbreviation | AbbreviationManager | `/api/projects/[id]/abbreviations/[abbrevId]` | PUT |
| Delete Abbreviation | AbbreviationManager | `/api/projects/[id]/abbreviations/[abbrevId]` | DELETE |
| Upload Figure | FigureGallery | `/api/projects/[id]/figures` | POST |
| Delete Figure | FigureGallery | `/api/projects/[id]/figures/[figureId]` | DELETE |
| Save Mermaid | MermaidEditor | `/api/projects/[id]/figures/mermaid` | POST |
| Add Analysis | AnalysisWizard | `/api/projects/[id]/analyses` | POST |
| Run Compliance Check | ComplianceDashboard | `/api/projects/[id]/compliance` | POST |
| Generate Share Link | ShareDialog | `/api/projects/[id]/share` | POST |
| Copy Share Link | ShareDialog | (navigator.clipboard, no API) | N/A |
| Download PDF | ThesisCompletion | `/api/projects/[id]/preview.pdf?download=1` | GET |
| Download CSV | ThesisCompletion | (CSV download handler) | GET |
| Export (menu) | ExportMenu | `/api/projects/[id]/export/[type]` | GET |
| Delete Project | DeleteProjectButton | `/api/projects/[id]` | DELETE |
| Attach Licence | AttachDialog | `/api/licenses/[lid]/attach/[pid]` | POST |
| Save Setup Wizard Step | SetupWizard | `/api/projects/[id]` | PATCH |

---

### PART 10: COMPONENT USAGE VERIFICATION

**All 67 components imported and used correctly.** 

**Critical Components:**
- `ProjectWorkspace` imports 34+ components  all functioning
- `SectionEditor`, `LaTeXSourceView`, `PdfViewer` dynamically loaded with fallback UI
- No circular dependencies detected
- No unused imports within components

---

### PART 11: SPECIAL PATTERNS

#### **Hydration-Safe State:**
Components using `useEffect` to defer rendering (avoiding hydration mismatch):
- `AIGenerateButton`  `mounted` state for Refine button visibility
- `CitationListPanel`  `hasTierD` effect to auto-expand
- `ReviewComments`  Initial load state

#### **Debouncing:**
- `ParsedDataReviewStep`  AI parse auto-call on mount (prevent duplicate calls)
- `CitationSearchDialog`  Query debounce (300ms) via useRef
- `MermaidEditor`  Render debounce (500ms) for Mermaid preview

#### **Polling:**
- `CompileButton`  Poll queue position every 5s
- `AnalysisWizard`  Multi-poll for multiple running analyses
- `ReviewComments`  Refresh button for comments (no auto-poll)

#### **SSE Streaming:**
- `AIGenerateButton`  Custom `useSSE` hook for text generation
- Uses abort controller for cancellation (Stop button)
- Accumulates streamed text, fires onComplete callback with citation summary

#### **Cursor-Tracking Glow:**
- `ProjectCard`, `ThesisCompletion` (CursorGlowCard), `ThesisCompletion` 
- CSS custom properties `--mouse-x`, `--mouse-y` set on mousemove
- Radial gradient: 15%  12%  6%  transparent

---

### SUMMARY

**Total Components:** 67   
**Total Pages/Routes:** 11   
**API Routes Called:** 45+ endpoints   
**Context Providers:** 5 (Sidebar, Theme, Clerk, PostHog, PWA)   
**Custom Hooks:** 2 (useSSE, useIsMobile)   
**Dynamic Imports:** 4 (all valid)   
**TODOs/FIXMEs:** 0   
**Deprecated Components:** 1 (PhaseStepper - candidate for removal)   
**Unused Imports:** None detected   
**Dead Code:** Minimal (only deprecated stepper)   

**Key Architectural Patterns:**
1. Landing page & dashboard locked (do not modify without approval)
2. Project workspace uses dynamic imports for editor/viewer performance
3. All API calls return error handling via toast notifications
4. Sidebar context manages collapsed/expanded state with keyboard shortcut
5. SSE streaming for AI generation with real-time UI updates
6. Cursor-tracking glow effects on cards (custom CSS properties)
7. All forms validate before submission
8. Citation tiers (A/B/C/D) with audit and re-resolution workflows
9. Licence gating on Phase 2+ and exports
10. CONSORT/STROBE/PRISMA/STARD/CARE compliance checking</result>
<usage>total_tokens: 95224
tool_uses: 54
duration_ms: 137130</usage>
</task-notification>
Full transcript available at: REDACTED.output

---

Write down parts I,II and III in full in /docs/REVIEW.md

---

<task-notification>
<task-id>ab96c09</task-id>
<status>completed</status>
<summary>Agent "Extract Part I findings from transcript" completed</summary>
<result>Now I have the full picture. Line 100 (which I read earlier) contains the TL;DR summary. The complete Part I report was delivered to the user on line 93. Here is the complete Part I report text as it was delivered:

---

# Apollo Gap Analysis: PLAN.md vs Codebase

## 1. CI/CD Health

| Check | Status | Details |
|-------|--------|---------|
| **Last commit CI** | **FAILED** | `8a900a2` -- lint step exits with code 1 |
| TypeScript (tsc) | PASS | 0 errors |
| Unit tests | PASS | **343/343** across 30 files |
| ESLint | **1 ERROR** | `lib/citations/auto-resolve.ts:151` -- `prefer-const` (`let tier` should be `const`) |
| ESLint warnings | 15 warnings | Unused vars (7), missing alt props (3), unused imports (5) |

**Root cause of CI failure**: A single `let` that should be `const` in `auto-resolve.ts`. Trivial fix.

---

## 2. Uncommitted Work (Risk)

**51 files modified** (+1,968 / -385 lines) and **17 untracked files/directories** sitting only on local. This represents Sprint 3-10 hardening work that has never been pushed since the Sprint 3-10 commits (`5cf238f`, `dd29b6f`, `9756fc6`). The last push was `8a900a2` (Feb 15) which failed CI.

**New untracked routes/components** (not yet version-controlled):
- `app/api/projects/[id]/citations/[citationId]/re-resolve/` -- citation re-resolution
- `app/api/projects/[id]/datasets/[datasetId]/download/` -- dataset download
- `app/api/projects/[id]/qc/` + `qc/fix/` -- Final QC (Phase 11)
- `app/api/projects/[id]/sections/[phase]/refine/` -- section refinement
- `components/project/thesis-completion.tsx` -- completion UI
- `lib/citations/pre-seed.ts` -- citation pre-seeding
- `lib/qc/final-qc.ts` -- QC engine
- `supabase/` -- migration files

---

## 3. Sprint-by-Sprint Gap Analysis

### Sprint 0: Dev Rules + Governance -- COMPLETE
All guidance files, governance docs, and CI pipeline present.

### Sprint 1-2: Foundation + Setup Wizard + Licenses -- COMPLETE
- Auth (Clerk) | Setup wizard (5 steps) | License CRUD
- Identity binding at Phase 1->2 | Workflow gates
- R2 signed URLs | Synopsis parsing

### Sprint 3-4: Compute + Editor -- COMPLETE
- LaTeX Docker container | R Plumber Docker container
- Inngest workflow (thesis + analysis) | Novel/Tiptap editor
- CodeMirror LaTeX view | Word count tracking
- Abbreviation management | Semaphore admission control

### Sprint 5-6: AI + Citations -- COMPLETE
- Claude API proxy | SSE streaming | AI prompts per phase
- Citation provenance pipeline (A/B/C/D tiers)
- PubMed/CrossRef search | Citation audit (bidirectional)
- Rate limiting | Auto-resolve

### Sprint 7: Dashboard + Compliance + Core Analysis -- MOSTLY COMPLETE

| Item | Status | Notes |
|------|--------|-------|
| 12-phase pipeline timeline | Done | With 3-tier dot hierarchy |
| PDF preview (react-pdf) | Done | Split-pane viewer |
| CONSORT/STROBE/PRISMA dashboards | Done | `lib/compliance/checklists.ts` |
| NBEMS checker | Done | `lib/compliance/nbems.ts` |
| Mermaid integration | Done | `figures/mermaid/route.ts` |
| Dataset upload + column detection | Done | `lib/datasets/parse.ts` |
| Template gallery | Done | `template-gallery.tsx` |
| **R Sprint 7 analyses** | Done | Descriptive, chi-square, t-test, survival |

### Sprint 8: Advanced Analysis + Observability -- PARTIAL

| Item | Status | Gap |
|------|--------|-----|
| R Sprint 8 (ROC, logistic, Kruskal-Wallis, meta-analysis) | **Needs verification** | `plumber.R` has endpoints, need to verify all 4 types |
| Runtime limits per analysis type | **Partial** | Semaphore exists, but per-type timeouts (15s-60s) not enforced at route level |
| Queue fairness (round-robin) | **MISSING** | No round-robin logic found -- FIFO only |
| Sentry traces across services | **Partial** | Sentry configs exist but no custom spans for Claude/compile/R |
| PII scrubbing in Sentry/PostHog | **Partial** | `lib/ai/redact.ts` exists for AI prompts, but no `beforeSend` PII filter in Sentry config |
| Playwright MCP configured | Done | Config and E2E specs exist |

### Sprint 9-10: Export + Payments + Launch -- MOSTLY COMPLETE

| Item | Status | Gap |
|------|--------|-----|
| Razorpay integration | Done | Webhook + checkout exist |
| Stripe integration | Done | Webhook exists |
| Export: PDF, DOCX, source, stats | Done | All 4 export routes exist |
| DOCX via pandoc | Done | In Dockerfile.latex |
| Supervisor dashboard | Done | `review/[token]` pages + comments API |
| Quality gate automation | **Partial** | QC routes exist (untracked), but not all checks wired |
| Landing page | Done | All sections locked |
| **PWA manifest + SW** | Done | `public/manifest.json` + `public/sw.js` |
| **PWA mobile pages** | **MISSING** | PLAN specifies 3 mobile-optimised pages (dashboard, AI chat, PDF preview) -- no mobile-specific routes exist |
| Velocity rules + abuse controls | **MISSING** | No >5 licenses/30 days check found |
| `processed_webhooks` table | **MISSING** | Webhook idempotency table not in migrations |

---

## 4. Security & Infrastructure Gaps

### Docker Security (PLAN vs Actual)

| Requirement | PLAN.md | Actual | Gap |
|-------------|---------|--------|-----|
| LaTeX: `--network=none` | Required | Port `3001` exposed | **DEVIATION** -- container accessible on network |
| LaTeX: seccomp profile | Active profile | `seccomp:unconfined` | **DEVIATION** -- no seccomp filtering |
| R: AppArmor profile | Required | Not configured | **MISSING** |
| R: no `system()` calls verified | Required | Not enforced | **MISSING** |
| Read-only rootfs | Required | `read_only: true` | OK |
| Memory limits | 1GB LaTeX, 512MB R | `mem_limit: 1g` / `512m` | OK |

### Webhook Hardening

| Requirement | Status |
|-------------|--------|
| Signature verification | Done -- In webhook routes |
| Idempotency (`processed_webhooks` table) | **MISSING** -- no table, no dedup logic |
| Replay protection (Razorpay 5min window) | **MISSING** |
| Atomic license provisioning | Done -- In `provision-licence.ts` |

### Database Schema

Only 3 incremental migrations found locally (`016`, `017`, `018`). The core schema (projects, sections, citations, etc.) presumably lives in Supabase directly or in earlier migrations not present locally. **Risk**: Schema drift between Supabase instance and local migration files.

---

## 5. Code Quality Issues

### Lint Errors (CI-blocking)
1. `lib/citations/auto-resolve.ts:151` -- `let tier` should be `const`

### Lint Warnings (should fix)
1. `project-workspace.tsx:701` -- unused `citeKey`
2. `projects/page.tsx:5` -- unused `DeleteProjectButton` import
3. `export/docx/route.ts:50` -- unused `warnings`
4. `refine/route.ts:75` -- unused `streamCompleted`
5. `hero-3d-scene.tsx:150` -- unused `roundRect`
6. `glass-sidebar.tsx:11` -- unused `X` import
7. `citation-search-dialog.tsx:8` -- unused `cn`
8. `dataset-upload.tsx:24` -- unused `ColumnPreview`
9. `figure-gallery.tsx:152,227,256` -- 3x missing `alt` props
10. `pubmed.ts:3` -- unused `stripDoiField`
11. `checker.ts:2` -- unused `createAdminSupabaseClient`
12. `parse-log.ts:67` -- unused `isFatalError`
13. `validate.ts:66` -- unused `_match`

---

## 6. Priority Actions

### P0 -- Fix Immediately
1. Fix the `prefer-const` lint error in `auto-resolve.ts` to unblock CI
2. Commit and push all 51 modified + 17 untracked files (massive loss risk)

### P1 -- Before Launch
3. Add `processed_webhooks` table + idempotency logic to webhook handlers
4. Add Razorpay replay protection (5-min timestamp check)
5. Fix Docker security: replace `seccomp:unconfined` with a proper profile
6. Add per-analysis-type runtime limits (15s-60s timeouts)
7. Wire PII scrubbing into Sentry `beforeSend`
8. Fix all 15 lint warnings

### P2 -- Before Launch (Lower Priority)
9. Implement velocity rules (>5 licenses/30 days -> hold)
10. Add queue fairness (round-robin across users)
11. Create 3 PWA mobile-optimised pages or confirm responsive design covers them
12. Resolve LaTeX container network isolation (internal Docker network vs `--network=none`)
13. Add AppArmor profile for R container
14. Ensure full database migration files are tracked in git

---

This was followed by a TL;DR on line 100:

> **TL;DR**: The codebase is impressively complete (~90% of PLAN.md), but has **1 CI-blocking lint error**, **51 files of uncommitted work at risk**, and ~10 security/infra gaps between what PLAN.md specifies and what's actually implemented (webhook idempotency, Docker seccomp, AppArmor, velocity rules).

The report was found on line 93 of the JSONL file at `/Users/devs/.REDACTED.jsonl`. The full analysis was delivered as a single assistant message with the text block containing the complete Part I infrastructure gap analysis covering all 6 sections: CI/CD Health, Uncommitted Work Risk, Sprint-by-Sprint Gap Analysis, Security & Infrastructure Gaps, Code Quality Issues, and Priority Actions (P0/P1/P2).</result>
<usage>total_tokens: 88601
tool_uses: 28
duration_ms: 287340</usage>
</task-notification>
Full transcript available at: /private/tmp/claude-501/-Users-devs-Downloads-Apollo/tasks/ab96c09.output

---

<task-notification>
<task-id>a77f0e4</task-id>
<status>completed</status>
<summary>Agent "Extract Part II agent findings" completed</summary>
<result>Now I have all five reports. Here is the complete findings text from each agent, organized by agent name.

---

## Agent 1: AI Prompts Audit

**File**: `/private/tmp/claude-501/-Users-devs-Downloads-Apollo/tasks/a3d46a3.output`

---

## Critical Analysis: Apollo AI Integration for Thesis Generation

### FILE 1: `/Users/devs/Downloads/Apollo/apps/web/lib/ai/prompts.ts`

**Complete content**: Shown in full above (440 lines). Contains 12 exported prompts/functions:
- `COMMON_RULES` (shared LaTeX rules)
- `SYNOPSIS_PARSE_SYSTEM_PROMPT` (Phase 0)
- `FRONT_MATTER_SYSTEM_PROMPT` (Phase 1)
- `INTRODUCTION_SYSTEM_PROMPT` (Phase 2)
- `AIMS_SYSTEM_PROMPT` (Phase 3)
- `ROL_SYSTEM_PROMPT` (Phase 4)
- `MATERIALS_METHODS_SYSTEM_PROMPT` (Phase 5)
- `RESULTS_SYSTEM_PROMPT` (Phase 6)
- `DISCUSSION_SYSTEM_PROMPT` (Phase 7)
- `CONCLUSION_SYSTEM_PROMPT` (Phase 8)
- `APPENDICES_SYSTEM_PROMPT` (Phase 10)
- `REFINE_SYSTEM_PROMPT` (editing)
- `DATASET_GENERATION_SYSTEM_PROMPT` (synthetic data)
- `getPhaseSystemPrompt()` and `getPhaseUserMessage()` functions

#### Strengths

1. **Comprehensive structure**: Each phase has a detailed structural template with numbered subsections. The prompts are not bare-minimum placeholders -- they specify exact section ordering, LaTeX formatting conventions, and content expectations.

2. **Citation handling is well-designed**: The `---BIBTEX---` separator convention is explicit and consistent. Every citation-heavy phase includes a mandatory BibTeX trailer instruction with example format. The system correctly instructs `\cite{key}` usage rather than hardcoded numbers.

3. **British English is enforced at multiple layers**: In `COMMON_RULES` rule #1, in the synopsis parser, and then validated post-generation by `review-section.ts` and `final-qc.ts`.

4. **Word count enforcement**: Each prompt specifies a target range AND a hard limit (e.g., Introduction: 700-1,200 words, hard limit 1,380). The hard limits correctly note that BibTeX entries don't count.

5. **Medical domain specificity**: NBEMS 12-section requirement for Materials & Methods, ICMR 2017 guidelines, ethics statement templates, STROBE/CONSORT references, PICO format for aims -- these are all genuinely useful for Indian medical PG theses.

6. **GOLD Standard methodology**: The 12-phase pipeline is fully represented. Each prompt specifies tense conventions (past for M&M/Results, present for Introduction, mixed for Discussion).

#### Critical Issues

**ISSUE 1: Phase 9 (References) is completely missing.**

In `getPhaseSystemPrompt()`, there is no `case 9`. The plan specifies Phase 9 as "References" but there is no prompt for it. The switch statement jumps from Phase 8 (Conclusion) to Phase 10 (Appendices). This means the references phase is either handled entirely by the BibTeX aggregation pipeline or is simply skipped. Given that citation management is core to the product, this gap is concerning -- there should at least be a prompt that consolidates and validates all BibTeX entries across chapters.

**ISSUE 2: Phase 6a (Dataset) and 6b (Results) are conflated.**

The PLAN.md specifies Phase 6a (Dataset generation) and Phase 6b (Results writing) as separate sub-phases. But `getPhaseSystemPrompt(6)` returns `RESULTS_SYSTEM_PROMPT`. There is no Phase 6a prompt in the switch statement. Dataset generation uses a separate prompt (`DATASET_GENERATION_SYSTEM_PROMPT`) but is invoked through a completely different API route (`/datasets/generate`), not through the phase pipeline. This means the phase numbering is inconsistent with the plan.

**ISSUE 3: Results prompt lacks specificity about analysis integration.**

The `RESULTS_SYSTEM_PROMPT` says "Include R-generated `\texttt{table\_latex}` content VERBATIM" but doesn't provide structured guidance on how to integrate multiple analysis types. For a thesis with descriptive stats, chi-square, ROC, and logistic regression, the prompt gives no ordering guidance beyond the generic structure. The user message in `getPhaseUserMessage(6)` doesn't mention analysis context at all -- that injection happens only in the route handler. The prompt should acknowledge that analysis summaries will be appended.

**ISSUE 4: Previous section context is truncated to 3,000 characters per section.**

In `getPhaseUserMessage()`, line 376:
```typescript
.map((s) => `--- ${s.phaseName} ---\n${s.content.slice(0, 3000)}`)
```

For the Review of Literature (which can be 3,500-4,500 words / ~20,000+ characters), only the first ~500 words are passed as context to subsequent phases. This means the Discussion chapter -- which must compare findings with literature -- receives almost no ROL context. For a thesis generation product, this is a severe quality limitation.

**ISSUE 5: No prompt for Phase 11 (Final QC) AI-assisted fixes.**

The QC route at `/api/projects/[id]/qc/route.ts` calls `finalQC()` which is purely deterministic. There is a `/qc/fix` route in the file listing, but the QC fix prompt is absent from `prompts.ts`. The plan likely envisions AI-assisted auto-fixes (e.g., replacing American spellings, expanding thin sections), but there is no AI prompt for this.

**ISSUE 6: Synopsis parse prompt is duplicated.**

`SYNOPSIS_PARSE_SYSTEM_PROMPT` in `prompts.ts` extracts `title, study_type, department, objectives, methodology_summary, sample_size, duration, setting, keywords`. But the standalone `/api/synopsis/parse/route.ts` uses a completely different inline prompt (`SYNOPSIS_WIZARD_PROMPT`) that extracts a different schema: `title, aims, objectives, study_type, study_design, sample_size, inclusion_criteria, exclusion_criteria, methodology_summary`. The two prompts disagree on field names and structure. This is confusing and error-prone -- which one is the source of truth?

**ISSUE 7: `COMMON_RULES` should include Unicode avoidance.**

The project's MEMORY.md documents that Unicode in LaTeX causes critical BibTeX failures ("Invalid UTF-8 byte sequence"). But `COMMON_RULES` never tells the AI to avoid Unicode characters. The escaping happens downstream in `escape.ts`, but preventing it at the source would reduce compilation failures.

---

### FILE 2: `/Users/devs/Downloads/Apollo/apps/web/lib/ai/client.ts`

**Complete content**: 14 lines. A singleton factory for the Anthropic SDK client.

#### Critical Issues

**ISSUE 1: `datasets/generate.ts` bypasses the singleton.**

Line 82 of `generate.ts`: `const anthropic = new Anthropic();` -- this creates a new client instance directly instead of using `getAnthropicClient()`. Same for `compliance/checker.ts` line 166: `const anthropic = new Anthropic();`. This means those call sites rely on the `ANTHROPIC_API_KEY` environment variable being auto-detected by the SDK's constructor, which is a different code path. It works, but it's inconsistent and means changes to the singleton (e.g., adding request timeout defaults, custom headers, or retry configuration) won't apply everywhere.

**ISSUE 2: No retry configuration.**

The Anthropic SDK supports automatic retries. The client is created with only `{ apiKey }` -- no `maxRetries`, no `timeout` configuration. For a production service where AI generation takes 10-30 seconds and can be rate-limited by Anthropic, this is risky. A transient 429 or 500 from Anthropic will immediately fail the generation.

**ISSUE 3: No base URL override for testing.**

There's no way to point the client at a mock server during tests. The `ANTHROPIC_API_URL` env var would work through the SDK, but there's no documentation or test helper for this.

---

### FILE 3: `/Users/devs/Downloads/Apollo/apps/web/lib/ai/review-section.ts`

**Complete content**: 315 lines. A **purely local, deterministic** review system -- no AI API calls despite the file name.

#### Critical Issues

**ISSUE 1: The name "review-section" is misleading.**

The PLAN.md and the code comments on the generate route suggest this should include an AI-powered review step. But the actual review route calls only the local `reviewSection()` function. There is **no AI-powered review of section quality**. The AI validation via Haiku exists in `validate.ts`, but it's for LaTeX syntax checking during compilation, not for content quality review. This means the product has no AI-assisted feedback on whether the Introduction adequately covers the knowledge gap, whether the Discussion sufficiently addresses limitations, etc.

**ISSUE 2: The M&M section check requires only 8 sections, but the prompt mandates 12.**

The review check on line 138: `if (sectionCount < 8)` -- but the `MATERIALS_METHODS_SYSTEM_PROMPT` specifies "MANDATORY 12 sections (NBEMS requirement)". The final QC in `final-qc.ts` checks for `< 12`. There's an inconsistency: the mid-pipeline review is lenient (8) while final QC is strict (12).

**ISSUE 3: Word count targets disagree across files.**

In `word-count-targets.ts`:
- Phase 2 (Introduction): min 750, max 1200
- Phase 3 (Aims): min 200, max 500
- Phase 8 (Conclusion): min 400, max 800

In `final-qc.ts`:
- Phase 2 (Introduction): min 500, max 750
- Phase 3 (Aims): min 150, max 200
- Phase 8 (Conclusion): min 500, max 750

These two modules have **completely different word count targets**. The mid-pipeline review uses `word-count-targets.ts` (more generous), while the final QC uses its own hardcoded values (more restrictive). A section could pass mid-pipeline review but fail final QC on the same metric. The Introduction target in `final-qc.ts` (500-750 words) is also below the prompt's instruction (700-1,200 words), meaning the AI will generate content that the QC considers "over target".

**ISSUE 4: British English list is duplicated.**

The same 21-entry American-to-British dictionary exists in both `review-section.ts` and `final-qc.ts`. This should be a shared constant. More importantly, the list misses common medical terms like "gynecology/gynaecology", "hematology/haematology", "edema/oedema", "diarrhea/diarrhoea", "leukocyte/leucocyte".

---

### FILE 4: `/Users/devs/Downloads/Apollo/apps/web/lib/ai/token-budget.ts`

**Complete content**: 124 lines.

**Limits**:
- 100,000 output tokens per phase
- 1,200,000 total tokens per thesis

#### Critical Issues

**ISSUE 1: Token budget is checked but records input+output as a single sum.**

The budget limits say "100K output tokens per phase" but the recording combines input AND output. A single generation call for the ROL chapter with a large synopsis + pre-seeded references could easily use 10,000+ input tokens. This inflates the recorded usage, making the budget artificially tighter.

**ISSUE 2: Refinement calls don't record token usage.**

The refine route does not call `checkTokenBudget()` or `recordTokenUsage()`. A student could refine a section unlimited times, consuming unlimited tokens, and the budget system would never know. This is a cost-control blind spot.

**ISSUE 3: Dataset generation doesn't record token usage.**

**ISSUE 4: Synopsis parsing (Phase 0) doesn't record token usage.**

**ISSUE 5: `messages_json` is always empty -- no conversation persistence.**

The `ai_conversations` table has a `messages_json` column, but `recordTokenUsage()` always inserts `messages_json: []`. There is **zero conversation history** stored, **no multi-turn capability**, and the "AI conversation persistence" mentioned in the table design is entirely unused.

---

### FILE 5: `/Users/devs/Downloads/Apollo/apps/web/lib/ai/analysis-explanations.ts`

Well-written educational content. Minor issue: the `suggested_figures` field in the auto-detect prompt references chart types like `violin` and `heatmap`, but the ELI15 dictionary doesn't explain these visualization types.

---

### FILE 6: `/Users/devs/Downloads/Apollo/apps/web/lib/ai/parse-synopsis-response.ts`

Clean, defensive code. Issue: There is no validation that the parsed `study_type` matches known types.

---

### FILE 7: `/Users/devs/Downloads/Apollo/apps/web/lib/ai/redact.ts`

Appropriate for the Indian market. Issues:
1. No address redaction (Indian postal addresses with PIN codes).
2. No name redaction (patient names in case reports).
3. The Aadhaar regex is too broad (matches any 12-digit number).
4. Redaction runs only on synopsis text before generation -- not on AI output.

---

### Model Routing Analysis

| Use Case | Model | Correct per Plan? |
|---|---|---|
| Synopsis parse (Phase 0) | Sonnet 4.5 | Should be Haiku for simple extraction |
| Section generation (Phases 1-8) | Sonnet 4.5 for ALL | **Wrong** -- Plan says Opus for Intro/Discussion |
| Refine/editing | Sonnet 4.5 | Acceptable |
| Auto-detect analyses | Haiku 4.5 | Correct |
| LaTeX validation | Haiku 4.5 | Correct |
| Compliance checking | Haiku 4.5 | Correct |
| Dataset generation | Sonnet 4.5 | Overkill -- Haiku would suffice |
| Synopsis wizard (/synopsis/parse) | Sonnet 4.5 | Should be Haiku |

The critical TODO on line 285 of the generate route is a dead conditional -- both branches return the same model. Opus on Introduction (Phase 2) and Discussion (Phase 7) is unimplemented.

---

### SSE Streaming Analysis

Streaming is properly implemented. The cancel handler and stale detection (2-minute timeout for stuck "generating" status) are good production safeguards. Prompt caching via `cache_control: { type: "ephemeral" }` on the system prompt is correctly applied for cost savings.

Issues: Phase 0 (synopsis parse) is streamed, but the response is JSON -- there's no benefit to streaming JSON incrementally to the client.

---

### Summary of Most Critical Findings

1. **No AI-powered content quality review** -- The review system is purely rule-based. There is no AI feedback on whether the content is academically sound.

2. **Opus model routing is unimplemented** -- Introduction and Discussion use the same model as everything else. The conditional is dead code.

3. **Zero conversation persistence** -- The `ai_conversations` table schema supports multi-turn, but every generation is single-turn. `messages_json` is always empty.

4. **Token budget has 4 blind spots** -- Refine, dataset generation, synopsis parsing, and auto-detect all bypass budget tracking.

5. **Word count targets are inconsistent across 3 locations** -- `prompts.ts`, `word-count-targets.ts`, and `final-qc.ts` all specify different ranges for the same phases.

6. **Previous section context is brutally truncated** -- 3,000 characters per section means the Discussion chapter has almost no knowledge of the Review of Literature it's supposed to reference.

7. **Phase 9 (References) has no AI prompt** -- Citation consolidation is apparently handled without AI guidance.

8. **Synopsis parse prompt is duplicated with different schemas** -- Two different routes parse synopses with incompatible field structures.

9. **The `COMMON_RULES` don't warn about Unicode** -- Despite Unicode being documented as a critical BibTeX-breaking issue, the AI is never told to avoid it.

10. **Input tokens are counted against output budget limits** -- The token budget system conflates input and output tokens but describes its limits as "output tokens per phase".

---

## Agent 2: Citation Pipeline Audit

**File**: `/private/tmp/claude-501/-Users-devs-Downloads-Apollo/tasks/a8dc46a.output`

---

## Complete Citation Pipeline Analysis

### 1. File-by-File Content Summary

All 13 files have been read in full. Here is a structural summary:

**Library Layer (`/Users/devs/Downloads/Apollo/apps/web/lib/citations/`):**
- **`extract-keys.ts`** -- Simple regex utility. Parses `\cite{key1,key2}` patterns from LaTeX strings, returning unique keys.
- **`crossref.ts`** -- CrossRef integration. `lookupDOI()` fetches BibTeX via content negotiation + structured metadata. `searchCrossRef()` queries by title/keywords. `stripDoiField()` removes DOI fields to avoid vancouver.bst underscore crashes. 10-second AbortController timeout on all network calls.
- **`pubmed.ts`** -- PubMed integration. `lookupPMID()` via esummary, `searchPubMed()` via esearch+esummary two-step. `pubmedArticleToBibtex()` cascades to CrossRef DOI lookup for higher-quality BibTeX. 10-second timeout.
- **`resolve.ts`** -- Core resolution engine. `resolveEntry()` follows a 4-step algorithm: DOI hint -> PMID hint -> title search with 0.85 Levenshtein similarity threshold -> Tier D fallback. `resolveAllEntries()` parses BibTeX, resolves entries in chunks of 3 concurrently.
- **`auto-resolve.ts`** -- Post-generation auto-resolver. `resolveSectionCitations()` splits AI output at `---BIBTEX---`, resolves entries, upserts to DB, then finds orphan `\cite{key}` references and attempts to resolve them too via CrossRef.
- **`pre-seed.ts`** -- Pre-seeds real PubMed references into AI prompts. Builds 2-3 search queries from thesis metadata, fetches articles within an 8-second budget, and formats BibTeX + human-readable summaries for the AI to use.
- **`audit.ts`** -- Pure function bidirectional audit. Checks forward (cite keys in sections not in DB) and reverse (DB citations not referenced in any section). Computes integrity score and identifies Tier D blockers.

**API Route Layer:**
- **`citations/route.ts`** (CRUD) -- GET lists all, POST creates via DOI/PMID/raw-BibTeX with auto-resolution.
- **`citations/[citationId]/route.ts`** -- PUT updates (including attestation which promotes D->C or to B with isbn/url evidence), DELETE removes.
- **`citations/[citationId]/re-resolve/route.ts`** -- POST re-resolves using two strategies: re-resolve from existing BibTeX, then CrossRef search by cite key pattern.
- **`citations/audit/route.ts`** -- POST fetches all sections + citations, runs the pure audit function.
- **`citations/search/route.ts`** -- GET searches CrossRef or PubMed by query string.

**UI Layer:**
- **`citation-list-panel.tsx`** -- Collapsible panel showing all citations with tier badges, audit button, re-resolve/attest/delete actions per citation. Auto-expands when Tier D citations exist.

---

### 2. Deep Analysis

#### Q: How does AI-generated text trigger citation creation?

The flow is:

1. **Generation phase**: For citation-heavy phases (2, 4, 5, 7), the system pre-seeds real PubMed references into the AI prompt via `preSeedReferences()` and `formatReferencesForPrompt()`.

2. **Post-generation save**: The full AI response (including `---BIBTEX---` trailer) is saved to `ai_generated_latex`, `latex_content`, and `rich_content_json`. Citation keys are extracted from the Tiptap parse.

3. **Auto-resolution**: `resolveSectionCitations()` is called with a **15-second timeout** (via `Promise.race`). This splits the response at `---BIBTEX---`, falls back to regex extraction if no separator found, resolves each BibTeX entry through CrossRef/PubMed (DOI -> PMID -> title search -> Tier D), upserts resolved citations to the `citations` table, and for any orphan `\cite{key}` references, creates Tier D placeholders.

4. **Same flow for refine** with a 10-second timeout.

**Key finding: Citation creation is AUTOMATIC on generation/refine.** However, the timeout means that for sections with many citations (e.g., Review of Literature with 30+ references), resolution may time out and some citations won't be resolved.

#### Q: Does the audit actually catch orphaned citations and missing BibTeX entries?

**Yes, but with a critical dependency on `section.citation_keys[]`.** The audit relies on this array being accurately maintained. The code does correctly extract keys on every save, so this is well-covered. The audit does NOT directly scan LaTeX content -- it only uses the pre-computed array.

#### Q: How are citations integrated into the compile pipeline?

BibTeX assembly in `assemble.ts` collects from TWO sources:
1. **Section BibTeX trailers** (prefers `ai_generated_latex` over `latex_content`)
2. **Citations table** (excluding Tier D)

Deduplication by cite key (last-write-wins). Tier D cite keys are identified and their `\cite{key}` commands are stripped from chapter bodies and replaced with `% UNRESOLVED` comments.

#### Q: Is re-resolve actually wired up and functional?

**Yes.** The full chain works: UI button -> API route with 3-strategy approach (re-resolve from existing BibTeX -> CrossRef search by key pattern -> manual attest message).

**Observation**: Strategy 2 uses Tier B (not A) for CrossRef search matches, which is correct. However, there's no title similarity check here unlike in `resolveEntry()`, so it could potentially assign a wrong paper to the cite key.

#### Q: What happens when CrossRef/PubMed APIs fail?

**There is NO explicit retry logic.** Every API call is wrapped in try/catch with a 10-second AbortController timeout. On failure, the resolution algorithm continues to the next strategy (DOI fails -> try PMID -> try title search -> fall back to Tier D). **Missing**: No exponential backoff, no retry queue, no circuit breaker.

#### Q: Is there a gap between citation keys in generated LaTeX and actual citation DB records?

**Yes, and this is by design** through the "Tier D placeholder" mechanism. **However, there is a real bug**: if auto-resolution times out before creating Tier D placeholders for orphan keys, those `\cite{}` commands persist through to compilation and produce BibTeX warnings. `stripTierDCitations` only removes keys that are in the `citations` table as Tier D. A key with NO DB record at all would survive as a `\cite{key}` in the chapter body.

#### Q: How does pre-seed work?

`preSeedReferences()` builds 2-3 PubMed queries from thesis metadata, fetches articles within an 8-second budget, deduplicates by PMID, converts to BibTeX, and formats for the AI prompt. Pre-seeded references are NOT automatically saved to the `citations` table -- they're only included in the AI prompt. If the AI uses them and includes them in the trailer, THEN they get resolved and upserted.

#### Q: What's the UX flow for Tier B/C/D citations?

- **Tier D**: Auto-expands panel, amber warning box, three action buttons (Re-resolve, Attest, Delete). Blocks Final QC only. Stripped during compilation.
- **Tier C**: Created when user attests a Tier D without external evidence. Included in compilation.
- **Tier B**: Created when user attests with isbn/url evidence, or by re-resolve CrossRef match. Included in compilation.
- **Tier A**: Created when DOI or PMID lookup succeeds. Has `verified_at` timestamp. The gold standard.

---

### 3. Summary of Identified Issues

**Critical Bug -- Orphan keys without DB records bypass Tier D stripping:** If `resolveSectionCitations()` times out before creating Tier D placeholders for orphan cite keys, those `\cite{key}` commands persist in the compiled output and produce "undefined citation" BibTeX warnings. The fix would be to also strip cite keys that exist in `section.citation_keys[]` but have NO matching record in the citations table at all.

**Medium -- No retry logic for API failures:** All CrossRef/PubMed calls are one-shot with timeout. A transient network failure during generation permanently loses resolution for that batch.

**Medium -- Re-resolve Strategy 2 lacks title verification:** The re-resolve route searches CrossRef by key pattern ("kumar 2023") and takes the first result with a DOI, without checking title similarity. Could assign the wrong paper.

**Low -- Pre-seeded references not persisted to DB:** If the AI uses a pre-seeded reference but doesn't include it in the trailer (possible if truncated by token limits), the cite key will become a Tier D orphan or go missing entirely.

**Low -- Timeout budget mismatch:** Generation has a 15-second timeout for resolution, but ROL phase has up to 30 pre-seeded refs and potentially 30+ AI-generated refs. Each ref requires up to 3 network calls with concurrency limited to 3. This could easily exceed 15 seconds for 30+ citations.

---

## Agent 3: LaTeX Pipeline Audit

**File**: `/private/tmp/claude-501/-Users-devs-Downloads-Apollo/tasks/a54e776.output`

---

# Complete LaTeX Processing Pipeline Analysis

## 2. FULL DATA FLOW: End-to-End Transformation Chain

### Step 1: AI Generates LaTeX
The AI generates raw LaTeX with a `---BIBTEX---` trailer. Stored in three columns: `ai_generated_latex` (preserved as-is), `latex_content` (working copy), `rich_content_json` (Tiptap JSON AST).

### Step 2: LaTeX to Tiptap (for the rich-text editor)
`latexToTiptap()` converts raw LaTeX to Tiptap JSON via preprocessing (strip trailer, remove `\label{}`, `\needspace{}`, convert markdown headings), block tokenisation, and inline parsing (bold, italic, cite commands, unescape special chars).

### Step 3: User Edits in Tiptap Editor

### Step 4: Tiptap to LaTeX (for compilation)
`tiptapToLatex()` converts back via tree walking, text escaping through `escapeLatex()` (which calls `normaliseUnicode()`), citation passthrough, and code block raw passthrough.

### Step 5: Assembly
`assembleThesisContent()` builds the complete thesis with metadata, front matter, chapters (primary path: Tiptap->LaTeX; fallback: full round-trip to sanitise), BibTeX collection, and post-processing.

### Step 6: Validation
Pre-flight (`preflightChapter()`) is deterministic and blocks on errors. AI validation (`aiValidateChapters()`) uses Haiku and is non-blocking.

### Step 7: Compilation
Three modes: `docker`, `local`, `mock`. 4-pass cycle: pdflatex -> bibtex -> pdflatex -> pdflatex.

### Step 8: Docker Compilation Script
Copies files, runs 4-pass, applies watermark for sandbox projects via Ghostscript.

### Step 9: PDF Serving
Reads from `compilations.pdf_url` (local disk path), falls back to deterministic path.

---

## 3. ROUND-TRIP ANALYSIS: Is LaTeX to Tiptap to LaTeX LOSSY?

**YES, the round-trip is lossy.** Here is what gets lost or corrupted:

### Definitively Lost

| Element | What Happens |
|---------|-------------|
| `\label{...}` | Stripped in preprocessing. Never restored. |
| `\needspace{...}` | Stripped in preprocessing. Never restored. |
| `\usepackage{...}` | Stripped in preprocessing. Never restored. |
| Full-line comments (`%...`) | Stripped in preprocessing. Never restored. |
| `---BIBTEX---` trailer | Stripped in preprocessing. Never restored in body. |
| Paragraph spacing/layout | Multiple blank lines collapsed |
| Specific whitespace/indentation | All normalised |

### Potentially Corrupted

| Element | What Happens |
|---------|-------------|
| **Unrecognised LaTeX commands** (`\url{}`, `\href{}`, `\textsc{}`, `\footnote{}`) | Garbled -- backslash consumed as plain text |
| **`\textsuperscript{}` / `\textsubscript{}`** | NOT in `FORMAT_COMMANDS`. Same garbling |
| **`\footnote{}`** | Not handled. Content lost/garbled |
| **Nested environments inside paragraphs** | Not properly detected as block boundary |
| **Multi-line headings** | Regex requires single line |
| **`\vspace{}`, `\hspace{}`, `\noindent`** | Not handled |
| **Unicode characters that were originally LaTeX commands** | Various corruption scenarios |

### What Survives Cleanly
Section headings, bold/italic/code/underline, `\cite{}`, bullet/numbered lists, blockquotes, complex environments as codeBlocks, basic paragraph text.

---

## 4. SIMPLER ALTERNATIVES TO THE ROUND-TRIP

**Option B: Selective Sanitisation Without Round-Trip** -- Apply targeted regex transformations directly on LaTeX instead of round-tripping through Tiptap. This preserves `\label{}`, `\footnote{}`, `\url{}`, and every other LaTeX command.

**Recommendation**: Option B or C. The current round-trip is the most fragile path in the system and destroys LaTeX semantics.

---

## 5. HOW assemble.ts BUILDS THE FINAL DOCUMENT

**Missing from PHASE_CHAPTER_MAP**: Phase 0 (no content), Phase 6a/6b conflated, Phase 9 (handled via BibTeX), Phase 11 (no content).

**Issue**: A `draft` section WOULD be used if no approved/review section exists, which contradicts the Supabase query in the compile route that filters `.in("status", ["approved", "review"])`.

---

## 7. PACKAGE ANALYSIS

**Issue**: `mathrsfs` is NOT in the Dockerfile's `tlmgr install` list and is NOT part of scheme-small. If AI-generated content uses `\mathscr{}`, compilation will fail.

---

## 9. MATH NOTATION SUPPORT

**Critical concern**: The `escapeLatex()` function escapes `$`, `\`, `{`, `}`, `^`, `_`, `~`, `#`, `%`, `&`. If math notation appears in a paragraph (text node), it will be destroyed:
- `$p < 0.05$` becomes `\$p < 0.05\$` -- literal dollar signs, not math mode

This is a significant limitation for medical statistics (p-values, confidence intervals, chi-squared, etc.).

---

## 11. WATERMARK FOR SANDBOX PROJECTS

**Issue in compile.ts Local flow**: The local compile mode does NOT apply any watermark. Sandbox projects compiled locally will have no watermark.

---

## 12. COMPILE ERROR BUDGET ENFORCEMENT

Per `CLAUDE.md`: "Compile warnings budget: <=20 tolerated". However, this budget is NOT enforced anywhere in code.

---

## 15. ADDITIONAL CRITICAL FINDINGS

### A. Abbreviations Are Never Injected
`assemble.ts` NEVER calls `generateAbbreviationsLatex()`. The abbreviations environment is never populated.

### B. front-matter.ts Is Never Used for Compilation
`generateFrontMatterLatex()` and `generateAcknowledgements()` appear to be dead code for the compile pipeline.

### C. PDF Storage Is Ephemeral
PDFs stored in `/tmp` are lost on reboot. No R2 integration yet.

### D. Concurrent Compilation Race Condition
TOCTOU gap between the check and the insert for concurrent compiles.

### F. The Brace-Checking Logic Has a Subtle Bug
Fails for `\\{` (double backslash followed by brace).

### G. The `\cite{}` Passthrough Has a Strict Regex
Requires ENTIRE text to be exactly `\cite{...}`. Multi-citation nodes like `\cite{a}\cite{b}` will fail.

---

## SUMMARY OF CRITICAL ISSUES (Ranked by Severity)

1. **Inline math destroyed by round-trip** -- `$p < 0.05$` in paragraphs becomes `\$p < 0.05\$`. Medical theses are full of p-values and statistical notation.

2. **`mathrsfs` package not installed in Docker** -- If AI uses `\mathscr{}`, compilation fails.

3. **Phase 10 (Appendices) content never rendered** -- Assembly generates the file but template never `\input`s it.

4. **Abbreviations never injected** -- The abbreviations generator exists but is never called during assembly.

5. **`\footnote{}`, `\url{}`, `\textsuperscript{}` destroyed by round-trip** -- These are common in academic writing.

6. **PDF storage ephemeral** -- PDFs stored in `/tmp` are lost on reboot. No R2 integration yet.

7. **Local compile mode ignores watermark** -- Sandbox projects compiled locally have no watermark.

8. **Warning budget not enforced** -- The 20-warning limit is documentation only.

9. **Brace-checking logic incorrect for `\\{`** -- Edge case but could cause silent corruption.

10. **`front-matter.ts` is dead code** -- Never called in the compile pipeline.

---

## Agent 4: R Analysis & Figure Pipeline Audit

**File**: `/private/tmp/claude-501/-Users-devs-Downloads-Apollo/tasks/a5afa5e.output`

---

## Complete Analysis: R Analysis + Figure Pipeline

### R ANALYSIS PIPELINE

### Endpoints Implemented in plumber.R

9 endpoints plus health check:

| # | Endpoint | Figures Produced | Table LaTeX |
|---|----------|-----------------|-------------|
| 1 | `POST /descriptive` | **None** (empty list) | Yes (Table 1) |
| 2 | `POST /chi-square` | 1 PDF (bar or heatmap) | Yes |
| 3 | `POST /t-test` | 1 PDF (box, violin, or bar) | Yes |
| 4 | `POST /correlation` | 1 PDF (scatter + regression line) | Yes |
| 5 | `POST /survival` | 1 PDF (KM curve + risk table) | Yes |
| 6 | `POST /roc` | 1 PDF (ROC curve) | Yes |
| 7 | `POST /logistic` | 1 PDF (forest plot of ORs) or 0 if only intercept | Yes |
| 8 | `POST /kruskal` | 1 PDF (boxplot) | Yes |
| 9 | `POST /meta-analysis` | **2 PDFs** (forest plot + funnel plot) | Yes |

All Sprint 7 types (descriptive, chi-square, t-test, survival) and Sprint 8 types (ROC, logistic, Kruskal-Wallis, meta-analysis) are fully implemented. Correlation is a bonus type.

### Shapiro-Wilk Normality Testing

**Yes, implemented** for T-test (tests each group separately, falls back to Wilcoxon) and Correlation (tests both variables, falls back to Spearman).

### Error Handling

Every R endpoint wrapped in `tryCatch()`. Client-side checks for error field. `executeAnalysis()` catches all errors and writes them to the database. Error messages from R do surface to the user through the chain. Additional safety: `setTimeLimit()` per endpoint, client-side `AbortController` timeout, `RPlumberError` wraps all error types.

---

## FIGURE PIPELINE

### Where Figures Are Stored

1. **Database (`figures` table)**: Metadata record with `file_url`, `caption`, `label`, `format`, `dpi`, `source_code`, `source_tool`, `figure_type`.
2. **Local filesystem (tmpdir)**: Binary PDF files at `os.tmpdir()/apollo-figures/{project_id}/{analysis_id}/{filename}`.

**R2 is NOT yet wired up for figures.** Only tmpdir path is implemented.

### How Figures Get From R to Storage to LaTeX

1. R generates base64 PDF at 300 DPI
2. Node decodes and writes to disk
3. Figure record inserted into DB
4. Phase 6 generation: route fetches analyses and figures, appends to AI prompt
5. LaTeX compile: route fetches figures, resolves disk paths, builds figureFiles map
6. Files copied into Docker compile working directory

### Can Users Download Individual Figures?

**Not directly.** The figure gallery shows placeholders for PDF figures. There is no PDF preview or download link. **This is a gap.**

---

## INTEGRATION

### Analysis Wizard to Results Section (Phase 6b)

The connection is **indirect through the database**. User runs analyses, they complete and store results. When user triggers Phase 6 generation, the route fetches all completed analyses and figures and appends as context to the AI prompt. **Results are NOT automatically incorporated** -- user must explicitly trigger generation.

### Inngest Flow

Full async flow: API creates "pending" record -> semaphore acquisition -> Inngest dispatches or inline fallback -> `executeAnalysis()` runs -> status updates -> semaphore released.

### Semaphore Details

In-memory admission controller: 3 total units, compile costs 2, analysis costs 1, max 2 concurrent analyses, max 2 per user, queue depth 5. **Not durable across restarts.**

---

## GAPS AND ISSUES IDENTIFIED

1. **R2 storage not wired for figures**: Figures written to `os.tmpdir()` which is ephemeral. Server restart loses all figure files. The `file_url` in DB becomes dangling.

2. **PDF figure preview impossible in UI**: Figure gallery cannot display PDF figures. Shows placeholder icon.

3. **No figure download endpoint**: No API route serves figure binary data. The `file_url` is a relative path, not a fetchable URL.

4. **Descriptive analysis has no figure**: Arguably correct (Table 1 is a table), but a histogram/bar chart is often included alongside Table 1 in medical theses.

5. **No minimum figure/table enforcement**: No validation gate for minimum requirements.

6. **Subfigure support absent**: Meta-analysis produces two separate figures but no mechanism to combine them into a LaTeX subfigure environment.

7. **In-memory semaphore**: Not durable across restarts. The `resolve` callbacks on queued entries are no-ops when using the synchronous `tryAcquire` path, meaning queued jobs never actually get promoted -- they just get rejected. **This is a bug**: queue entries are created but never consumed.

8. **Colour scheme and chart_type not exposed in UI**: The R code and TypeScript schemas support these parameters, but the analysis wizard UI does not expose them to the user.

---

## Agent 5: Phase Transitions Audit

**File**: `/private/tmp/claude-501/-Users-devs-Downloads-Apollo/tasks/a77af11.output`

---

## Complete Phase-to-Phase Pipeline Analysis

### Phase Definitions (constants.ts)

12 phases (0-11), with Phase 0-1 available without a licence and Phases 2-11 requiring one.

**CRITICAL GAP -- Phase 6a/6b Split is Missing**: The PLAN.md calls for Phase 6a (Dataset) and Phase 6b (Results) as separate phases. The actual constants collapse them into a single Phase 6 "Results". The `AI_GENERATABLE_PHASES` set includes `6`, meaning the user can click "Generate with AI" without uploading a dataset.

### Word Count Targets Inconsistency

`word-count-targets.ts` and `final-qc.ts` have **completely different** hardcoded word count targets:

| Phase | word-count-targets.ts | final-qc.ts |
|-------|----------------------|-------------|
| 2 | 750-1,200 | 500-750 |
| 3 | 200-500 | 150-200 |
| 4 | 3,500-4,500 | 2,500-3,500 |
| 5 | 1,500-3,000 | 1,500-2,500 |
| 6 | 1,500-3,000 | 1,500-2,500 |
| 7 | 2,000-3,500 | 2,000-2,500 |
| 8 | 400-800 | 500-750 |

### Phase Transition Logic (transitions.ts)

**BUG -- canAdvancePhase section status check is bypassed**: The approve route always passes the string literal `"approved"`, not the section's actual status. The `canAdvancePhase` guard is architecturally dead code for the status check.

### Generation Route Gaps

1. **No licence gate on generation**: Sandbox projects can generate Phase 2+ content freely. Licence only blocks approval/advancement.
2. **Phase 9, 10, 11 not handled by generate**: Only Phases 0-8 are supported.
3. **No phase sequence enforcement**: Can generate content for any phase regardless of current phase. Only approval enforces sequence.
4. **Model routing TODO**: Dead conditional -- both branches return Sonnet.

### Approval Route Issues

1. **No QC pass verification before Phase 11 approval**: Users can approve Phase 11 and complete the thesis even with blocking QC failures.
2. **Phase 1->2 identity binding NOT implemented**: Licence-to-user binding is not in the code.
3. **Phase 6a->6b dataset requirement NOT enforced**.
4. **Inngest creates duplicate sections**: The Inngest workflow creates empty "draft" sections that **overwrite** the auto-generated content from the approve route for Phases 1, 9, and 11. **This is a data loss bug.**
5. **`phases_completed` array can have duplicates**: No deduplication check.

### Refine Route Issues

- **No limit on refine calls**: No rate limit or iteration counter. Token budget is bypassed.
- **BUG -- Refine can un-approve sections**: Refining an approved section changes status to "review" without rolling back the project's phase tracking, creating inconsistent state.

### Final QC Issues

- `overallPass` is never checked during Phase 11 approval.
- Undefined references check passes when no compile log exists (should probably fail or warn).
- QC report stored as JSON in `latex_content`, overloading the column's semantic meaning.

### QC Fix Issues

- **auto-fix-spelling doesn't update `rich_content_json`**: Fix is invisible in rich text mode.
- **expand-section is a placeholder only**.
- **Duplicated AMERICAN_TO_BRITISH dictionary** across three files.

### Workspace Issues

1. **Refine SSE stream consumed silently**: No streaming progress shown to user during refine.
2. **Auto-compile on every action**: Could queue compiles unnecessarily.
3. **Citation search onInsert ignores citeKey**: Doesn't insert into editor.
4. **Phase 10 generate button shows but likely fails**.
5. **No QC trigger button in workspace UI** for Phase 11.

---

### Summary of Critical Issues

**Severity: High**

1. **Inngest overwrites auto-generated content**: Data loss bug for phases 1, 9, and 11.
2. **Phase 11 approval skips QC verification**: Users can complete thesis with blocking QC failures.
3. **No QC trigger in workspace UI**: QC route exists but isn't wired to UI.
4. **Refine route bypasses token budget**: Unlimited token usage.
5. **Word count targets mismatch**: Different ranges in two locations.

**Severity: Medium**

6. **No dataset/analysis requirement for Phase 6**.
7. **No Phase 1->2 identity binding**.
8. **Refine can un-approve sections** creating inconsistent state.
9. **Spelling fix doesn't update rich_content_json**.
10. **Generate route lacks phase sequence enforcement**.
11. **canAdvancePhase section status check is dead code**.

**Severity: Low**

12. Duplicated AMERICAN_TO_BRITISH dictionary.
13. Phase 10 generate button shows but fails.
14. Compile triggered on every save.
15. `phases_completed` can have duplicates.
16. Undefined references check passes when no compile log exists.
17. ThesisCompletion hardcodes "12/12".</result>
<usage>total_tokens: 94083
tool_uses: 25
duration_ms: 321866</usage>
</task-notification>
Full transcript available at: /private/tmp/claude-501/-Users-devs-Downloads-Apollo/tasks/a77f0e4.output

---

[Request interrupted by user]

---

IF getting the full files are not possible to find, then write Review I, Review III now, and then we can rerun the analysis for part II. Ignore if done.

---

Now lets proceed to part III, an overall analysis with regards to security and monetization gating. Go through the entire codebase, and the finance piepline meticulously and find any mistakes, and lacunae.

---

[Request interrupted by user]

---

Now lets proceed to part IV, an overall analysis with regards to security and monetization          gating. Go through the entire codebase, and the finance piepline meticulously and find any          mistakes, and lacunae. Also give your own recommendations on all fronts across the width of the  codebase. Be thoufough and thoughtfull. Think ultra hard.

---

This session is being continued from a previous conversation that ran out of context. The summary below covers the earlier portion of the conversation.

Analysis:
Let me chronologically analyze the entire conversation:

1. **Session Start**: This is a continuation from a previous conversation that ran out of context. The summary covers Parts I, II, and III of a gap analysis of the Apollo thesis generation platform.

2. **Previous Session Work**: 
   - Part I: Infrastructure-level gap analysis (completed and delivered)
   - Part II: Deep-dive business logic audit using 5 parallel agents (completed and delivered)
   - Part III: Frontend-backend linkage audit using 4 parallel agents (agents still running at session start)

3. **Current Session Start**: Retrieved outputs from remaining Part III agents (a230c7b, a0d4277, a2ae992) - all completed. Agent a990a75 (API routes audit) was already complete from previous session.

4. **Part III Report Delivered**: Synthesized findings from all 4 agents into comprehensive Part III report covering:
   - 38 wired + 11 unwired API routes
   - PLAN.md requirements coverage (95%)
   - Workspace component deep audit (17 child components)
   - Phase 11 Final QC critical missing piece
   - Dead/deprecated code
   - SSE streaming verification
   - Combined priority matrix

5. **Multiple task notifications**: Agents a0d4277, a2ae992, a230c7b completed - all findings already incorporated.

6. **User Request**: "Write down parts I, II and III in full in /docs/REVIEW.md"

7. **Data Recovery**: Launched 2 background agents:
   - ab96c09: Extract Part I from conversation transcript (completed - found full Part I on line 93 of JSONL)
   - a77f0e4: Extract Part II agent findings from 5 agent output files (completed - got all 5 sub-agent reports)

8. **REVIEW.md Writing**: Wrote complete file to `/Users/devs/Downloads/Apollo/docs/REVIEW.md` containing all three parts plus combined priority matrix. File was written twice (second write was the complete/clean version).

9. **User's Final Request**: "Now lets proceed to part IV, an overall analysis with regards to security and monetization gating. Go through the entire codebase, and the finance pipeline meticulously and find any mistakes, and lacunae. Also give your own recommendations on all fronts across the width of the codebase. Be thorough and thoughtful. Think ultra hard."

10. **Part IV Launch**: Launched 5 parallel background agents:
    - a100e91: Auth & security posture audit
    - a87491c: Payment & licence pipeline audit
    - aff159f: RLS policies & data isolation audit
    - a99d733: Data privacy & DPDP Act compliance audit
    - afd4aef: Architecture recommendations deep analysis

All 5 agents are currently running (progress notifications received showing active work).

Key files referenced/created:
- `/Users/devs/Downloads/Apollo/docs/REVIEW.md` - Created with complete 3-part review
- Multiple agent output files in `/private/tmp/claude-501/-Users-devs-Downloads-Apollo/tasks/`

No code changes were made to application files - this is purely a research/audit session.

Summary:
1. Primary Request and Intent:
   The user is conducting a comprehensive multi-part gap analysis of the Apollo thesis generation platform. The conversation spans four review passes:
   
   - **Part I** (completed in prior session): Infrastructure-level gap analysis
   - **Part II** (completed in prior session): Deep-dive business logic audit of all pipelines
   - **Part III** (completed this session): Frontend-backend linkage and wiring audit
   - **Part IV** (currently in progress): Security, monetization gating, and architectural recommendations
   
   The user also requested all three completed parts be written to `/docs/REVIEW.md`, which was done.
   
   The user's most recent request: "Now lets proceed to part IV, an overall analysis with regards to security and monetization gating. Go through the entire codebase, and the finance pipeline meticulously and find any mistakes, and lacunae. Also give your own recommendations on all fronts across the width of the codebase. Be thorough and thoughtful. Think ultra hard."

2. Key Technical Concepts:
   - **Apollo Platform**: Next.js 15 App Router, TypeScript, Tailwind CSS, Clerk auth, Supabase PostgreSQL, Claude AI (Sonnet 4.5), Docker containers for LaTeX/R compute, Inngest workflows
   - **GOLD Standard 12-Phase Pipeline**: Phases 0-11 for thesis generation with human-in-the-loop approval gates
   - **LaTeX Round-Trip Problem**: AI generates LaTeX  `latexToTiptap()` (lossy)  rich editor  `tiptapToLatex()` (lossy)  compile. Modified Option C recommended (CodeMirror 6 as canonical editor)
   - **Citation Provenance Tiers**: A (DOI/PMID verified), B (ISBN/URL confirmed), C (manual attestation), D (unresolvable)
   - **Payment System**: Razorpay (INR) + Stripe (USD) with licence-based gating
   - **Semaphore Admission Control**: In-memory, 3 units max (compile=2, analysis=1)
   - **Docker Isolation**: LaTeX and R Plumber containers with security constraints
   - **SSE Streaming**: For AI generation and refinement via `useSSE()` hook

3. Files and Code Sections:
   - `/Users/devs/Downloads/Apollo/docs/REVIEW.md`
     - **Created** with complete 3-part review (~1,200 lines)
     - Contains Parts I (infrastructure), II (business logic - 47 issues), III (frontend wiring)
     - Combined priority matrix: 16 P0, 23 P1, 23 P2
   
   - `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/compile/route.ts`
     - Read in system context - compile route with semaphore, pre-flight validation, AI validation, Docker compile
   
   - `/Users/devs/Downloads/Apollo/apps/web/lib/latex/compile.ts`
     - Read in system context - three compile modes (docker, local, mock), PDF persistence to tmpdir
   
   - Agent output files (all read for synthesis):
     - `REDACTED.output` - Frontend components audit (67 components, all wired)
     - `/private/tmp/claude-501/-Users-devs-Downloads-Apollo/tasks/a0d4277.output` - PLAN.md requirements (95% complete)
     - `/private/tmp/claude-501/-Users-devs-Downloads-Apollo/tasks/a2ae992.output` - Workspace wiring (17 child components, Phase 11 gap)
     - `/private/tmp/claude-501/-Users-devs-Downloads-Apollo/tasks/a990a75.output` - API routes (49 total, 11 unwired)
     - `/private/tmp/claude-501/-Users-devs-Downloads-Apollo/tasks/a77f0e4.output` - Part II agent findings extraction
     - `/private/tmp/claude-501/-Users-devs-Downloads-Apollo/tasks/ab96c09.output` - Part I report extraction from transcript

4. Errors and fixes:
   - **Agent output files too large to read directly**: The JSONL output files exceeded the 25,000 token read limit. Fixed by using Grep to search for key content within the files.
   - **Part I and Part II text lost to context compaction**: The reports delivered in earlier sessions were compacted. Fixed by launching 2 recovery agents (ab96c09 for Part I transcript extraction, a77f0e4 for Part II agent output extraction).
   - **First REVIEW.md write was incomplete**: Initial write used em-dashes () but then a second complete write replaced it with the full, clean version using proper formatting.

5. Problem Solving:
   - Successfully recovered all three parts of the review from compacted context using background agents
   - Synthesized Part III from 4 parallel agent outputs into a coherent report
   - Wrote complete REVIEW.md with all parts and combined priority matrix
   - Launched Part IV with 5 parallel agents covering security, payment, RLS, privacy, and architecture

6. All user messages:
   - (Continuation prompt): "Please continue the conversation from where we left off without asking the user any further questions."
   - Task notification: Agent a0d4277 completed
   - User response to Part III: (acknowledged incorporation)
   - Task notification: Agent a2ae992 completed
   - User response: (acknowledged incorporation)
   - Task notification: Agent a230c7b completed
   - User response: (acknowledged incorporation)
   - **"Write down parts I,II and III in full in /docs/REVIEW.md"**
   - Task notification: Agent ab96c09 completed (Part I extraction)
   - Task notification: Agent a77f0e4 completed (Part II extraction)
   - **"IF getting the full files are not possible to find, then write Review I, Review III now, and then we can rerun the analysis for part II. Ignore if done."** (user was concerned about data recovery - but it was already done)
   - **"Now lets proceed to part IV, an overall analysis with regards to security and monetization gating. Go through the entire codebase, and the finance pipeline meticulously and find any mistakes, and lacunae. Also give your own recommendations on all fronts across the width of the codebase. Be thorough and thoughtful. Think ultra hard."**

7. Pending Tasks:
   - **Part IV synthesis**: 5 background agents are currently running for the Part IV audit:
     - a100e91: Auth & security posture (52 tools used, still running)
     - a87491c: Payment & licence pipeline (37 tools used, still running)
     - aff159f: RLS policies & data isolation (32 tools used, still running)
     - a99d733: Data privacy & DPDP compliance (20 tools used, still running)
     - afd4aef: Architecture recommendations (6 tools used, still running)
   - Once all 5 agents complete, synthesize their findings into a Part IV report
   - Append Part IV to `/docs/REVIEW.md` (or write as separate section)

8. Current Work:
   Waiting for 5 Part IV background agents to complete their deep audits of:
   1. Authentication, authorization, IDOR, input validation, CSRF, rate limiting, file upload security, Docker container security
   2. Payment flow end-to-end (Razorpay/Stripe), licence provisioning, licence gating enforcement, bypass vectors, export gating
   3. RLS policies, Supabase admin client usage, data isolation between users, migration files
   4. PII data inventory, AI data handling, third-party data sharing, DPDP Act compliance, medical data handling
   5. Scalability architecture, reliability/error recovery, performance, DX, UX, business model, technical debt

9. Optional Next Step:
   Wait for all 5 Part IV agents to complete, then synthesize their findings into a comprehensive Part IV report covering security posture, monetization/licence gating gaps, data privacy compliance, and architectural recommendations. The report should be appended to `/docs/REVIEW.md` as "Part IV: Security, Monetization & Architectural Recommendations". 
   
   User's exact request: "Now lets proceed to part IV, an overall analysis with regards to security and monetization gating. Go through the entire codebase, and the finance pipeline meticulously and find any mistakes, and lacunae. Also give your own recommendations on all fronts across the width of the codebase. Be thorough and thoughtful. Think ultra hard."

If you need specific details from before compaction (like exact code snippets, error messages, or content you generated), read the full transcript at: /Users/devs/.REDACTED.jsonl
Please continue the conversation from where we left off without asking the user any further questions. Continue with the last task that you were asked to work on.

---

This session is being continued from a previous conversation that ran out of context. The summary below covers the earlier portion of the conversation.

Analysis:
Let me chronologically analyze the conversation:

1. **Session Start**: This is a continuation from a previous conversation that ran out of context. The summary covers Parts I, II, III, and now Part IV of a comprehensive gap analysis of the Apollo thesis generation platform.

2. **Previous Session Work (summarized)**:
   - Part I: Infrastructure-level gap analysis (completed)
   - Part II: Deep-dive business logic audit (completed)
   - Part III: Frontend-backend linkage audit (completed)
   - All three parts written to `/docs/REVIEW.md`
   - Part IV: 5 background agents launched for security, monetization, RLS, privacy, and architecture audits

3. **Current Session Start**: The user asked to continue from where they left off. I checked the status of the 5 Part IV background agents (a100e91, a87491c, aff159f, a99d733, afd4aef) - all were still running.

4. **Agent Completion**: I waited for all 5 agents to complete using TaskOutput with block=true:
   - a100e91 (Auth & Security): Completed - 3 Critical, 6 High, 8 Medium, 5 Low
   - a87491c (Payment & Licence Pipeline): Completed - 2 Critical, 8 High, 9 Medium, 3 Low (22 total findings)
   - aff159f (RLS & Data Isolation): Completed - 8 Critical, 3 High, 4 Medium, 2 Low
   - a99d733 (Data Privacy & DPDP): Completed - 9 Critical, 10 High, 7 Medium
   - afd4aef (Architecture Recommendations): Completed - comprehensive recommendations

5. **REVIEW.md Update**: Read the current file (739 lines), found the ending, and appended Part IV covering:
   - IV-A: Authentication & Security Posture
   - IV-B: Payment & Licence Pipeline
   - IV-C: RLS Policies & Data Isolation
   - IV-D: Data Privacy & DPDP Act Compliance
   - IV-E: Architecture & Reliability Recommendations
   - IV Combined: Priority Matrix (19 Critical, 27 High, 28 Medium, 10 Low)
   - Recommended Fix Order (30 items across 3 milestones)

6. **Task notification**: Agent aff159f completed (RLS audit) - findings already incorporated into the review.

7. The user's final message is asking for a summary of the conversation.

Key files:
- `/docs/REVIEW.md` - The main deliverable, now containing all 4 parts
- Multiple agent output files read for synthesis

No code changes were made to application files - this is purely a research/audit session.

Summary:
1. Primary Request and Intent:
   The user is conducting a comprehensive multi-part gap analysis of the Apollo thesis generation platform. This session continues from a previous conversation that ran out of context. The work spans four review passes:
   
   - **Part I** (completed in prior sessions): Infrastructure-level gap analysis
   - **Part II** (completed in prior sessions): Deep-dive business logic audit of all pipelines
   - **Part III** (completed in prior sessions): Frontend-backend linkage and wiring audit
   - **Part IV** (completed this session): Security, monetization gating, data privacy (DPDP Act), and architectural recommendations
   
   All four parts were written to `/docs/REVIEW.md`. The user's most recent explicit request was: "Now lets proceed to part IV, an overall analysis with regards to security and monetization gating. Go through the entire codebase, and the finance pipeline meticulously and find any mistakes, and lacunae. Also give your own recommendations on all fronts across the width of the codebase. Be thorough and thoughtful. Think ultra hard."

2. Key Technical Concepts:
   - **Apollo Platform**: Next.js 15 App Router, TypeScript, Tailwind CSS, Clerk auth, Supabase PostgreSQL with RLS, Claude AI (Sonnet 4.5), Docker containers for LaTeX/R compute, Inngest workflows (configured but unused)
   - **GOLD Standard 12-Phase Pipeline**: Phases 0-11 for thesis generation with human-in-the-loop approval gates
   - **Dual-layer authorization**: RLS policies at database level + application-level ownership checks via `.eq("user_id", authResult.user.id)`
   - **Admin vs Server Supabase clients**: `createAdminSupabaseClient()` bypasses RLS (used in ~35 routes), `createServerSupabaseClient()` respects RLS (used in only 5 routes)
   - **Payment pipeline**: Razorpay (INR) + Stripe (USD), webhook-based licence provisioning, idempotency via `processed_webhooks` table
   - **IDOR vulnerabilities**: Project CRUD routes, share token listing, upload signed-url lack ownership verification
   - **DPDP Act compliance**: India's data protection law requiring consent, erasure rights, data retention policies
   - **PII redaction**: `redactPII()` covers phone, Aadhaar, email, PAN but NOT metadata (names, registration numbers) sent to Claude API
   - **Licence gating gaps**: Generate and refine routes have no licence check  sandbox users can consume AI tokens for free
   - **In-memory state**: Semaphore and rate limiter use `Map`  reset on deploy, not shared across instances

3. Files and Code Sections:
   - `/Users/devs/Downloads/Apollo/docs/REVIEW.md`
     - **Central deliverable file** containing the complete 4-part review
     - Part IV appended this session by replacing the closing line with ~400 lines of new content
     - Contains: IV-A (Auth & Security), IV-B (Payment & Licence Pipeline), IV-C (RLS & Data Isolation), IV-D (Data Privacy & DPDP), IV-E (Architecture Recommendations), priority matrix (19 Critical, 27 High, 28 Medium, 10 Low), and 30-item prioritised fix order
   
   - `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/compile/route.ts` (read in system context)
     - Compile route with semaphore admission control, pre-flight validation, AI validation, Docker compile
     - Key finding: no licence check (sandbox users can compile)
   
   - `/Users/devs/Downloads/Apollo/apps/web/lib/latex/compile.ts` (read in system context)
     - Three compile modes: docker, local, mock
     - PDF persisted to `/tmp` (lost on deploy  P0 issue)
   
   - Agent output files (all read for synthesis):
     - `/private/tmp/claude-501/-Users-devs-Downloads-Apollo/tasks/a100e91.output`  Auth & Security audit (IDOR, CSRF, rate limiting, file upload, Docker security)
     - `REDACTED.output`  Payment & Licence pipeline (22 findings: race conditions, missing gates, pricing inconsistency)
     - `/private/tmp/claude-501/-Users-devs-Downloads-Apollo/tasks/aff159f.output`  RLS & Data Isolation (role escalation, missing RLS policies, inconsistent client usage)
     - `/private/tmp/claude-501/-Users-devs-Downloads-Apollo/tasks/a99d733.output`  DPDP compliance (PII in AI prompts, no privacy policy, no account deletion)
     - `/private/tmp/claude-501/-Users-devs-Downloads-Apollo/tasks/afd4aef.output`  Architecture recommendations (Redis, R2, Inngest, bundle size, business model)

4. Errors and fixes:
   - No code errors in this session  this was purely a research/audit session
   - The 5 background agents from the previous session were still running when this session started; waited for completion using `TaskOutput` with `block=true` and 300000ms timeout
   - Agent outputs were truncated in TaskOutput results but contained the full report text visible in the output

5. Problem Solving:
   - Successfully retrieved all 5 Part IV agent outputs after they completed
   - Synthesized findings from 5 separate agent reports into a unified Part IV with deduplicated findings, consistent severity ratings, and a combined priority matrix
   - Appended Part IV to the existing 739-line REVIEW.md by editing the closing line
   - Total review now covers 136 unique findings across all four parts

6. All user messages:
   - "Please continue the conversation from where we left off without asking the user any further questions. Continue with the last task that you were asked to work on." (session continuation prompt)
   - (Task notification): Agent aff159f completed  RLS & Data Isolation audit (findings already incorporated)

7. Pending Tasks:
   - No explicit pending tasks. The Part IV review is complete and written to `/docs/REVIEW.md`.
   - The user has not yet requested any fixes to be implemented from the review findings.

8. Current Work:
   Part IV has been completed and appended to `/docs/REVIEW.md`. The complete review document now contains:
   - Part I: Infrastructure-Level Gap Analysis
   - Part II: Business Logic Pipeline Audit (47 issues)
   - Part III: Frontend-Backend Linkage Audit
   - Part IV: Security, Monetization & Architectural Recommendations (19 Critical, 27 High, 28 Medium, 10 Low)
   - Combined Priority Matrix across all 4 parts (136 total unique findings)
   - 30-item prioritised fix order across 3 milestones (Week 1, Week 2-3, Week 4-6)

9. Optional Next Step:
   The review is complete. The natural next step would be for the user to review the findings and decide which fixes to implement first. The review document provides a clear priority order. No further action should be taken without user direction, as the explicit task ("proceed to part IV") has been fully completed.

If you need specific details from before compaction (like exact code snippets, error messages, or content you generated), read the full transcript at: /Users/devs/.REDACTED.jsonl
Please continue the conversation from where we left off without asking the user any further questions. Continue with the last task that you were asked to work on.

---

<task-notification>
<task-id>a87491c</task-id>
<status>completed</status>
<summary>Agent "Audit payment and licence pipeline" completed</summary>
<result>Now I have a comprehensive understanding of the entire monetization pipeline. Here is the full audit.

---

# Apollo Finance/Monetization Pipeline -- Exhaustive Audit

## 1. PAYMENT FLOW -- END TO END

### 1.1 Architecture Summary

The flow is:

1. **Checkout UI** (`/Users/devs/Downloads/Apollo/apps/web/app/(dashboard)/checkout/page.tsx`): User selects plan and currency (INR/USD). Calls `POST /api/checkout`.
2. **Checkout API** (`/Users/devs/Downloads/Apollo/apps/web/app/api/checkout/route.ts`): Validates input via Zod, creates a Razorpay order (INR) or Stripe session (USD), returns payment details.
3. **Payment Gateway**: Razorpay modal on-page or Stripe hosted checkout redirect.
4. **Webhooks**: Razorpay (`/Users/devs/Downloads/Apollo/apps/web/app/api/webhooks/razorpay/route.ts`) or Stripe (`/Users/devs/Downloads/Apollo/apps/web/app/api/webhooks/stripe/route.ts`) fires. Signature verified, idempotency checked, licence provisioned.
5. **Provisioning** (`/Users/devs/Downloads/Apollo/apps/web/lib/payments/provision-licence.ts`): Inserts a `thesis_licenses` row. If `project_id` was passed, also updates the project to `licensed`.

### 1.2 Findings

**FINDING F1 -- CRITICAL: Race condition between provision and markEventProcessed**

File: `/Users/devs/Downloads/Apollo/apps/web/app/api/webhooks/razorpay/route.ts`, lines 62-63
File: `/Users/devs/Downloads/Apollo/apps/web/app/api/webhooks/stripe/route.ts`, lines 62-63

```typescript
await provisionLicence(userId, planType, projectId);
await markEventProcessed("razorpay", eventId, eventType);
```

If `provisionLicence` succeeds but `markEventProcessed` fails (e.g., DB write error), the next webhook retry will pass the idempotency check (`isEventProcessed` returns false) and provision a **second licence** for the same payment. These two operations are not atomic -- they are separate Supabase calls with no transaction wrapping.

**Severity: CRITICAL**
**Impact: Double-provisioning of licences on webhook retry**
**Fix: Wrap both in a Supabase RPC/transaction, or reverse the order: mark as processed FIRST, then provision. If provisioning fails, a manual reconciliation is safer than a double licence.**

---

**FINDING F2 -- HIGH: provisionLicence auto-attaches without verifying project ownership**

File: `/Users/devs/Downloads/Apollo/apps/web/lib/payments/provision-licence.ts`, lines 41-51

```typescript
if (projectId) {
  await supabase
    .from("projects")
    .update({
      status: "licensed",
      license_id: licence.id,
      updated_at: new Date().toISOString(),
    })
    .eq("id", projectId)
    .eq("user_id", userId);
}
```

While the `.eq("user_id", userId)` clause prevents attaching to another user's project, the `projectId` comes from **payment metadata** (`notes.project_id`). A malicious user could craft a checkout request with someone else's `project_id` in the body. The checkout route (`/Users/devs/Downloads/Apollo/apps/web/app/api/checkout/route.ts`, line 34) passes it through blindly into Razorpay notes:

```typescript
const metadata = {
  user_id: authResult.user.id,
  plan_type,
  plan_label: pricing.label,
  ...(project_id ? { project_id } : {}),
};
```

The checkout API does **not verify** that the `project_id` belongs to the authenticated user before embedding it in payment metadata. The provisioning step does filter by `user_id`, so the attack does not succeed in attaching to another user's project -- but the payment metadata is polluted, and the provisioned licence has the wrong `project_id` set (row-level, before the project update fails silently due to the `.eq("user_id")` guard).

**Severity: HIGH**
**Impact: Licence created with incorrect project_id, potentially wasted. Silent failure on project update.**
**Fix: Validate `project_id` ownership in the checkout route before embedding in metadata. Also check that the project is in "sandbox" status.**

---

**FINDING F3 -- MEDIUM: Razorpay client-side success handler is a timing guess**

File: `/Users/devs/Downloads/Apollo/apps/web/app/(dashboard)/checkout/page.tsx`, lines 170-179

```typescript
handler: () => {
  toast.success("Payment successful! Your licence is being provisioned.");
  setTimeout(() => {
    if (attachProjectId) {
      router.push(`/projects/${attachProjectId}`);
    } else {
      router.push("/dashboard?payment=success");
    }
  }, 2000);
},
```

The Razorpay `handler` fires immediately on client-side payment success, but the webhook may not have fired yet (network latency, queuing). The 2-second delay is a hopeful guess. If the webhook takes longer, the user arrives at the project page before the licence is provisioned, seeing a confusing "licence required" state.

**Severity: MEDIUM**
**Impact: Poor UX -- user sees "licence required" after successful payment**
**Fix: Poll a `/api/licenses` endpoint or use Supabase Realtime subscription to confirm provisioning before redirecting.**

---

**FINDING F4 -- LOW: Professional plan provisions 3 licences but code provisions only 1**

File: `/Users/devs/Downloads/Apollo/apps/web/app/(dashboard)/checkout/page.tsx`, line 46: `"3 thesis licences"`
File: `/Users/devs/Downloads/Apollo/apps/web/lib/payments/provision-licence.ts`: The function creates exactly ONE licence row per call.

The `provisionLicence` function has no logic to handle the Professional plan's "3 thesis licences" promise. It always inserts a single licence. The checkout page advertises 3 licences, but only 1 is created.

**Severity: HIGH (commercial promise not fulfilled)**
**Impact: Professional plan users receive 1 licence instead of 3**
**Fix: Add a `licenceCount` lookup based on `planType` in `provisionLicence`, and insert multiple licence rows for `professional_monthly`.**

---

## 2. LICENCE PROVISIONING

### 2.1 Idempotency

File: `/Users/devs/Downloads/Apollo/apps/web/lib/payments/provision-licence.ts`, lines 59-87

The idempotency system uses a `processed_webhooks` table (`/Users/devs/Downloads/Apollo/apps/web/supabase/migrations/022_create_processed_webhooks.sql`). The `event_id` column has a `UNIQUE` constraint, which is the correct approach.

**FINDING F5 -- MEDIUM: isEventProcessed uses `maybeSingle()` not atomic with insert**

The idempotency check (`isEventProcessed`) and the mark (`markEventProcessed`) are separate calls. Two concurrent webhook deliveries (common with Stripe and Razorpay) could both pass the `isEventProcessed` check before either inserts. The `UNIQUE` constraint on `event_id` will cause the second INSERT to fail, but the `provisionLicence` call has already executed by that point.

**Severity: MEDIUM (partially mitigated by UNIQUE constraint, but double provision still possible)**
**Fix: Use `INSERT ... ON CONFLICT DO NOTHING RETURNING id` as the first step. If no row is returned, the event was already processed.**

---

### 2.2 Licence Expiry

File: `/Users/devs/Downloads/Apollo/apps/web/lib/payments/provision-licence.ts`, lines 15-21

```typescript
if (planType.includes("monthly")) {
  expiresAt.setDate(expiresAt.getDate() + 30);
} else {
  expiresAt.setFullYear(expiresAt.getFullYear() + 1);
}
```

**FINDING F6 -- HIGH: No licence expiry enforcement anywhere in the codebase**

The `expires_at` field is set at provisioning time, but there is **no cron job, no scheduled function, no middleware check, and no API route check** that verifies whether a licence has expired. A licence with `status: 'active'` that is past its `expires_at` will continue to work indefinitely.

The phase transition check in `/Users/devs/Downloads/Apollo/apps/web/lib/phases/transitions.ts` only checks `project.status !== "licensed"` -- it does not check whether the associated licence has expired.

**Severity: HIGH**
**Impact: Monthly subscribers get perpetual access after their 30-day period ends**
**Fix: Add a scheduled job (Inngest cron or Supabase pg_cron) to expire licences. Also add an expiry check in `checkLicenceGate` and `canAdvancePhase`.**

---

## 3. LICENCE GATING -- WHERE IT'S ENFORCED

### 3.1 Phase Advancement Gate

File: `/Users/devs/Downloads/Apollo/apps/web/lib/phases/transitions.ts`, lines 42-56
File: `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/sections/[phase]/approve/route.ts`, lines 95-101

The `canAdvancePhase` function checks `nextPhase.requiresLicence` and `project.status`. This gates advancement past Phase 1 (since Phase 2 requires licence, per `/Users/devs/Downloads/Apollo/apps/web/lib/phases/constants.ts`).

This is correctly implemented.

### 3.2 Export Gates

Files:
- `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/export/pdf/route.ts`
- `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/export/docx/route.ts`
- `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/export/source/route.ts`
- `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/export/stats/route.ts`

All four export routes use `checkLicenceGate()` correctly, returning 402 if project is not `licensed` or `completed`.

### 3.3 MISSING LICENCE GATES

**FINDING F7 -- HIGH: Generate route has NO licence check**

File: `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/sections/[phase]/generate/route.ts`

The generate route checks auth, validates phase, checks rate limit, checks token budget -- but never checks the licence. A sandbox user can call `POST /api/projects/{id}/sections/5/generate` to generate any Phase 2-11 section content via AI. The only gate is at the *approval/advancement* step, not at the *generation* step.

This means sandbox users can consume expensive Claude API tokens for phases they should not have access to. They cannot advance past Phase 1, but they can generate content for all 12 phases.

**Severity: HIGH (financial impact -- AI costs without revenue)**
**Fix: Add a licence check in the generate route for phases where `requiresLicence === true`.**

---

**FINDING F8 -- HIGH: Refine route has NO licence check**

File: `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/sections/[phase]/refine/route.ts`

Same issue as F7. The refine route (AI-powered section refinement) has no licence check whatsoever. Sandbox users can repeatedly refine content, consuming Claude tokens.

**Severity: HIGH (financial impact)**
**Fix: Add licence check for phases where `requiresLicence === true`.**

---

**FINDING F9 -- MEDIUM: Compile route has NO licence check**

File: `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/compile/route.ts`

The compile route checks auth and project ownership but does not check licence status. A sandbox user can trigger compilation, consuming Docker compute resources. The watermark IS correctly applied (`isWatermark = typedProject.status === "sandbox"` at line 183), but the resource consumption is ungated.

**Severity: MEDIUM (compute cost without revenue, but watermark is enforced)**
**Fix: Consider adding a licence check, or at minimum rate-limit sandbox compilations more aggressively.**

---

**FINDING F10 -- MEDIUM: Preview PDF route has NO licence check**

File: `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/preview.pdf/route.ts`

The preview PDF endpoint streams the compiled PDF directly. There is no licence check. While the PDF is watermarked for sandbox projects, the endpoint allows downloading the full PDF file (with `?download=1` parameter). This means sandbox users can download watermarked PDFs.

**Severity: MEDIUM (watermark partially mitigates, but content is still accessible)**

---

**FINDING F11 -- MEDIUM: Analysis, dataset generation, auto-detect, QC, and share routes have NO licence checks**

Files:
- `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/analyses/route.ts` (run R analysis)
- `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/analyses/auto-detect/route.ts` (AI recommendation)
- `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/datasets/generate/route.ts` (AI dataset generation)
- `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/qc/route.ts` (final QC)
- `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/share/route.ts` (share token creation)

None of these routes check licence status. Sandbox users can:
- Generate datasets using AI (Claude cost)
- Run statistical analyses (R Plumber compute cost)
- Get AI-powered analysis recommendations (Claude cost)
- Run Final QC (though they cannot approve it)
- Create supervisor share links

**Severity: MEDIUM (cumulative cost and feature leakage)**

---

## 4. LICENCE ATTACHMENT & TRANSFER

### 4.1 Attachment

File: `/Users/devs/Downloads/Apollo/apps/web/app/api/licenses/[lid]/attach/[pid]/route.ts`

Correctly implemented:
- Verifies licence belongs to user (line 27-29)
- Verifies licence status is `available` (line 35)
- Verifies project belongs to user (line 42-48)
- Verifies project is in `sandbox` status (line 53)
- Updates licence to `active` with `project_id`
- Updates project to `licensed` with `license_id`

**FINDING F12 -- MEDIUM: Attach operation is not atomic**

Lines 60-88: The licence update and project update are separate calls (not wrapped in a transaction). If the licence update succeeds but the project update fails, the licence will be `active` but the project will remain `sandbox`. The user would be in a broken state where their licence is consumed but their project is not licensed.

**Severity: MEDIUM**
**Fix: Use a Supabase RPC (stored procedure) to make both updates atomic.**

---

### 4.2 Transfer

File: `/Users/devs/Downloads/Apollo/apps/web/app/api/licenses/[lid]/transfer/route.ts`

Correctly checks:
- Licence belongs to user
- Licence status is `active`
- Sets status to `transferred` (DB trigger enforces 6-month cooldown)
- Sets project back to `sandbox`

**FINDING F13 -- LOW: Transfer does not check if project has content beyond Phase 1**

A user could transfer a licence from a project at Phase 8, reverting the project to sandbox. The content remains in the sections table. They could then attach a new licence and continue. This may be acceptable behaviour, but it could also be used to "shuffle" licences between projects to get multiple projects past the paywall (albeit one at a time, with a 6-month cooldown).

**Severity: LOW (6-month cooldown mitigates abuse)**

---

### 4.3 One Licence Per Project Enforcement

The DB schema has `project_id UUID UNIQUE` on `thesis_licenses`, ensuring one licence per project. The `projects` table has `license_id UUID UNIQUE`, ensuring one project per licence. This is correctly enforced at the database level.

---

## 5. PRICING PLANS

### 5.1 Plans Defined

File: `/Users/devs/Downloads/Apollo/apps/web/lib/validation/payment-schemas.ts`, lines 30-35

| Plan | INR | USD | Licences |
|------|-----|-----|----------|
| student_monthly | 49,900 paise (Rs 499) | 999 cents ($9.99) | 1 |
| professional_monthly | 99,900 paise (Rs 999) | 1,999 cents ($19.99) | 3 (advertised) |
| addon | 29,900 paise (Rs 299) | 599 cents ($5.99) | 1 |
| one_time | 1,49,900 paise (Rs 1,499) | 2,999 cents ($29.99) | 1 |

**FINDING F14 -- MEDIUM: Pricing inconsistency between landing page and checkout**

Landing page (`/Users/devs/Downloads/Apollo/apps/web/components/landing/pricing-section.tsx`):
- Professional one-time: Rs 2,999

Checkout page (`/Users/devs/Downloads/Apollo/apps/web/app/(dashboard)/checkout/page.tsx`):
- No one-time option for Professional

FAQ section (`/Users/devs/Downloads/Apollo/apps/web/components/landing/faq-section.tsx`, line 30):
- Student: Rs 2,499/month or Rs 14,999 for 6-month access
- Professional: Rs 4,999/month or Rs 24,999 for lifetime

Actual checkout prices:
- Student monthly: Rs 499
- Professional monthly: Rs 999

The FAQ prices are wildly different from actual prices. This is misleading.

**Severity: MEDIUM (legal/trust risk -- misleading pricing)**
**Fix: Synchronize all pricing displays across the app from a single source of truth.**

---

### 5.2 Plan-Based Feature Gating

**FINDING F15 -- HIGH: No plan-based feature differentiation whatsoever**

The Professional plan advertises:
- "Priority compile queue" -- No priority queue implementation exists
- "Supervisor collaboration links" -- The share route has no plan check
- "Source LaTeX export" -- Export routes only check `licensed` status, not plan type

There is zero code anywhere that differentiates between `student_monthly` and `professional_monthly` in terms of features. A Student plan licence grants exactly the same access as a Professional plan licence.

**Severity: HIGH (commercial promise not fulfilled)**
**Fix: Implement plan-based feature checks in the relevant routes.**

---

### 5.3 "addon" Plan

The `addon` plan type exists in the validation schema and pricing table but is NOT displayed on the checkout page. It can be purchased by crafting a direct API call to `POST /api/checkout` with `plan_type: "addon"`. At Rs 299, this is the cheapest way to get a thesis licence.

**FINDING F16 -- MEDIUM: Hidden "addon" plan accessible via direct API call**

**Severity: MEDIUM (revenue leakage)**
**Fix: Either remove "addon" from the schema or add it to the checkout UI.**

---

## 6. BYPASS & ABUSE VECTORS

### 6.1 DEV_LICENCE_BYPASS

File: `/Users/devs/Downloads/Apollo/apps/web/lib/phases/transitions.ts`, line 44

```typescript
const devBypass = process.env.DEV_LICENCE_BYPASS === "true";
```

**FINDING F17 -- CRITICAL: DEV_LICENCE_BYPASS is a server-side environment variable with no production guard**

This env var, when set to `"true"`, completely disables licence checking for phase advancement. There is no check for `NODE_ENV === "development"` or similar. If this variable is accidentally set in production (e.g., copied from a dev `.env` file), all licence gates are disabled.

Furthermore, this bypass is only checked in `canAdvancePhase`, not in `checkLicenceGate` (export gate). So it bypasses phase advancement but not exports -- an inconsistent security posture.

**Severity: CRITICAL**
**Fix: Add `process.env.NODE_ENV !== "production"` guard. Better yet, remove this entirely and use a test-specific override.**

---

### 6.2 Sandbox Content Generation (Unlimited)

**FINDING F18 -- HIGH: Sandbox users can generate unlimited AI content**

As noted in F7 and F8, the generate and refine routes have no licence check. Sandbox users can:
- Generate content for all 12 phases
- Refine content repeatedly
- Run auto-detect analysis recommendations
- Generate datasets

The only limits are:
- Token budget per phase (100K output tokens)
- Token budget per thesis (1.2M total tokens)
- Rate limiting

But these limits apply equally to paid and unpaid users. There is no separate budget for sandbox vs. licensed.

**Severity: HIGH (significant financial exposure)**

---

### 6.3 Unlimited Project Creation

**FINDING F19 -- MEDIUM: No limit on project creation**

File: `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/route.ts`, POST handler

There is no check on the number of projects a user can create. A user could create unlimited sandbox projects, each with its own token budget (1.2M tokens). Combined with F18, this means unlimited AI generation across unlimited projects.

**Severity: MEDIUM**
**Fix: Add a project count limit per user, or a global token budget per user (not just per project).**

---

### 6.4 No Velocity Limits on Licence Purchases

There is no limit on how many licences a user can purchase. While this is not necessarily an abuse vector (they're paying), it could be used with stolen credit cards for fraud.

**Severity: LOW**

---

## 7. REFUND & CANCELLATION

**FINDING F20 -- HIGH: No refund, cancellation, or subscription management exists**

The entire codebase has:
- **No Stripe subscription management** -- all payments are one-time (`mode: "payment"` in Stripe session, line 27 of `/Users/devs/Downloads/Apollo/apps/web/lib/payments/stripe.ts`)
- **No Razorpay subscription API usage** -- orders are one-time
- **No refund endpoint**
- **No cancellation webhook handler** (the Stripe webhook only handles `checkout.session.completed`)
- **No subscription.updated or subscription.cancelled event handlers**
- **No customer portal link** for self-service management

Despite being called "monthly" plans, they are NOT subscriptions -- they are one-time payments that create a licence with a 30-day expiry. But since expiry is not enforced (F6), they are effectively perpetual one-time purchases.

**Severity: HIGH (business model fundamentally broken -- "monthly" plans are really one-time purchases)**
**Fix: Either implement actual Stripe/Razorpay subscriptions with recurring billing, or rename the plans to accurately reflect the one-time nature.**

---

## 8. EXPORT GATING

### 8.1 API-Level Gating

All four export routes (PDF, DOCX, source, stats) correctly use `checkLicenceGate()` which returns 402 for non-licensed projects. This is properly implemented.

### 8.2 Frontend Gating

File: `/Users/devs/Downloads/Apollo/apps/web/components/project/export-menu.tsx`

The ExportMenu component checks `projectStatus === "licensed" || projectStatus === "completed"` and disables the button + hides the dropdown for unlicensed projects. This is correctly implemented as a UX layer on top of the API gate.

### 8.3 Watermark Enforcement

File: `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/compile/route.ts`, line 183

```typescript
const isWatermark = typedProject.status === "sandbox";
```

The watermark is passed to the Docker compile command. The CLS files (`sskm-thesis.cls`, `ssuhs-thesis.cls`) include `draftwatermark` package support. The PDF viewer also shows an overlay "SANDBOX" watermark.

**FINDING F21 -- LOW: Preview PDF endpoint serves watermarked PDFs without licence check**

The `/api/projects/[id]/preview.pdf` route serves compiled PDFs. For sandbox projects, the PDF is watermarked. However, a sandbox user can compile and view/download the watermarked PDF. This is probably acceptable since the watermark is present, but it means sandbox users get a "preview" of their full thesis.

**Severity: LOW (acceptable behaviour -- watermark is present)**

---

**FINDING F22 -- MEDIUM: `checkLicenceGate` does not honour DEV_LICENCE_BYPASS**

File: `/Users/devs/Downloads/Apollo/apps/web/lib/api/licence-gate.ts`

The export gate does NOT check `DEV_LICENCE_BYPASS`. So in development, a developer can advance past Phase 1 with the bypass, generate all content, compile -- but cannot export. This is inconsistent with the bypass in `canAdvancePhase`.

**Severity: LOW for security (actually safer), MEDIUM for DX**

---

## 9. SEVERITY SUMMARY

| ID | Severity | Finding |
|----|----------|---------|
| F1 | CRITICAL | Race condition: provisionLicence + markEventProcessed not atomic -- double provisioning possible |
| F17 | CRITICAL | DEV_LICENCE_BYPASS has no production guard |
| F4 | HIGH | Professional plan advertises 3 licences, only 1 provisioned |
| F6 | HIGH | No licence expiry enforcement -- monthly licences are perpetual |
| F7 | HIGH | Generate route has no licence check -- sandbox users consume AI tokens for free |
| F8 | HIGH | Refine route has no licence check |
| F15 | HIGH | No plan-based feature differentiation (Professional === Student) |
| F18 | HIGH | Sandbox users can generate unlimited AI content across unlimited projects |
| F20 | HIGH | No subscription/refund/cancellation system -- "monthly" plans are one-time purchases |
| F2 | HIGH | Checkout API does not validate project_id ownership |
| F5 | MEDIUM | Idempotency check is not atomic with provisioning |
| F9 | MEDIUM | Compile route has no licence check |
| F10 | MEDIUM | Preview PDF has no licence check |
| F11 | MEDIUM | Analysis/dataset/QC/share routes have no licence checks |
| F12 | MEDIUM | Licence attach operation is not atomic |
| F14 | MEDIUM | Pricing inconsistency between landing page, checkout, and FAQ |
| F16 | MEDIUM | Hidden "addon" plan at Rs 299 accessible via direct API |
| F19 | MEDIUM | No limit on project creation |
| F3 | MEDIUM | Razorpay success handler uses timing guess for redirect |
| F22 | LOW/MEDIUM | checkLicenceGate inconsistent with DEV_LICENCE_BYPASS |
| F13 | LOW | Transfer does not check project progress |
| F21 | LOW | Preview PDF serves watermarked PDFs without licence gate |

**Total findings: 22**
- Critical: 2
- High: 8
- Medium: 9
- Low: 3</result>
<usage>total_tokens: 100448
tool_uses: 70
duration_ms: 241723</usage>
</task-notification>
Full transcript available at: REDACTED.output

---

<task-notification>
<task-id>a100e91</task-id>
<status>completed</status>
<summary>Agent "Audit auth and security posture" completed</summary>
<result>I now have a comprehensive picture. Let me compile the full security audit report.

---

# Apollo Platform -- Exhaustive Security Audit Report

## Executive Summary

The Apollo platform demonstrates good security fundamentals: Clerk handles authentication, all API routes call `getAuthenticatedUser()`, most project routes verify ownership, webhook signatures are verified, and Docker containers are hardened. However, several significant vulnerabilities exist that require remediation before production deployment.

**Critical findings: 3 | High findings: 6 | Medium findings: 8 | Low findings: 5**

---

## 1. Authentication & Authorization

### 1.1 Middleware Route Protection

**File:** `/Users/devs/Downloads/Apollo/apps/web/middleware.ts` (lines 4-12)

The Clerk middleware protects routes via `createRouteMatcher`:

```typescript
const isProtectedRoute = createRouteMatcher([
  "/dashboard(.*)",
  "/projects(.*)",
  "/licences(.*)",
  "/checkout(.*)",
  "/api/projects(.*)",
  "/api/licenses(.*)",
  "/api/upload(.*)",
]);
```

**CRITICAL -- Missing route protection patterns:**

- `/api/checkout(.*)` is NOT in the protected list. Although the route handler itself calls `getAuthenticatedUser()`, the middleware layer does not enforce auth. The checkout route at `/Users/devs/Downloads/Apollo/apps/web/app/api/checkout/route.ts` is application-level protected but not middleware-level protected.
- `/api/synopsis(.*)` is NOT in the protected list. The synopsis parse route at `/Users/devs/Downloads/Apollo/apps/web/app/api/synopsis/parse/route.ts` calls `getAuthenticatedUser()` at the application level, but is not middleware-protected.
- `/api/citations(.*)` is NOT in the protected list. The citation search route at `/Users/devs/Downloads/Apollo/apps/web/app/api/citations/search/route.ts` calls `getAuthenticatedUser()` at the application level.
- `/api/inngest(.*)` is NOT in the protected list. The Inngest route at `/Users/devs/Downloads/Apollo/apps/web/app/api/inngest/route.ts` exports `GET`, `POST`, and `PUT` handlers served by the Inngest SDK. Inngest itself handles verification via signing keys, but a missing middleware pattern means raw requests can reach this endpoint without Clerk auth.
- `/api/review(.*)` is correctly NOT protected (public review links by design).
- `/api/webhooks(.*)` is correctly NOT protected (webhook endpoints must be publicly accessible).

**Severity: MEDIUM** -- Application-level auth provides a defence layer, but middleware should be the authoritative gate. If a developer accidentally omits `getAuthenticatedUser()` in a new route under `/api/checkout/` or `/api/citations/`, it would be unprotected.

### 1.2 Authentication Function

**File:** `/Users/devs/Downloads/Apollo/apps/web/lib/api/auth.ts`

The `getAuthenticatedUser()` function works correctly: it checks Clerk `auth()`, looks up the user in Supabase, and has JIT provisioning as a fallback. All 43 matched files call this function. No API route under `/api/projects/` was found without it.

**Finding: GOOD** -- Comprehensive authentication coverage at the application layer.

### 1.3 Webhook Endpoints -- Properly Secured

- **Clerk webhook** (`/Users/devs/Downloads/Apollo/apps/web/app/api/webhooks/clerk/route.ts`): Uses Svix signature verification (lines 39-53). Properly validates `svix-id`, `svix-timestamp`, and `svix-signature` headers. **GOOD.**
- **Razorpay webhook** (`/Users/devs/Downloads/Apollo/apps/web/app/api/webhooks/razorpay/route.ts`): Verifies HMAC-SHA256 signature (line 23), has idempotency check (line 42). **GOOD.**
- **Stripe webhook** (`/Users/devs/Downloads/Apollo/apps/web/app/api/webhooks/stripe/route.ts`): Uses `constructStripeEvent()` for signature verification (line 24), has idempotency check (line 34). **GOOD.**

---

## 2. IDOR (Insecure Direct Object Reference)

### 2.1 CRITICAL -- `GET /api/projects/[id]` Missing Ownership Check

**File:** `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/route.ts` (lines 12-37)

```typescript
export async function GET(...) {
  const authResult = await getAuthenticatedUser();
  if (!authResult) return unauthorised();

  const { id } = await params;
  const supabase = await createServerSupabaseClient();

  const { data: project, error } = await supabase
    .from("projects")
    .select("*")
    .eq("id", id)
    .single();  // <-- NO .eq("user_id", authResult.user.id) !!
```

This route uses `createServerSupabaseClient()` (anon key with RLS). The RLS policies on the `projects` table DO filter by the Clerk JWT `sub` claim. However, this relies entirely on RLS being correctly configured and the Clerk-Supabase token integration working properly. **If the Supabase token doesn't carry the correct Clerk JWT (e.g., token expiry, misconfiguration), any authenticated user could read any project.**

**Severity: HIGH** -- Defence-in-depth violation. The application should explicitly filter by `user_id` regardless of RLS.

### 2.2 CRITICAL -- `PATCH /api/projects/[id]` Missing Ownership Check

**File:** `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/route.ts` (lines 40-76)

Same issue as GET -- the PATCH handler queries with `.eq("id", id)` only, relying on RLS for ownership enforcement. A user could potentially update another user's project metadata (title, university_type, etc.).

**Severity: HIGH** -- Allows modification of another user's project data if RLS fails.

### 2.3 CRITICAL -- `DELETE /api/projects/[id]` Missing Ownership Check

**File:** `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/route.ts` (lines 78-105)

Same issue -- the DELETE (soft-delete/archive) handler has no explicit `user_id` check.

**Severity: HIGH** -- Allows archiving another user's project if RLS fails.

### 2.4 `GET /api/projects` Missing User Filter

**File:** `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/route.ts` (lines 11-33)

```typescript
const { data: projects, error } = await supabase
  .from("projects")
  .select("*")
  .order("updated_at", { ascending: false });
  // No .eq("user_id", ...) filter
```

This uses `createServerSupabaseClient()` with RLS, which should filter by user. Same defence-in-depth concern as above.

**Severity: MEDIUM** -- Relies solely on RLS.

### 2.5 `GET /api/licenses` Missing User Filter

**File:** `/Users/devs/Downloads/Apollo/apps/web/app/api/licenses/route.ts` (lines 6-28)

Uses `createServerSupabaseClient()` with no explicit `.eq("user_id", ...)` filter. Relies on RLS.

**Severity: MEDIUM** -- Relies solely on RLS.

### 2.6 `GET /api/projects/[id]/share` -- IDOR on Review Tokens

**File:** `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/share/route.ts` (lines 67-90)

The GET handler lists all review tokens for a project but does **not verify project ownership**:

```typescript
const { data: tokens } = await supabase
  .from("review_tokens")
  .select("id, token, expires_at, created_at")
  .eq("project_id", id)  // <-- No ownership check!
```

This uses `createAdminSupabaseClient()` (service role key, bypasses RLS). **Any authenticated user can list review tokens for any project**, exposing shareable review links.

**Severity: HIGH** -- Leaks review URLs for other users' projects, enabling unauthorised thesis reviews.

### 2.7 Positive Findings -- Routes WITH Proper Ownership Checks

The following routes correctly verify ownership with `.eq("user_id", authResult.user.id)`:
- All `/api/projects/[id]/sections/` routes
- All `/api/projects/[id]/citations/` routes
- All `/api/projects/[id]/datasets/` routes
- All `/api/projects/[id]/analyses/` routes
- All `/api/projects/[id]/figures/` routes
- All `/api/projects/[id]/abbreviations/` routes
- `/api/projects/[id]/compile/`
- `/api/projects/[id]/preview.pdf/`
- `/api/projects/[id]/share/` (POST only)
- `/api/projects/[id]/compilations/`
- `/api/projects/[id]/compliance/`
- `/api/projects/[id]/qc/`
- All export routes use `checkLicenceGate()` which verifies ownership
- All licence attach/transfer routes verify licence+project ownership

---

## 3. Input Validation & Injection

### 3.1 Admin Supabase Client Used Extensively -- Bypasses RLS

**File:** `/Users/devs/Downloads/Apollo/apps/web/lib/supabase/admin.ts`

`createAdminSupabaseClient()` uses the `SUPABASE_SERVICE_ROLE_KEY`, which **bypasses all RLS policies**. This client is used by the vast majority of API routes (30+ routes). While each route does manual ownership verification, this means RLS provides zero defence if the manual check is omitted.

**Severity: MEDIUM** -- The pattern of using admin client + manual ownership checks is less safe than using anon client + RLS. It increases the blast radius of any missed ownership check.

**Recommendation:** Use `createServerSupabaseClient()` (anon key + RLS) for read operations and reserve the admin client for operations that genuinely need it (webhook handlers, background jobs).

### 3.2 Zod Validation Coverage

Input validation via Zod schemas is generally good:
- `projectCreateSchema` / `projectUpdateSchema` -- projects
- `sectionUpdateSchema` -- sections
- `citationCreateSchema` / `citationUpdateSchema` -- citations
- `analysisCreateSchema` / `autoDetectSchema` -- analyses
- `datasetColumnsSchema` / `datasetGenerateSchema` -- datasets
- `figureUploadSchema` / `mermaidGenerateSchema` -- figures
- `abbreviationCreateSchema` / `abbreviationUpdateSchema` -- abbreviations
- `complianceRunSchema` -- compliance
- `checkoutSchema` -- payments
- `commentSchema` -- review comments

### 3.3 No SQL Injection Vectors

All database queries use the Supabase client's parameterised query builder (`.eq()`, `.select()`, `.insert()`, etc.). No raw SQL or string interpolation in queries was found. **GOOD.**

### 3.4 Command Injection -- Low Risk but Present

**File:** `/Users/devs/Downloads/Apollo/apps/web/lib/latex/compile.ts` (line 1, 189)

```typescript
import { execFile } from "child_process";
// ...
const { stdout, stderr } = await execFileAsync("docker", args, { timeout: 120_000 });
```

`execFile` is used (not `exec`), which prevents shell metacharacter injection. The `args` array is constructed from controlled values (project ID is a UUID, `containerName` comes from env vars). The `projectId` is used in path construction (`apollo-compile-${options.projectId}`) but since it comes from a database UUID, this is safe.

**Severity: LOW** -- `execFile` is the correct choice for command execution.

### 3.5 XSS -- `dangerouslySetInnerHTML` in Two Components

**File:** `/Users/devs/Downloads/Apollo/apps/web/components/preview/title-page-preview.tsx` (line 12)

```typescript
dangerouslySetInnerHTML={{ __html: html }}
```

The `html` prop is rendered without sanitisation. If user-controlled data reaches this component, it creates an XSS vector.

**File:** `/Users/devs/Downloads/Apollo/apps/web/components/project/mermaid-editor.tsx` (line 66)

```typescript
previewRef.current.innerHTML = svg;
```

Mermaid renders diagrams from user-provided source code. However, Mermaid is initialised with `securityLevel: "strict"` (line 51), which strips event handlers and JavaScript. **This is mitigated.**

**Severity: MEDIUM** (title-page-preview) / **LOW** (mermaid-editor -- mitigated by strict security level)

### 3.6 LaTeX Injection

User-controlled content enters LaTeX through the Tiptap editor and AI-generated content. The system mitigates this through:
- `escapeLatex()` in `tiptap-to-latex.ts` for special characters
- `normaliseUnicode()` for non-ASCII characters
- `escapeBareAmpersands()` for BibTeX content
- Chapter files are written to isolated temp directories
- No `\input{}` or `\include{}` commands use user-controlled paths

**Severity: LOW** -- The escape pipeline is thorough.

### 3.7 DOCX Export -- Header Injection

**File:** `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/export/docx/route.ts` (line 68)

```typescript
"Content-Disposition": `attachment; filename="${project.title || "thesis"}.tex"`,
```

The `project.title` is interpolated directly into the `Content-Disposition` header. If a title contains `"` or newlines, it could break the header or inject additional headers.

**Severity: LOW** -- Could cause malformed headers but is unlikely to be exploitable in modern browsers.

---

## 4. CSRF & Request Forgery

### 4.1 No Explicit CSRF Protection

**Severity: MEDIUM**

There is no CSRF middleware, no `SameSite` cookie configuration (Clerk handles this), and no CSRF token validation on mutation endpoints. Clerk's session cookies likely have `SameSite=Lax` by default, which provides some protection against CSRF for POST requests initiated by other origins. However:

- SSE streaming endpoints (`generate`, `refine`) are POST requests returning `text/event-stream`. These are adequately protected by the Clerk session cookie + `SameSite`.
- API routes that modify state (DELETE, PATCH, PUT) are protected by session cookies.

Since Clerk manages cookies with proper SameSite settings, and API routes use cookie-based auth (not custom headers), the CSRF risk is low for modern browsers.

### 4.2 Origin Header Usage for Share URLs

**File:** `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/share/route.ts` (line 51)

```typescript
const origin = _request.headers.get("origin") ?? process.env.NEXT_PUBLIC_APP_URL ?? "http://localhost:3000";
```

The `origin` header is used to construct share URLs. An attacker could craft a request with a malicious `origin` to generate phishing share links. However, this only affects the URL returned in the response, not stored data.

**Severity: LOW** -- The share token itself is cryptographically random and validated server-side.

---

## 5. Rate Limiting

### 5.1 In-Memory Rate Limiter -- Not Production-Ready

**File:** `/Users/devs/Downloads/Apollo/apps/web/lib/ai/rate-limit.ts`

The rate limiter is an in-memory `Map` with a 10 requests/hour/user window. This has several issues:

- **Resets on server restart/deploy** -- all limits cleared
- **Not shared across instances** -- if running multiple Next.js instances (e.g., behind a load balancer), each instance has its own store
- **Only applied to AI generation** (`/api/projects/[id]/sections/[phase]/generate/route.ts`) -- NOT applied to:
  - AI refine endpoint (`/api/projects/[id]/sections/[phase]/refine/route.ts`)
  - AI auto-detect endpoint (`/api/projects/[id]/analyses/auto-detect/route.ts`)
  - Synopsis parse endpoint (`/api/synopsis/parse/route.ts`)
  - Citation search endpoint (proxies to CrossRef/PubMed)
  - Compile endpoint (has semaphore but no per-user rate limit)

The `.env.example` has commented-out Upstash Redis configuration (`UPSTASH_REDIS_REST_URL`, `UPSTASH_REDIS_REST_TOKEN`) suggesting a plan for proper distributed rate limiting that hasn't been implemented yet.

**Severity: HIGH** -- An authenticated user can make unlimited AI API calls (via refine, auto-detect, synopsis parse), potentially incurring significant Anthropic API costs. The compile semaphore limits concurrency but not frequency.

### 5.2 Compute Semaphore

**File:** `/Users/devs/Downloads/Apollo/apps/web/lib/compute/semaphore.ts`

The semaphore limits concurrent compile (1) and analysis (2) operations. This is per-instance and in-memory, with the same issues as the rate limiter. However, it does protect against resource exhaustion.

**Severity: MEDIUM** -- Adequate for single-instance but won't scale.

---

## 6. Secrets & Environment Variables

### 6.1 No Hardcoded Secrets

A search for API key patterns (`sk_test_`, `sk_live_`, `sk_ant_`) in TypeScript source returned zero results. All secrets are loaded from environment variables. **GOOD.**

### 6.2 `NEXT_PUBLIC_` Variables

The following are exposed to the client:
- `NEXT_PUBLIC_SUPABASE_URL` -- Safe (public project URL)
- `NEXT_PUBLIC_SUPABASE_ANON_KEY` -- Safe (anon key, protected by RLS)
- `NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY` -- Safe (designed for client)
- `NEXT_PUBLIC_CLERK_SIGN_IN_URL` / `SIGN_UP_URL` / `AFTER_SIGN_*_URL` -- Safe (route config)
- `NEXT_PUBLIC_SENTRY_DSN` -- Safe (Sentry DSN is not secret)
- `NEXT_PUBLIC_POSTHOG_KEY` -- Safe (analytics key)

No server-only secrets are leaked to the client. **GOOD.**

### 6.3 `DEV_LICENCE_BYPASS` -- Dangerous in Production

**File:** `/Users/devs/Downloads/Apollo/apps/web/lib/phases/transitions.ts` (line 44)

```typescript
const devBypass = process.env.DEV_LICENCE_BYPASS === "true";
```

If this environment variable is accidentally set in production, **all licence requirements are bypassed**, allowing any user to advance through all thesis phases without paying.

**Severity: HIGH** -- This should be checked against `NODE_ENV === "development"` as a safety net. The `.env.example` has it commented out, but there's no runtime guard.

---

## 7. File Upload Security

### 7.1 Upload Type Validation

**File:** `/Users/devs/Downloads/Apollo/apps/web/lib/r2/client.ts` (lines 8-14)

Allowed types: PDF, CSV, XLSX, PNG, JPEG. Validated both in the R2 client and the signed-url route. **GOOD.**

### 7.2 Path Traversal Protection

**File:** `/Users/devs/Downloads/Apollo/apps/web/app/api/upload/signed-url/route.ts` (lines 40-53)

Rejects `..`, `//`, `\\` in filenames, then sanitises to `[^\w.\-]` -> `_`. Key is prefixed with `projects/{projectId}/{uuid}/`. **GOOD.**

### 7.3 Missing File Size Enforcement on Signed URL

**File:** `/Users/devs/Downloads/Apollo/apps/web/lib/r2/client.ts`

`MAX_FILE_SIZE` (50MB) is defined but **never passed as a `ContentLength` constraint** to the `PutObjectCommand`. The signed URL is generated without a maximum content length, meaning a user could upload files larger than 50MB using the pre-signed URL.

**Severity: MEDIUM** -- Could be used for storage abuse. The `MAX_FILE_SIZE` constant is exported but not enforced server-side.

### 7.4 Missing Project Ownership Verification on Upload

**File:** `/Users/devs/Downloads/Apollo/apps/web/app/api/upload/signed-url/route.ts`

The route accepts a `projectId` in the request body and uses it to construct the storage key, but **does not verify that the authenticated user owns that project**. Any authenticated user can request an upload URL for any project ID.

**Severity: HIGH** -- Allows any authenticated user to upload files into another user's project storage namespace.

### 7.5 Dataset Upload -- No File Size Check Server-Side

**File:** `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/datasets/route.ts` (lines 57-168)

The dataset upload endpoint (`POST /api/projects/:id/datasets`) receives a `FormData` file but does **not validate file size** before calling `file.arrayBuffer()`. A large file could exhaust server memory.

**Severity: MEDIUM** -- Could cause denial of service via memory exhaustion.

---

## 8. Docker Container Security

### 8.1 LaTeX Container -- Well Secured

**File:** `/Users/devs/Downloads/Apollo/docker/docker-compose.yml` (lines 5-28)

Positive security controls:
- `network_mode: none` -- No network access
- `read_only: true` -- Filesystem is read-only
- `mem_limit: 1g` -- Memory capped
- `pids_limit: 256` -- Fork bomb protection
- `cap_drop: ALL` + minimal `cap_add` -- Principle of least privilege
- `no-new-privileges: true` -- Prevents privilege escalation
- Templates mounted as `:ro` (read-only)
- `tmpfs` for writable temp space

**Severity: GOOD** -- Excellent container hardening.

### 8.2 R Plumber Container -- Minor Issue

**File:** `/Users/devs/Downloads/Apollo/docker/docker-compose.yml` (lines 30-58)

Similar hardening to LaTeX container. However:
- Port `8787` is exposed to all interfaces (`"8787:8787"`), meaning the R Plumber API is accessible on the host network.
- `seccomp:unconfined` on both containers -- loosens the default seccomp profile. This is often needed for TeX Live and R but should be documented and ideally replaced with a custom seccomp profile.

**Severity: LOW** -- The R Plumber port exposure is acceptable if the host firewall blocks external access. The `seccomp:unconfined` is a minor concern.

### 8.3 R Plumber -- No Authentication

**File:** `/Users/devs/Downloads/Apollo/docker/plumber.R`

The R Plumber API has **no authentication**. Any process that can reach port 8787 can run statistical analyses. In the current architecture, only the Next.js application calls it, but if the port is exposed (see 8.2), it becomes an attack vector.

**Severity: MEDIUM** -- Should have a shared secret or API key for inter-service authentication.

### 8.4 R Plumber -- CPU Time Limits

Each R endpoint has `setTimeLimit()` calls (15-60 seconds). This prevents runaway computations. **GOOD.**

### 8.5 Docker Compile Mode -- `local` Mode Runs TeX Directly

**File:** `/Users/devs/Downloads/Apollo/apps/web/lib/latex/compile.ts` (lines 252-373)

The `local` compile mode runs `pdflatex` and `bibtex` directly on the host via `execFile`. While `execFile` prevents shell injection, running TeX directly on the application server is less secure than the Docker mode (no network isolation, no filesystem restrictions, no memory limits).

**Severity: MEDIUM** -- `local` mode should not be used in production. The `mock` default is safe.

---

## 9. Additional Findings

### 9.1 Sentry Tunnel Route

**File:** `/Users/devs/Downloads/Apollo/apps/web/next.config.ts` (line 34)

```typescript
tunnelRoute: "/monitoring",
```

The Sentry tunnel route at `/monitoring` is not in the Clerk middleware matcher exclusions and is not in the protected routes list. This route proxies Sentry events and should be publicly accessible (which it is, since it doesn't match any protected pattern). **This is correct behavior** but should be documented.

### 9.2 Review Token Endpoint -- No Rate Limiting

**File:** `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/share/route.ts`

The share endpoint generates cryptographically random review tokens (48 hex chars -- 192 bits of entropy). This is secure against brute force. However, there's no limit on how many tokens can be generated per project, which could lead to token sprawl.

**Severity: LOW**

### 9.3 Review Comments -- No Rate Limiting

**File:** `/Users/devs/Downloads/Apollo/apps/web/app/api/review/[token]/comments/route.ts`

The review comments endpoint has input validation (Zod schema, max 5000 chars) but no rate limiting. An attacker with a valid review token could spam comments.

**Severity: LOW** -- Review tokens are not publicly discoverable and expire after 7 days.

### 9.4 Inngest Route -- SDK-Managed Security

**File:** `/Users/devs/Downloads/Apollo/apps/web/app/api/inngest/route.ts`

The Inngest SDK's `serve()` function handles request verification using the `INNGEST_SIGNING_KEY`. This is secure when the signing key is configured.

**Severity: LOW** -- Verify that `INNGEST_SIGNING_KEY` is set in production.

---

## Summary of Findings by Severity

### CRITICAL (3)
1. **IDOR on `GET /api/projects/[id]`** -- No explicit `user_id` check, relies solely on RLS via `createServerSupabaseClient()` (`/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/route.ts`, line 23-27)
2. **IDOR on `PATCH /api/projects/[id]`** -- No explicit `user_id` check (`/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/route.ts`, line 60-65)
3. **IDOR on `DELETE /api/projects/[id]`** -- No explicit `user_id` check (`/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/route.ts`, line 89-94)

### HIGH (6)
1. **IDOR on `GET /api/projects/[id]/share`** -- Lists review tokens without project ownership verification using admin client (`/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/share/route.ts`, lines 67-90)
2. **No rate limiting on AI refine, auto-detect, synopsis parse** -- Unlimited Anthropic API cost exposure (`/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/sections/[phase]/refine/route.ts`)
3. **`DEV_LICENCE_BYPASS`** -- No `NODE_ENV` guard prevents production bypass of payment (`/Users/devs/Downloads/Apollo/apps/web/lib/phases/transitions.ts`, line 44)
4. **Upload signed-url** -- No project ownership verification (`/Users/devs/Downloads/Apollo/apps/web/app/api/upload/signed-url/route.ts`, lines 20-24)
5. **In-memory rate limiter** -- Resets on deploy, not shared across instances (`/Users/devs/Downloads/Apollo/apps/web/lib/ai/rate-limit.ts`)
6. **Admin Supabase client used extensively** -- Most routes bypass RLS, increasing IDOR blast radius (`/Users/devs/Downloads/Apollo/apps/web/lib/supabase/admin.ts`)

### MEDIUM (8)
1. **Middleware missing routes** -- `/api/checkout`, `/api/synopsis`, `/api/citations`, `/api/inngest` not in protected routes (`/Users/devs/Downloads/Apollo/apps/web/middleware.ts`, lines 4-12)
2. **`GET /api/projects` and `GET /api/licenses`** -- No explicit user filter, relies on RLS
3. **XSS via `dangerouslySetInnerHTML`** in title-page-preview (`/Users/devs/Downloads/Apollo/apps/web/components/preview/title-page-preview.tsx`, line 12)
4. **File size not enforced on R2 signed URLs** (`/Users/devs/Downloads/Apollo/apps/web/lib/r2/client.ts`)
5. **Dataset upload no file size check** (`/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/datasets/route.ts`)
6. **R Plumber has no authentication** (`/Users/devs/Downloads/Apollo/docker/plumber.R`)
7. **`local` compile mode** runs TeX on host (`/Users/devs/Downloads/Apollo/apps/web/lib/latex/compile.ts`, line 252)
8. **`seccomp:unconfined`** on both Docker containers (`/Users/devs/Downloads/Apollo/docker/docker-compose.yml`, lines 19, 43)

### LOW (5)
1. **Content-Disposition header injection** in DOCX export
2. **Origin header** used for share URL construction
3. **No rate limit** on review comments
4. **No limit** on review token generation per project
5. **Mermaid innerHTML** -- mitigated by `securityLevel: "strict"`

---

## Recommended Remediations (Priority Order)

1. **Add explicit `user_id` filter** to `GET/PATCH/DELETE /api/projects/[id]` -- either add `.eq("user_id", authResult.user.id)` or switch to admin client with manual ownership check.

2. **Add project ownership check** to `GET /api/projects/[id]/share` token listing.

3. **Add project ownership check** to `POST /api/upload/signed-url`.

4. **Add `DEV_LICENCE_BYPASS` guard**: `const devBypass = process.env.NODE_ENV === "development" && process.env.DEV_LICENCE_BYPASS === "true";`

5. **Extend rate limiting** to all AI endpoints (refine, auto-detect, synopsis parse). Implement Redis-backed rate limiter using Upstash.

6. **Add missing routes to middleware** `isProtectedRoute`: `/api/checkout(.*)`, `/api/synopsis(.*)`, `/api/citations(.*)`.

7. **Enforce file size** in R2 signed URL generation using `ContentLength` conditions.

8. **Add shared secret** to R Plumber for inter-service auth.

9. **Sanitise HTML** in `TitlePagePreview` component (use `DOMPurify` or equivalent).

10. **Prefer `createServerSupabaseClient()` over admin client** for read operations where RLS should apply.</result>
<usage>total_tokens: 144205
tool_uses: 92
duration_ms: 280498</usage>
</task-notification>
Full transcript available at: /private/tmp/claude-501/-Users-devs-Downloads-Apollo/tasks/a100e91.output

---

<task-notification>
<task-id>afd4aef</task-id>
<status>completed</status>
<summary>Agent "Architecture recommendations deep analysis" completed</summary>
<result>Now I have a thorough understanding of the architecture. Let me compile the comprehensive review.

---

# Apollo Platform Architecture Review -- Production Readiness Assessment

## 1. Scalability and Architecture

### 1.1 The In-Memory Semaphore Problem (CRITICAL)

**Files**: `/Users/devs/Downloads/Apollo/apps/web/lib/compute/semaphore.ts`, `/Users/devs/Downloads/Apollo/apps/web/lib/ai/rate-limit.ts`

The entire admission control system -- the semaphore, the queue, the rate limiter -- lives in process memory using JavaScript `Map` objects:

```typescript
const activeJobs = new Map<string, ActiveJob>();
const queues: Record<JobType, QueueEntry[]> = { compile: [], analysis: [] };
```

```typescript
const store = new Map<string, RateLimitEntry>(); // rate-limit.ts
```

This creates several cascading failure modes:

**Problem 1: Process restart wipes state.** When the Next.js process restarts (deploy, crash, OOM kill), all active jobs vanish from the semaphore but the Docker containers or AI streams may still be running. The semaphore reports 0 used units while resources are actually consumed. Subsequent requests acquire "phantom" slots, leading to resource oversubscription.

**Problem 2: Multi-instance deployment is impossible.** If you ever run 2+ Next.js instances (Coolify scale-up, Hetzner load balancer), each instance has its own semaphore. A compile job on instance A is invisible to instance B. The "1 concurrent compile" guarantee evaporates.

**Problem 3: Serverless functions ignore the semaphore entirely.** If any API route runs in a separate serverless function (Vercel edge, or even Next.js edge runtime), the semaphore is process-local and has no effect.

**Recommendation**: Replace both the semaphore and rate limiter with Redis-backed implementations. Redis `SETNX`/`INCR` with TTL keys provides atomic, multi-instance-safe counters. For the rate limiter, use a Redis sliding window (e.g., `ZRANGEBYSCORE`). This is the single highest-priority infrastructure change before launch.

For the immediate term on a single VPS, add a TTL-based "stale job reaper" that runs on a timer (e.g., every 60 seconds) and evicts any active job older than its maximum expected duration (120s for compile, 90s for analysis). This protects against process-crash orphans even without Redis.

### 1.2 Database Connection Pooling

**File**: `/Users/devs/Downloads/Apollo/apps/web/lib/supabase/admin.ts`

Every call to `createAdminSupabaseClient()` creates a new Supabase client:

```typescript
export function createAdminSupabaseClient() {
  return createClient(
    process.env.NEXT_PUBLIC_SUPABASE_URL!,
    process.env.SUPABASE_SERVICE_ROLE_KEY!,
    { auth: { autoRefreshToken: false, persistSession: false } }
  );
}
```

The `supabase-js` client uses `fetch` under the hood, not a persistent connection pool. This means every DB operation opens a new HTTPS request to the Supabase PostgREST proxy. While Supabase itself pools connections server-side, there is no HTTP connection reuse on the client side.

**Recommendation**: Create a singleton admin client at module scope (it is stateless and safe to reuse):

```typescript
let _adminClient: ReturnType<typeof createClient> | null = null;
export function createAdminSupabaseClient() {
  if (!_adminClient) {
    _adminClient = createClient(/* ... */);
  }
  return _adminClient;
}
```

If you later move to direct PostgreSQL access (for transactions), use PgBouncer or Supabase's built-in pooler (port 6543) with the connection string.

### 1.3 AI Generation Should Move to Inngest

**File**: `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/sections/[phase]/generate/route.ts`

The AI generation currently runs as a long-lived SSE stream from an API route. This is architecturally fragile for several reasons:

- Next.js API routes on Vercel or edge have timeout limits (typically 30s-60s). On self-hosted Hetzner this is not an issue today, but it limits future migration options.
- The 670-line route file handles authentication, context gathering, database writes, AI streaming, citation resolution, and error recovery all in one request lifecycle. If the client disconnects, the `cancel` handler tries to reset state, but there is a race window.
- The user's browser must keep the connection open for the full generation (potentially 60-90s for ROL). On Indian mobile networks with intermittent connectivity, this is unreliable.

**Recommendation**: Split into two operations:
1. **POST** `/generate` -- enqueue an Inngest job, return a `job_id` immediately.
2. **GET** `/generate/status` -- poll or subscribe (Supabase Realtime on the `sections` table) for progress updates.

The Inngest function handles the full lifecycle: AI streaming, DB writes, citation resolution. If it fails, Inngest retries automatically. The client is decoupled from the generation process. Inngest is already in your `package.json` (`"inngest": "^3.52.0"`) but appears unused.

### 1.4 CDN/Edge Caching Strategy

**File**: `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/preview.pdf/route.ts`

PDFs are served directly from the Node.js process reading from `/tmp`:

```typescript
pdfBytes = await readFile(candidate);
return new Response(pdfBytes as unknown as BodyInit, {
  headers: {
    "Cache-Control": "private, max-age=60",
  },
});
```

This has multiple issues:
- `/tmp` is ephemeral -- a server restart loses all compiled PDFs.
- Serving large PDFs (medical theses can be 100+ pages, 5-20MB) through the Node.js event loop blocks the single-threaded JS process.
- There is no CDN layer; every PDF view hits the origin server.

**Recommendation**:
1. After successful compilation, upload the PDF to Cloudflare R2 (already in your infrastructure plan).
2. Generate a signed URL with a 1-hour TTL and return it as a redirect.
3. Cloudflare R2 serves the PDF directly, with edge caching, zero Node.js involvement.
4. Store the R2 object key in the `compilations.pdf_url` column instead of a `/tmp` path.

---

## 2. Reliability and Error Recovery

### 2.1 Crash Mid-Compilation (HIGH RISK)

**File**: `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/compile/route.ts`

If the server process crashes during compilation:

1. The `compilations` record is stuck at `status: "running"` forever.
2. The semaphore slot is never released (the `finally { release(slot.jobId!) }` never executes).
3. The Docker container `apollo-latex` may have an orphaned `docker run` process consuming resources.

The only protection is the "running compilation" check at the start of the route:

```typescript
const { data: runningCompilation } = await supabase
  .from("compilations")
  .select("id")
  .eq("project_id", id)
  .eq("status", "running")
  .single();

if (runningCompilation) {
  return conflict("A compilation is already in progress");
}
```

But this permanently blocks the project from compiling -- the user sees "A compilation is already in progress" forever.

**Recommendation**:
1. Add a `started_at` timestamp to compilation records.
2. When checking for running compilations, apply a staleness window (e.g., 5 minutes):

```typescript
const { data: runningCompilation } = await supabase
  .from("compilations")
  .select("id, created_at")
  .eq("project_id", id)
  .eq("status", "running")
  .single();

if (runningCompilation) {
  const age = Date.now() - new Date(runningCompilation.created_at).getTime();
  if (age > 5 * 60 * 1000) {
    // Reset stale compilation
    await supabase.from("compilations")
      .update({ status: "failed", errors: ["Compilation timed out"] })
      .eq("id", runningCompilation.id);
  } else {
    return conflict("A compilation is already in progress");
  }
}
```

3. Add a periodic health-check cron (via Inngest schedule) that sweeps all `status: "running"` compilations older than 5 minutes and marks them failed.

### 2.2 AI Generation Timeout and Stale Detection

**File**: `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/sections/[phase]/generate/route.ts`

The stale generation detector at line 31 uses a 2-minute window:

```typescript
const STALE_GENERATING_MS = 2 * 60 * 1000; // 2 minutes
```

But the AI generation for the Review of Literature (Phase 4) uses `max_tokens: 12000`, which at Claude's output rate could take 60-90 seconds for the AI call alone, plus citation resolution (15s timeout), plus DB writes. Two minutes is too tight -- it could prematurely reset a legitimate generation.

Meanwhile, the comment on line 89 says "stuck for > 5 minutes" but the constant is 2 minutes -- a documentation/code mismatch.

**Recommendation**: Increase `STALE_GENERATING_MS` to 5 minutes. Add a `heartbeat_at` column to sections that the SSE stream updates every 30 seconds during generation. Use the heartbeat (not `updated_at`) for staleness detection.

### 2.3 R Plumber Container Failure

**File**: `/Users/devs/Downloads/Apollo/apps/web/lib/r-plumber/client.ts`

The R Plumber client correctly has timeout enforcement and error handling, and the Docker service has a health check. However:

- There is no retry logic for transient failures (network blip, container restart).
- There is no circuit breaker -- if R Plumber is down, every analysis request will wait for the full timeout before failing.
- The analysis runner at `/Users/devs/Downloads/Apollo/apps/web/lib/r-plumber/analysis-runner.ts` sets status to "failed" on error but does not distinguish between transient and permanent failures.

**Recommendation**:
1. Add a single retry with exponential backoff (wait 2s, retry once) for connection errors and 5xx responses.
2. Implement a simple circuit breaker: after 3 consecutive failures, short-circuit for 30 seconds before trying again.
3. Expose the `checkRPlumberHealth()` function at an API health endpoint so monitoring can detect container issues.

### 2.4 Missing Health Check Endpoints

There is no `/api/health` endpoint for the Next.js application. For production monitoring (Coolify, uptime robots, load balancers), you need:

```
GET /api/health -> { status: "ok", db: true, rPlumber: true, latex: true }
```

This should check:
- Supabase connectivity (simple `SELECT 1`)
- R Plumber health (`/health` endpoint exists in Docker config)
- LaTeX container availability (`docker ps --filter name=apollo-latex`)
- Semaphore status (current load)

### 2.5 Non-Atomic Multi-Step Operations

Throughout the codebase, multi-step database operations are not transactional. For example, in the compile route:

1. Insert compilation record (status: running)
2. Run compilation
3. Update compilation record (status: completed)

If step 3 fails (Supabase outage), the compilation succeeded but the record says "running" forever. Similarly, in the generate route, the section upsert, AI generation, and final update are separate operations.

Supabase REST API does not support transactions. If atomicity matters (and for billing-related operations like licence activation, it absolutely does), use Supabase's `rpc()` to call PostgreSQL functions that wrap multi-step operations in a single transaction.

---

## 3. Performance

### 3.1 Bundle Size Concerns

**File**: `/Users/devs/Downloads/Apollo/apps/web/package.json`

Several heavy dependencies deserve scrutiny:

- **`three` (0.182.0) + `@react-three/fiber` + `@react-three/drei`**: These are massive (Three.js alone is ~600KB minified). They appear to be used only for the auth page 3D scene (`auth-3d-scene.tsx`). Ensure these are lazily loaded with `next/dynamic` and `ssr: false`. If this is only used on the auth page, it should never be included in the dashboard or editor bundles.

- **`mermaid` (11.12.2)**: ~1.8MB minified. Used for diagram rendering. If only used in the thesis viewer, lazy-load it.

- **`xlsx` (0.18.5)**: ~600KB. Used for dataset parsing. Should be dynamically imported only when the user uploads a file.

- **`pdfjs-dist` (5.4.624)**: ~800KB. The PDF worker is loaded from unpkg CDN (good), but the main library is bundled. Consider dynamic import on the workspace page.

- **`mammoth` (1.11.0)**: DOCX-to-HTML converter. Likely only used for synopsis upload -- dynamic import.

**Recommendation**: Run `npx @next/bundle-analyzer` and verify that three.js, mermaid, xlsx, and mammoth are code-split into their own chunks and not included in the shared layout bundle. Any page that uses these should use `next/dynamic({ ssr: false })`.

### 3.2 PDF Viewer Performance

**File**: `/Users/devs/Downloads/Apollo/apps/web/components/viewer/pdf-viewer.tsx`

The PDF viewer loads the full PDF and renders all thumbnail pages when thumbnails are toggled:

```typescript
{Array.from({ length: numPages }, (_, i) => (
  <button key={i + 1} onClick={() => setPageNumber(i + 1)}>
    <Page pageNumber={i + 1} width={72} renderTextLayer={false} renderAnnotationLayer={false} />
  </button>
))}
```

For a 100-page thesis, this creates 100 `<Page>` components simultaneously, each rendering a canvas. This will cause significant memory usage and rendering lag on mobile devices.

**Recommendation**:
1. Virtualise the thumbnail list (use `react-window` or similar) to only render visible thumbnails.
2. Add `loading="lazy"` behaviour -- render thumbnails as the user scrolls to them.
3. Consider generating thumbnail images server-side during compilation (using `pdftoppm`) instead of client-side rendering.

### 3.3 PDF Worker Loaded from unpkg CDN

```typescript
pdfjs.GlobalWorkerOptions.workerSrc = `https://unpkg.com/pdfjs-dist@${pdfjs.version}/build/pdf.worker.min.mjs`;
```

Loading the PDF.js worker from unpkg means: (a) a dependency on a third-party CDN for core functionality, (b) no offline support, (c) potential CORS/CSP issues. Self-host the worker file in `/public/` and reference it locally.

### 3.4 Supabase Admin Client Created Per Request

As noted in section 1.2, `createAdminSupabaseClient()` creates a new client per call. In the compile route alone, it is called once at the top level, and then `assembleThesisContent` and sub-functions may create additional clients. Each creates a new HTTP session. Singleton pattern is the fix.

### 3.5 N+1 Query Pattern in Citation Resolution

**File**: `/Users/devs/Downloads/Apollo/apps/web/lib/citations/auto-resolve.ts`

The citation upsert loop performs individual `supabase.from("citations").upsert(...)` calls for each citation:

```typescript
for (const citation of resolved) {
  // ...
  await supabase.from("citations").upsert({ /* ... */ }, { onConflict: "project_id,cite_key" });
}
```

For a Review of Literature section with 30+ citations, this is 30+ sequential database round-trips.

**Recommendation**: Batch the upserts. Supabase `.upsert()` accepts an array:

```typescript
const toUpsert = resolved.filter(/* eligible */).map(/* transform */);
await supabase.from("citations").upsert(toUpsert, { onConflict: "project_id,cite_key" });
```

The same pattern appears in the orphan citation creation loop further down in the same file. Batch those as well.

---

## 4. Developer Experience

### 4.1 Test Coverage

The test suite has 26 test files covering:

- LaTeX parsing/generation (7 files): `assemble.test.ts`, `escape.test.ts`, `front-matter.test.ts`, `generate-tex.test.ts`, `latex-to-tiptap.test.ts`, `parse-log.test.ts`, `tiptap-to-latex.test.ts`, `validate.test.ts`
- Citations (5 files): `crossref.test.ts`, `pubmed.test.ts`, `resolve.test.ts`, `audit.test.ts`, `auto-resolve.test.ts`
- Compliance (3 files): `nbems.test.ts`, `checklists.test.ts`, `checker.test.ts`, `prisma-flow.test.ts`
- Core infra (3 files): `semaphore.test.ts`, `transitions.test.ts`, `rate-limit.test.ts`
- R Plumber (2 files): `client.test.ts`, `analysis-runner.test.ts`
- Datasets (1 file): `parse.test.ts`

**Gaps**:
- No API route tests (the generate, compile, and review routes are untested at the HTTP level).
- No integration tests that verify the full compile pipeline (assemble -> validate -> compileTex) end-to-end with real TeX content.
- No tests for the `preview.pdf` route, which has file-system edge cases.
- No component tests for critical UI interactions (PDF viewer, compile button, AI generate button).
- The MEMORY.md mentions "226 tests across 17 files" but the pipeline E2E test file path (`tests/pipeline-e2e.test.ts`) does not appear to exist in the current directory.

**Recommendation**: Before launch, add:
1. Integration tests for the compile route (using mock mode) that verify the full pipeline from project data to CompileResult.
2. API route tests using `NextRequest` mocks for auth, error handling, and validation paths.
3. A "golden path" E2E test using Playwright that creates a project, uploads a synopsis, generates Phase 0, and verifies the UI updates.

### 4.2 Local Development Setup

The developer experience for local setup is reasonable:
- `.env.example` is comprehensive with clear comments.
- `LATEX_COMPILE_MODE=mock` allows development without Docker.
- `DEV_LICENCE_BYPASS=true` skips payment gates.
- `pnpm dev` with Turbopack for fast iteration.

**Gaps**:
- No `docker-compose up` command for the full stack (the compose file only covers latex + r-plumber, not the web app).
- No seed script to populate a test database with sample projects, sections, and citations.
- No documentation for setting up Clerk + Supabase webhook integration locally.
- The R Plumber URL defaults to localhost:8787, but there is no guidance on running R Plumber locally outside Docker.

**Recommendation**: Create a `scripts/seed.ts` that populates a development database with a sample project at various pipeline stages. This lets a new developer immediately see the dashboard, editor, and PDF viewer in action without going through the full thesis generation flow.

### 4.3 Environment Variable Management

**File**: `/Users/devs/Downloads/Apollo/apps/web/.env.example`

The env file uses non-null assertion (`!`) everywhere:

```typescript
process.env.NEXT_PUBLIC_SUPABASE_URL!
process.env.SUPABASE_SERVICE_ROLE_KEY!
```

If any required env var is missing, the error will be a cryptic "Cannot read properties of undefined" deep in a Supabase call, not a clear startup failure.

**Recommendation**: Add a startup validation module (e.g., using Zod) that runs in `next.config.ts` or a root layout and validates all required env vars at build/startup time. Next.js supports this via `env` validation in the config.

---

## 5. Security Review

### 5.1 Admin Supabase Client Usage (HIGH RISK)

**File**: `/Users/devs/Downloads/Apollo/apps/web/lib/supabase/admin.ts`

The admin client uses `SUPABASE_SERVICE_ROLE_KEY`, which **bypasses all Row Level Security (RLS) policies**. It is used throughout the API routes for all database operations:

```typescript
const supabase = createAdminSupabaseClient();
const { data: project } = await supabase.from("projects").select("*").eq("id", id).eq("user_id", authResult.user.id).single();
```

The code manually adds `.eq("user_id", authResult.user.id)` to enforce ownership, but this is a manual enforcement pattern that RLS was designed to automate. If any developer forgets the `.eq("user_id", ...)` clause, they create an IDOR vulnerability.

Looking at the compile route, the ownership check is correct:
```typescript
.eq("user_id", authResult.user.id)
```

But in `analysis-runner.ts`, the `executeAnalysis` function fetches the analysis and dataset without any user-level check:
```typescript
const { data: analysis } = await supabase.from("analyses").select("*").eq("id", analysisId).single();
```

This is called from an API route context where auth has already been verified, but the function itself accepts any `analysisId` without verification.

**Recommendation**: For API routes that handle user-facing requests, use a Supabase client authenticated with the user's JWT (via `createServerSupabaseClient()` which is already used in the licences page). Reserve the admin client for background jobs (Inngest functions) and system-level operations. This activates RLS as a defence-in-depth layer.

### 5.2 Docker Compile Security

**File**: `/Users/devs/Downloads/Apollo/apps/web/lib/latex/compile.ts`

The Docker compile function has good security defaults:
- `--network=none` (no network access)
- `--read-only` filesystem
- `tmpfs` for ephemeral writes
- Memory limit (1GB)
- PID limit (256)
- Capabilities dropped except DAC_OVERRIDE and FOWNER

However, the work directory is bind-mounted directly into the container:
```typescript
"-v", `${workDir}:/thesis`
```

This means the container has read access to all files written to `workDir`. If a malicious LaTeX file uses `\input{/templates/...}` or reads from unexpected paths, the `read_only` flag on the container root and the limited bind mount mitigate this. The implementation is solid.

**One concern**: The `containerName` comes from an env var:
```typescript
const containerName = process.env.LATEX_CONTAINER_NAME ?? "apollo-latex";
```

If this env var were ever user-controlled (it is not today), it could be used for container name injection. Mark this as a note for future reference.

### 5.3 PDF Preview Route -- Path Traversal

**File**: `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/preview.pdf/route.ts`

The `compilation.pdf_url` value from the database is used directly as a file path:
```typescript
pdfBytes = await readFile(candidate);
```

If an attacker could write a malicious `pdf_url` value to the database (e.g., `/etc/passwd`), this would read arbitrary files. The value comes from `compileTex()` which constructs the path deterministically, and the database requires admin-level access to write. But as a defense-in-depth measure, validate that the path starts with the expected prefix:

```typescript
const allowedPrefix = path.join(os.tmpdir(), "apollo-pdfs");
if (!candidate.startsWith(allowedPrefix)) continue;
```

---

## 6. User Experience Recommendations

### 6.1 Offline/Poor-Connectivity Handling (CRITICAL for Indian Market)

The target users are Indian medical PG students, many of whom access the internet via 4G mobile connections with frequent dropouts. The current architecture is hostile to poor connectivity:

- AI generation requires a sustained SSE connection for 30-90 seconds.
- PDF preview loads the entire PDF through the Node.js process.
- No service worker for offline caching of the dashboard or editor shell.
- No optimistic UI updates -- every action waits for the server response.

**Recommendations**:
1. Move AI generation to background jobs (Inngest) as discussed in section 1.3. Show a progress indicator that polls rather than relying on a sustained connection.
2. Cache the last-compiled PDF in the browser using the Cache API or IndexedDB.
3. Add a service worker that caches the application shell (HTML, CSS, JS) for offline access to the dashboard and editor.
4. Show clear, non-technical error messages when the network is unavailable: "Your internet connection appears to be offline. Your work is saved locally and will sync when you reconnect."
5. Add "Retry" buttons on all failed operations, not just error toasts that disappear.

### 6.2 Error Messaging

The API error responses use standard HTTP codes with JSON envelopes, but some user-facing messages are too technical:

- "A compilation is already in progress" -- could say "Your thesis is currently being compiled. Please wait a moment and try again."
- "Token budget exhausted" -- could say "You have used all available AI generation credits for this section. Please edit the content manually or contact support."
- "Per-user concurrency limit reached" -- meaningless to a medical student.

**Recommendation**: Create a `lib/errors/user-messages.ts` map that translates internal error codes to user-friendly, British English messages. The API returns a machine-readable `code`, and the frontend maps it to a human message.

### 6.3 Onboarding

There is no guided onboarding flow visible in the codebase. A first-time user who signs up lands on the dashboard with no projects and no guidance.

**Recommendation**:
1. Add a "Create Your First Thesis" empty-state card on the dashboard.
2. Show a brief interactive tour (3-4 steps) that explains: upload synopsis, AI generates sections, review and approve, compile PDF.
3. Provide a "Sample Thesis" that users can explore in read-only mode to understand the output quality.

### 6.4 Accessibility

The codebase uses semantic HTML in many places (buttons, links) but relies heavily on colour-only indicators (sage green for success, muted grey for inactive). There are no `aria-label` attributes on icon-only buttons in the PDF viewer. The dot-grid background pattern may cause visual noise for users with certain visual conditions.

**Recommendation**: Conduct a WCAG 2.1 AA audit. At minimum:
- Add `aria-label` to all icon-only buttons.
- Ensure colour contrast meets 4.5:1 ratio (some of the `text-[#D1D1D1]` on white backgrounds may fail).
- Add `role="status"` and `aria-live="polite"` to loading/progress indicators.

---

## 7. Business Model Recommendations

### 7.1 Pricing Analysis

**File**: `/Users/devs/Downloads/Apollo/apps/web/app/(dashboard)/checkout/page.tsx`

Current pricing:
- Student Plan: INR 499/month (~$6) -- 1 thesis licence, 30-day access
- Professional Plan: INR 999/month (~$12) -- 3 licences, 30-day access
- One-Time Thesis: INR 1,499 (~$18) -- no time limit

**Assessment**:
- INR 499/month is aggressive for the Indian student market. Medical PG students typically have monthly stipends of INR 40,000-80,000 depending on the state and institution. INR 499 is affordable but students are extremely price-sensitive.
- The **30-day time limit on the monthly plans is problematic**. Thesis writing is not a linear 30-day process. Students work in bursts, often with weeks between supervisor feedback rounds. A student who purchases the Student Plan, generates 3 sections, then waits 2 weeks for supervisor review, has consumed their licence window doing nothing.
- The One-Time plan at INR 1,499 is the natural choice, but it cannibalises the monthly recurring revenue.

**Recommendations**:
1. Change the Student Plan to **INR 499/thesis** (no monthly expiry). The licence activates when first used for generation and expires 90 days later or upon thesis completion, whichever comes first.
2. Consider a **INR 199 trial tier** that covers Phase 0-1 only (synopsis parsing + front matter) so students can evaluate quality before committing.
3. The Professional Plan should target **departments or guides**, not individual students. "INR 2,999 for 5 thesis licences per semester" is a more natural purchasing unit for a supervising professor.

### 7.2 Feature Gating

Currently, the only gate is Phase 1 -> Phase 2 (licence required). Consider:

- **Free tier**: Phase 0 (synopsis parsing) + Phase 1 (front matter) + Phase 3 (aims). These are short, low-cost sections that demonstrate value.
- **Paid**: Phase 2 (Introduction) onwards -- these are the citation-heavy, high-token-cost phases where the AI provides the most value.
- **Premium add-on**: Export to DOCX, supervisor collaboration links, priority compile queue.

### 7.3 Viral Growth Potential

Medical PG students operate in tight-knit cohorts (typically 4-20 students per department per year). If one student produces a significantly better thesis, others will ask how.

**Recommendations**:
1. Add a "Powered by Apollo" watermark on sandbox PDFs (already implemented).
2. Add a referral system: "Share Apollo with a batchmate, both get INR 100 off."
3. Allow students to share their completed thesis (read-only) via a public link, which serves as a portfolio piece and marketing.

---

## 8. Technical Debt

### 8.1 Must Fix Before Launch

1. **Redis for semaphore + rate limiter**: The in-memory approach will cause production incidents on the first deploy/restart.

2. **PDF storage on R2**: Files in `/tmp` will be lost on every deployment. This is the most visible user-facing bug -- "I compiled yesterday and now the PDF is gone."

3. **Stale compilation recovery**: Add the staleness window to the compile route's "already running" check.

4. **Env var validation**: Add startup-time validation of all required environment variables.

5. **Batch citation upserts**: The N+1 query pattern in citation resolution will cause timeouts with large reference lists.

6. **Self-host PDF.js worker**: Remove the unpkg CDN dependency.

### 8.2 Should Fix Soon After Launch

1. **Move AI generation to Inngest**: Decouple from SSE for connectivity resilience.

2. **Singleton Supabase admin client**: Reduce connection overhead.

3. **PDF viewer virtualisation**: Prevent memory issues on mobile devices with large documents.

4. **Health check endpoints**: Essential for monitoring and alerting.

5. **API route integration tests**: Cover the critical compile and generate paths.

6. **User-facing error message map**: Replace technical errors with helpful guidance.

7. **Bundle size analysis**: Ensure Three.js, mermaid, and xlsx are code-split.

### 8.3 Can Wait

1. **Multi-instance scaling**: Redis-based semaphore enables this, but a single CX23 can handle initial load.

2. **PostgreSQL transactions**: Only critical for billing operations; can use Supabase RPC when needed.

3. **Service worker / offline support**: Important for mobile UX but not launch-blocking.

4. **Internationalisation (Hindi UI)**: Indian medical education is conducted in English; this is nice-to-have.

5. **WCAG compliance audit**: Should happen within 3 months post-launch.

### 8.4 Dependencies to Watch

- **`xlsx` (0.18.5)**: This is the SheetJS community edition, which has licence complexity (Apache 2.0 for basic features, proprietary for advanced). Evaluate if you need it or if `papaparse` (CSV only) suffices for most datasets.
- **`novel` (1.0.2)**: Novel is a Tiptap-based editor wrapper. Your codebase already uses `@tiptap/core` directly. If Novel is only used for its default configuration, you may be loading duplicate Tiptap instances. Verify that Novel and your custom Tiptap setup share the same dependencies.
- **`@sentry/nextjs` (10.38.0)**: The conditional Sentry wrapping in `next.config.ts` is good. Just ensure the Sentry DSN is set in production.

### 8.5 Code Patterns That Will Cause Issues at Scale

1. **The 3-tier DB fallback pattern** in the generate route (lines 373-432) where it tries 3 different `UPDATE` calls with decreasing column sets is a code smell indicating schema uncertainty. Once the schema is stable, remove the fallbacks and use a single update.

2. **`process.cwd()` for template resolution** (`path.resolve(process.cwd(), "../../templates")`) is fragile and depends on the working directory at runtime. In a Docker deployment, `process.cwd()` may differ from local dev. Use an environment variable (`TEMPLATES_DIR`) or resolve relative to `__dirname`.

3. **The `as unknown as BodyInit` cast** in the PDF preview route (line 71) masks a type incompatibility. Use `new Response(Buffer.from(pdfBytes))` instead.

---

## Summary: Priority Matrix

| Priority | Item | Effort | Impact |
|----------|------|--------|--------|
| P0 | Redis semaphore + rate limiter | Medium | Prevents production incidents |
| P0 | PDF storage on R2 (not /tmp) | Medium | Prevents data loss on deploy |
| P0 | Stale compilation recovery | Small | Unblocks stuck projects |
| P0 | Env var validation at startup | Small | Prevents cryptic errors |
| P1 | Batch citation upserts | Small | Fixes timeout on large refs |
| P1 | Self-host PDF.js worker | Small | Removes CDN dependency |
| P1 | Move AI gen to Inngest | Large | Connectivity resilience |
| P1 | Singleton Supabase client | Small | Reduces connection overhead |
| P1 | Health check endpoint | Small | Enables monitoring |
| P2 | PDF viewer virtualisation | Medium | Mobile performance |
| P2 | Bundle size optimisation | Medium | Initial load time |
| P2 | Integration test suite | Large | Prevents regressions |
| P2 | Error message humanisation | Medium | User experience |
| P3 | Service worker / offline | Large | Mobile UX |
| P3 | Multi-instance scaling | Large | Future-proofing |
| P3 | Pricing model refinement | N/A | Business impact |

This platform has strong domain-specific engineering -- the LaTeX compilation pipeline, citation resolution system, BibTeX sanitisation, and university template abstraction are all well-designed for the problem domain. The primary risks are in infrastructure reliability (in-memory state, ephemeral storage) and connectivity resilience for the target market. Addressing the P0 items before launch will dramatically improve production stability.</result>
<usage>total_tokens: 109471
tool_uses: 36
duration_ms: 243009</usage>
</task-notification>
Full transcript available at: /private/tmp/claude-501/-Users-devs-Downloads-Apollo/tasks/afd4aef.output

---

<task-notification>
<task-id>a99d733</task-id>
<status>completed</status>
<summary>Agent "Audit data privacy and compliance" completed</summary>
<result>Now I have a comprehensive understanding of the entire data flow. Let me compile the full audit report.

---

# Apollo Platform -- Data Privacy & DPDP Act Compliance Audit

## Audit Date: 2026-02-17

## Executive Summary

Apollo demonstrates **above-average privacy awareness** for an early-stage SaaS product. The codebase includes PII redaction before AI calls, Sentry/PostHog PII sanitisation, RLS on every table, audit logging, and a structured data classification document. However, several **critical gaps** remain that would block DPDP Act compliance before launch. The platform handles medical thesis content (which may contain patient data) and processes it through third-party AI services, making these gaps high-priority.

---

## 1. PII Data Inventory

### 1.1 Personal Data Collected

| Data Field | Storage Location | Classification |
|---|---|---|
| Email | `users.email` (Supabase) + Clerk | Sensitive |
| Name | `users.name` (Supabase) + Clerk | Sensitive |
| Candidate name | `projects.metadata_json.candidate_name` | Sensitive |
| Registration number | `projects.metadata_json.registration_no` | Sensitive |
| Guide name | `projects.metadata_json.guide_name` | Sensitive |
| HOD name | `projects.metadata_json.hod_name` | Sensitive |
| Department | `projects.metadata_json.department` | Internal |
| University | `thesis_licenses.university` | Internal |
| IP address | `audit_log.ip_address` | Sensitive |
| Synopsis text (may contain patient data) | `projects.synopsis_text` | Confidential/Highly Sensitive |
| Dataset (may contain patient data) | `datasets.rows_json` + R2 | Highly Sensitive |

**Source files**:
- `/Users/devs/Downloads/Apollo/apps/web/supabase/migrations/002_create_users.sql` -- stores email and name in plaintext
- `/Users/devs/Downloads/Apollo/apps/web/supabase/migrations/004_create_projects.sql` -- `metadata_json` JSONB contains all candidate/guide PII
- `/Users/devs/Downloads/Apollo/apps/web/lib/validation/schemas.ts` (lines 8-18) -- schema accepts `candidate_name`, `guide_name`, `hod_name`, `registration_no`
- `/Users/devs/Downloads/Apollo/apps/web/components/wizard/steps/metadata-form-step.tsx` -- collects all these fields via form

### 1.2 PII Storage Analysis

**FINDING [HIGH]: Candidate/guide PII stored in plaintext in `metadata_json`**

The `thesis_licenses` table correctly stores hashed versions (`candidate_name_hash`, `registration_no_hash`, `guide_name_hash`) per `/Users/devs/Downloads/Apollo/apps/web/supabase/migrations/003_create_thesis_licenses.sql` (lines 10-13). However, the `projects.metadata_json` column stores all the same fields in **plaintext**. The hashing on `thesis_licenses` is only used for identity-lock enforcement, not for PII protection.

**FINDING [MEDIUM]: No hashing implementation found**

While the database schema defines `candidate_name_hash`, `registration_no_hash`, and `guide_name_hash` columns, I found **no code that actually performs SHA-256 hashing** when writing to these columns. A search for `hash`, `SHA-256`, `createHash` in TypeScript files only returned results in `razorpay.ts` (HMAC verification), `validate.ts` (LaTeX), and test files with hardcoded placeholder values like `"abc123"`.

**FINDING [LOW]: IP address stored in audit log**

`/Users/devs/Downloads/Apollo/apps/web/supabase/migrations/013_create_audit_log.sql` (line 8) defines `ip_address INET`. However, the audit trigger function in migration 014 does not currently populate this field -- it is always NULL. This is acceptable for now but should be documented if populated in future.

### 1.3 PII in Logs

**Positive findings**:

- `/Users/devs/Downloads/Apollo/apps/web/lib/logging/logger.ts` (lines 31-35) explicitly strips `metadata_json`, `synopsis_text`, `email`, `name`, and `registration_no` from log entries before writing.

**FINDING [MEDIUM]: Console.error/warn statements bypass structured logger**

Multiple API routes use direct `console.error()` / `console.warn()` rather than the structured logger. While these do not currently log PII, the pattern is fragile. Examples:
- `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/sections/[phase]/generate/route.ts` line 83: `console.error("Unexpected error in POST generate:", err)` -- `err` could contain user data from failed Supabase queries.
- `/Users/devs/Downloads/Apollo/apps/web/app/api/webhooks/clerk/route.ts` line 65: `console.error("No email address found in Clerk user.created event")` -- while this does not log the email, the error log from Clerk webhook failure (line 81) includes the full Supabase error which could contain email.

---

## 2. AI Data Handling

### 2.1 PII Redaction Before AI Calls

**Positive finding**: `/Users/devs/Downloads/Apollo/apps/web/lib/ai/redact.ts` implements redaction for:
- Phone numbers (Indian format)
- Aadhaar numbers (12-digit)
- Email addresses
- PAN numbers

This is applied in the generate route at `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/sections/[phase]/generate/route.ts` (line 192):
```typescript
const { redacted: redactedSynopsis } = redactPII(project.synopsis_text);
```

### 2.2 What Data Goes to Claude API

**FINDING [CRITICAL]: `metadata_json` sent to AI unredacted**

In the generate route (line 199), the full `project.metadata_json` is passed to `getPhaseUserMessage()`:
```typescript
let userMessage = getPhaseUserMessage(
    phaseNumber,
    redactedSynopsis,
    (project.metadata_json ?? {}) as Record<string, unknown>,
    previousSections
);
```

In `/Users/devs/Downloads/Apollo/apps/web/lib/ai/prompts.ts` (lines 368-371), metadata is serialised directly into the prompt:
```typescript
const metadataStr = Object.entries(metadata)
    .filter(([, v]) => v !== null && v !== undefined && v !== "")
    .map(([k, v]) => `${k}: ${String(v)}`)
    .join("\n");
```

This means **candidate_name, guide_name, hod_name, registration_no, department** are all sent to the Claude API in every generation call. The redaction only covers the synopsis text, not the metadata.

**FINDING [CRITICAL]: Dataset generation sends synopsis to AI without redaction**

In `/Users/devs/Downloads/Apollo/apps/web/lib/datasets/generate.ts` (lines 58-59):
```typescript
if (project.synopsis_text) {
    userPrompt += `Synopsis:\n${project.synopsis_text.slice(0, 3000)}\n\n`;
}
```
The synopsis is sent **without** passing through `redactPII()`. The dataset generation prompt also sends `metadata_json` (line 47).

**FINDING [HIGH]: Refine route sends existing LaTeX (which contains names) to AI without redaction**

In `/Users/devs/Downloads/Apollo/apps/web/app/api/projects/[id]/sections/[phase]/refine/route.ts` (line 84):
```typescript
const userMessage = `Here is the current chapter content:\n\n${currentLatex}\n\n---STUDENT INSTRUCTIONS---\n${instructions.trim()}`;
```
The existing chapter content -- which includes `\candidatename{}`, `\supervisorname{}`, and other PII baked into the LaTeX during front matter generation -- is sent directly to the Claude API with no redaction.

**FINDING [HIGH]: Previously approved sections sent to AI with potential PII**

The generate route (lines 177-189) sends previously approved section content as context. Since Phase 1 (Front Matter) content includes names, registration numbers, guide names etc. (generated by `/Users/devs/Downloads/Apollo/apps/web/lib/latex/front-matter.ts`), all subsequent generation calls include this PII.

### 2.3 Synopsis / Patient Data Handling

**FINDING [CRITICAL]: No medical data sanitisation**

Synopses for medical theses, particularly case reports and case series, frequently contain:
- Patient demographics (age, sex, specific dates)
- Case histories with identifiable details
- Hospital record numbers
- Clinical details that could identify patients

The `redactPII()` function only catches structured identifiers (Aadhaar, PAN, phone, email). It does **not** detect:
- Patient names mentioned in prose
- Hospital record/MRD numbers
- Date-of-birth or age+date combinations
- Geographic identifiers in case reports

### 2.4 AI Response Checking

**FINDING [HIGH]: No PII check on AI responses**

AI-generated content is stored directly in the database and displayed to users without any post-generation PII scan. If the AI model hallucinated or echoed back PII from the prompt, it would be stored verbatim.

---

## 3. Third-Party Data Sharing

### 3.1 Clerk (Authentication)

**Data sent**: Email, name (first + last), authentication tokens

**Source**: Clerk's SDK handles sign-up/sign-in. On user creation, the webhook at `/Users/devs/Downloads/Apollo/apps/web/app/api/webhooks/clerk/route.ts` extracts `email_addresses`, `first_name`, `last_name` and syncs to Supabase.

**FINDING [MEDIUM]: No DPA (Data Processing Agreement) reference for Clerk**

Clerk stores user PII (email, name, OAuth tokens) on their infrastructure (US-based). There is no reference to a DPA in the codebase or governance documents.

### 3.2 PostHog (Analytics)

**Positive findings** in `/Users/devs/Downloads/Apollo/apps/web/components/providers/posthog-provider.tsx`:
- Uses EU endpoint (`https://eu.i.posthog.com`)
- `sanitize_properties` strips email, name, registration_no, candidate_name, guide_name, and `$ip`
- Only captures in production
- Event allowlist restricts to 7 specific events
- `capture_pageview: false` -- no automatic page tracking

**FINDING [MEDIUM]: PostHog is opt-out, not opt-in**

PostHog initialises automatically for all production users. The only opt-out is the development mode check. There is no user-facing opt-in/opt-out mechanism. Under DPDP Act, consent for analytics tracking should be explicit.

### 3.3 Sentry (Error Tracking)

**Positive findings**:
- Client config (`/Users/devs/Downloads/Apollo/apps/web/sentry.client.config.ts`): `beforeSend` strips `email`, `username`, `name`, `registration_no` from both `event.user` and breadcrumbs
- Server config (`/Users/devs/Downloads/Apollo/apps/web/sentry.server.config.ts`): Same `beforeSend` PII stripping

**FINDING [HIGH]: Edge Sentry config has no PII stripping**

`/Users/devs/Downloads/Apollo/apps/web/sentry.edge.config.ts` (lines 1-8) initialises Sentry **without** a `beforeSend` hook. Any errors in edge middleware (which handles authentication via Clerk) could leak PII to Sentry.

**FINDING [MEDIUM]: Sentry session replays could capture PII**

While `replaysSessionSampleRate` is 0, `replaysOnErrorSampleRate` is 0.1 (10%). Session replays capture DOM state, which includes form fields with candidate names, registration numbers, guide names, etc. There is no `maskAllText` or `maskAllInputs` configuration.

### 3.4 Razorpay / Stripe (Payments)

**Data sent**: `user_id` (UUID), `plan_type`, `project_id` -- passed as metadata/notes in payment creation.

**Positive finding**: No PII (name, email) is sent in the webhook payloads processed by the platform. Card details are never stored (handled entirely by payment providers).

**Source**: `/Users/devs/Downloads/Apollo/apps/web/app/api/webhooks/stripe/route.ts` and `/Users/devs/Downloads/Apollo/apps/web/app/api/webhooks/razorpay/route.ts`

**Note**: Razorpay and Stripe themselves collect name, email, and card details during their checkout flows. The Razorpay checkout modal is loaded client-side.

### 3.5 CrossRef / PubMed (Citation Search)

**Data sent**: Search queries derived from thesis title, keywords, study type, and department.

**Source**: `/Users/devs/Downloads/Apollo/apps/web/lib/citations/pre-seed.ts` sends queries like `"{title} {keywords}"` and `"{department} {keywords}"` to public APIs.

**FINDING [LOW]: Department name sent to CrossRef/PubMed**

The department name (e.g., "Department of General Surgery, SSKM Hospital") could be considered quasi-identifying. This is a low risk since these are public academic search APIs.

### 3.6 Anthropic (Claude API)

**Data sent** (as detailed in section 2): Synopsis text (redacted), metadata including candidate name, guide name, HOD name, registration number, department, previously approved section content including front matter with full names.

**FINDING [CRITICAL]: Cross-border data transfer without adequate disclosure**

The governance document `/Users/devs/Downloads/Apollo/docs/governance/data-classification.md` (line 37) acknowledges "Claude API: US-based processing" and states "No patient-identifiable data in prompts (enforced by PII redaction gate)". However, as shown in section 2, this claim is **not accurate** -- personal data (names, registration numbers) IS sent to the US-based API.

---

## 4. Data Retention & Deletion

### 4.1 Account Deletion

**FINDING [CRITICAL]: No "delete my account" flow exists**

A search for `deleteAccount`, `delete.*account`, `data.*erasure`, `right.*forget` found zero results in the codebase. The governance document (`data-classification.md` line 68) claims "Access, correction, erasure, grievance -- all supported via account settings", but **no account settings page or deletion API exists**.

Under DPDP Act Section 12(1), the Data Principal (user) has the right to erasure. This is not implemented.

### 4.2 Project Deletion

**Positive finding**: Project deletion uses `ON DELETE CASCADE` across all child tables:
- `sections` (migration 005)
- `citations` (migration 006)
- `datasets` (migration 007)
- `analyses` (migration 008)
- `figures` (migration 009)
- `compliance_checks` (migration 010)
- `compilations` (migration 011)
- `ai_conversations` (migration 012)

This means deleting a project cascades to all related data.

**FINDING [HIGH]: Audit log not cascaded on project deletion**

`audit_log.project_id` is a regular FK, NOT `ON DELETE CASCADE` (migration 013, line 7). This means audit logs persist after project deletion. The governance document says audit logs are retained for 2 years, which is reasonable, but the `old_value_json` and `new_value_json` JSONB columns contain full snapshots of old/new row values -- **including PII like candidate_name, email, synopsis_text in their plaintext form**.

**FINDING [HIGH]: No R2 file cleanup on project deletion**

The governance document mentions "Cleanup job within 24hrs of project deletion" for R2 objects, but no such cleanup job, cron task, or trigger exists in the codebase. Compiled PDFs and dataset files would persist in R2 indefinitely after project deletion.

### 4.3 AI Conversation Logs

`ai_conversations` table stores full message JSON arrays (`messages_json JSONB[]`). These cascade on project delete, but:

**FINDING [HIGH]: No auto-purge job for AI conversations**

The governance document specifies "90 days after project completion" auto-purge. No such job, cron, or scheduled function exists in the codebase. A search for `auto.purge`, `cron`, `retention`, `cleanup`, `scheduled` found no relevant implementation.

### 4.4 Compilation Logs

`compilations.log_text` stores up to 50,000 characters of raw LaTeX compilation logs. These cascade on project delete. However, log text could contain file paths, error messages with thesis content, and names from the LaTeX source.

### 4.5 Data Retention Implementation

**FINDING [CRITICAL]: Zero retention policies implemented in code**

The governance document defines comprehensive retention schedules, but **none** are implemented:
- No 30-day grace period for user PII after account deletion (no deletion flow exists)
- No 90-day retention limit for AI conversations
- No 2-year auto-purge for audit logs
- No R2 cleanup job
- No auto-purge scheduler of any kind

---

## 5. Governance Documents Analysis

### 5.1 Data Classification (`data-classification.md`)

**Well-structured** with clear classification levels, retention schedules, data residency table, and handling rules.

**FINDING [MEDIUM]: Claims not backed by implementation**

Several claims in this document are aspirational rather than implemented:
| Claim | Reality |
|---|---|
| "Hash candidate name, registration number, guide name in `thesis_licenses` (SHA-256)" | No hashing code found |
| "Validate for PII patterns on upload (flag columns matching names, phone, Aadhaar)" | No dataset PII validation exists |
| "R2 cleanup job within 24hrs" | No cleanup job exists |
| "Auto-purge job" for AI conversations and audit logs | No auto-purge exists |
| "Data principal rights: Access, correction, erasure, grievance" | No erasure flow exists |

### 5.2 Incident Response (`incident-response.md`)

Well-structured playbook with severity levels, response steps, DR scenarios, and credential rotation checklist. This is a governance-ready document.

**FINDING [LOW]**: Breach notification timeline states "within 72 hours" with a caveat "confirm with legal counsel". This should be finalised before launch.

### 5.3 Security Tests (`security-tests.md`)

Comprehensive checklist covering RLS, auth, signed URLs, rate limits, upload validation, licence gates, phase transitions, payment webhooks, container isolation, and SSL.

**FINDING [MEDIUM]**: These are documented as checklists but there is no `pnpm test:security` or `pnpm test:rls` script visible in the codebase, and no `deploy-conformance.sh` script exists. The security tests are **aspirational**.

---

## 6. Consent & Transparency

### 6.1 Privacy Policy

**FINDING [CRITICAL]: No privacy policy page exists**

The footer at `/Users/devs/Downloads/Apollo/apps/web/components/landing/footer-section.tsx` (lines 17-18) has a "Privacy Policy" link pointing to `#` (dead link). No `/privacy` route exists.

### 6.2 Terms of Service

**FINDING [CRITICAL]: No terms of service page exists**

Same footer has "Terms of Service" linking to `#`. No `/terms` route exists.

### 6.3 Cookie Consent

**FINDING [HIGH]: No cookie consent mechanism**

No cookie consent banner, dialog, or component exists anywhere in the codebase. The platform sets:
- Clerk authentication cookies (functional -- exempt)
- PostHog analytics cookies (requires consent under DPDP)
- `sidebar_state` cookie (functional -- exempt)

### 6.4 AI Processing Consent

**FINDING [CRITICAL]: No explicit consent for AI processing**

There is no acknowledgement, checkbox, or consent flow at sign-up or project creation that informs users:
- Their synopsis will be processed by AI (Claude, US-based)
- Their thesis content will be sent to Anthropic's servers
- Their metadata (names, registration numbers) will be included in AI prompts

The governance document mentions "Dataset consent: Explicit acknowledgement that data will be processed by AI and R services" but this is not implemented.

### 6.5 PostHog Opt-in/Opt-out

As noted in section 3.2, PostHog is active for all production users with no opt-out mechanism. The `opt_out_capturing()` call at line 21 of the PostHog provider only applies in development mode.

---

## 7. Medical Data Special Handling

### 7.1 Synopsis Content

**FINDING [CRITICAL]: No special handling for medical/health data in synopses**

Medical thesis synopses, particularly for:
- **Case reports** -- may contain specific patient histories, demographics, treatments
- **Retrospective studies** -- may reference specific patient cohorts with identifiable details
- **Case series** -- multiple patient descriptions

The platform treats all synopses identically. There is no:
- Warning about patient data at synopsis upload
- Scan for medical record numbers, dates of birth, or patient identifiers
- Option to flag a study as containing patient-level data
- Different handling path for case reports vs. population studies

### 7.2 Uploaded Datasets

**FINDING [HIGH]: No PII scanning on dataset upload**

The governance document (`data-classification.md` line 44) states "Validate for PII patterns on upload (flag columns matching names, phone, Aadhaar)" -- but no such validation exists. The dataset upload and generation routes accept data without any PII check.

The AI dataset generation prompt at `/Users/devs/Downloads/Apollo/apps/web/lib/ai/prompts.ts` (line 423) correctly instructs "Do NOT include patient names, hospital IDs, or any personally identifiable information", but this only applies to AI-generated datasets. User-uploaded datasets have no guardrails.

### 7.3 Ethics Committee Reference

**Positive finding**: The Materials & Methods prompt (lines 177-178) includes a template for IHEC approval and mandates ethical considerations as section 11 of 12 required sections. The Appendices prompt includes Ethics Approval Certificate placeholder.

**FINDING [MEDIUM]**: While the AI generates ethics-related text, there is no programmatic requirement for ethics committee approval number. A project can proceed through all phases without any ethics reference.

---

## 8. Compliance Summary & Risk Matrix

### CRITICAL Findings (Must fix before launch)

| # | Finding | DPDP Section | File(s) |
|---|---|---|---|
| C1 | No privacy policy page | S6 (Notice) | Footer links to `#` |
| C2 | No terms of service page | S6 (Notice) | Footer links to `#` |
| C3 | No account deletion flow | S12(1) (Erasure) | No code exists |
| C4 | No consent for AI processing | S6 (Consent) | No consent UI |
| C5 | Metadata (names, reg. no.) sent to Claude API unredacted | S8 (Processing) | `generate/route.ts:199`, `prompts.ts:368` |
| C6 | Synopsis sent to AI without redaction in dataset generation | S8 (Processing) | `datasets/generate.ts:59` |
| C7 | Zero data retention policies implemented | S8(7) (Retention) | No cron/cleanup code |
| C8 | Cross-border transfer to US (Claude API) without adequate disclosure | S16 (Transfer) | `data-classification.md:37` |
| C9 | No medical data special handling | S9 (Sensitive data) | No code exists |

### HIGH Findings (Fix before public beta)

| # | Finding | File(s) |
|---|---|---|
| H1 | Refine route sends LaTeX with PII to AI without redaction | `refine/route.ts:84` |
| H2 | No cookie consent banner | No code exists |
| H3 | Edge Sentry config missing PII stripping | `sentry.edge.config.ts` |
| H4 | Audit log retains PII after project deletion (no cascade) | Migration 013 |
| H5 | No R2 file cleanup on project deletion | No code exists |
| H6 | No auto-purge for AI conversations | No code exists |
| H7 | No PII scanning on dataset upload | No code exists |
| H8 | No PII check on AI-generated responses | No code exists |
| H9 | Previously approved sections (with PII) sent as context to AI | `generate/route.ts:184-189` |
| H10 | Sentry session replays capture form fields with PII | `sentry.client.config.ts:9` |

### MEDIUM Findings (Fix before GA)

| # | Finding | File(s) |
|---|---|---|
| M1 | PostHog opt-out only, not opt-in | `posthog-provider.tsx:21` |
| M2 | No DPA references for Clerk, Sentry, PostHog, Anthropic | Governance docs |
| M3 | Identity hashing not implemented (schema exists, no code) | Missing entirely |
| M4 | Console.error bypasses structured logger | Multiple API routes |
| M5 | Security test scripts referenced but not implemented | `security-tests.md` |
| M6 | Governance claims not backed by code | `data-classification.md` |
| M7 | No ethics committee approval enforcement | No programmatic check |

---

## 9. Recommendations (Priority Order)

1. **Immediate -- before any user testing**:
   - Extend `redactPII()` to also cover `metadata_json` before it reaches AI prompts. Create a `sanitiseMetadataForAI()` function that strips `candidate_name`, `guide_name`, `hod_name`, `registration_no` and replaces with placeholders.
   - Apply `redactPII()` in the dataset generation route.
   - Add `beforeSend` PII stripping to `sentry.edge.config.ts`.
   - Add `maskAllText: true` and `maskAllInputs: true` to Sentry replay configuration.

2. **Before public beta**:
   - Create `/privacy` and `/terms` pages with DPDP-compliant content (covering data collection, processing, AI use, cross-border transfer, retention, and data principal rights).
   - Implement cookie consent banner (at minimum for PostHog analytics cookies).
   - Add AI processing consent at project creation (checkbox acknowledging synopsis/content will be processed by AI services in the US).
   - Implement "Delete My Account" flow (cascade delete all projects, R2 files, Clerk user).
   - Implement R2 cleanup trigger on project deletion (database trigger + async job).
   - Implement SHA-256 hashing for identity fields when writing to `thesis_licenses`.

3. **Before GA launch**:
   - Implement scheduled auto-purge jobs (Supabase pg_cron or Inngest scheduled function) for AI conversations (90-day) and audit logs (2-year).
   - Add dataset PII scanner on upload (check column names and sample values for patterns matching names, phone numbers, hospital IDs).
   - Add a synopsis upload warning for case reports/series about patient data.
   - Convert PostHog to opt-in with user preference storage.
   - Establish DPAs with Clerk, Anthropic, PostHog, and Sentry.
   - Run all security tests defined in `security-tests.md` and create actual test files.
   - Add post-generation PII scan on AI responses before storing.</result>
<usage>total_tokens: 118834
tool_uses: 78
duration_ms: 271445</usage>
</task-notification>
Full transcript available at: /private/tmp/claude-501/-Users-devs-Downloads-Apollo/tasks/a99d733.output

---

Now go through this review, and find all  areas where my choice is reqd ,eg pricing, latex round trip options , etc etc  and ask me questions to clarify those points.